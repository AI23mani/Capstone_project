{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28fe3396-805a-48b1-b678-5186a690e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "201032f6-7022-4388-91a7-00a60ca018a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X,dep_Y,n):\n",
    "        rfelist=[]\n",
    "        feature_names = indep_X.columns\n",
    "        log_model = LogisticRegression(solver='lbfgs')\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "       # NB = GaussianNB()\n",
    "        DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "        svc_model = SVC(kernel = 'linear', random_state = 0)\n",
    "        #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        rfemodellist=[log_model,svc_model,RF,DT] \n",
    "        for i in   rfemodellist:\n",
    "            print(i)\n",
    "            log_rfe = RFE(estimator=i, n_features_to_select=n)\n",
    "            log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "            log_rfe_feature=log_fit.transform(indep_X)\n",
    "            rfelist.append(log_rfe_feature)\n",
    "        return rfelist\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efaf8951-ec8c-45ba-a453-380ede3f6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.25, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52b85135-f320-48c6-aa4d-ef038fec1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def svm_linear(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    \n",
    "def svm_NL(X_train,y_train,X_test):\n",
    "                \n",
    "        from sklearn.svm import SVC\n",
    "        classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "   \n",
    "def Navie(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.naive_bayes import GaussianNB\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm         \n",
    "    \n",
    "    \n",
    "def knn(X_train,y_train,X_test):\n",
    "           \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "032ebe65-5769-4af9-8c56-cb1e8fee3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf): \n",
    "    \n",
    "    rfedataframe=pd.DataFrame(index=['Logistic','SVC','Random','DecisionTree'],columns=['Logistic','SVMl','SVMnl',\n",
    "                                                                                        'KNN','Navie','Decision','Random'])\n",
    "\n",
    "    for number,idex in enumerate(rfedataframe.index):\n",
    "        \n",
    "        rfedataframe['Logistic'][idex]=acclog[number]       \n",
    "        rfedataframe['SVMl'][idex]=accsvml[number]\n",
    "        rfedataframe['SVMnl'][idex]=accsvmnl[number]\n",
    "        rfedataframe['KNN'][idex]=accknn[number]\n",
    "        rfedataframe['Navie'][idex]=accnav[number]\n",
    "        rfedataframe['Decision'][idex]=accdes[number]\n",
    "        rfedataframe['Random'][idex]=accrf[number]\n",
    "    return rfedataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd6cba91-4d45-4635-87ce-105e3a7df0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(\"preprocessdata.csv\", index_col=None)\n",
    "df2 = dataset1\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "indep_X = df2.drop('diagnosis_M', axis=1)\n",
    "dep_Y = df2['diagnosis_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "663eb754-ae92-47ce-a1a7-3af23d6388b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.22862</td>\n",
       "      <td>0.28241</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1937.05</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.62695</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.41915</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1937.05</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.27500</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.00</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.36130</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.133695</td>\n",
       "      <td>0.22862</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.70</td>\n",
       "      <td>0.19010</td>\n",
       "      <td>0.62695</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.41915</td>\n",
       "      <td>0.12301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.100300</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.00</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.23640</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1326.3</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>1937.05</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.097800</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.00</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.25720</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.084550</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.00</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.22180</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.117800</td>\n",
       "      <td>0.22862</td>\n",
       "      <td>0.28241</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.00</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.62695</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.40870</td>\n",
       "      <td>0.12301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.057975</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.60</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.28710</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          17.99         10.38          122.80     1001.0         0.118400   \n",
       "1          20.57         17.77          132.90     1326.0         0.084740   \n",
       "2          19.69         21.25          130.00     1203.0         0.109600   \n",
       "3          11.42         20.38           77.58      386.1         0.133695   \n",
       "4          20.29         14.34          135.10     1297.0         0.100300   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1326.3         0.111000   \n",
       "565        20.13         28.25          131.20     1261.0         0.097800   \n",
       "566        16.60         28.08          108.30      858.1         0.084550   \n",
       "567        20.60         29.33          140.10     1265.0         0.117800   \n",
       "568         7.76         24.54           47.92      181.0         0.057975   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0             0.22862         0.28241              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.22862         0.24140              0.10520         0.2464   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.22862         0.28241              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.07875  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0             184.60     1937.05           0.16220            0.62695   \n",
       "1             158.80     1937.05           0.12380            0.18660   \n",
       "2             152.50     1709.00           0.14440            0.42450   \n",
       "3              98.87      567.70           0.19010            0.62695   \n",
       "4             152.20     1575.00           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10     1937.05           0.14100            0.21130   \n",
       "565           155.00     1731.00           0.11660            0.19220   \n",
       "566           126.70     1124.00           0.11390            0.30940   \n",
       "567           184.60     1821.00           0.16500            0.62695   \n",
       "568            59.16      268.60           0.08996            0.06444   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.7119                0.2654         0.41915   \n",
       "1             0.2416                0.1860         0.27500   \n",
       "2             0.4504                0.2430         0.36130   \n",
       "3             0.6869                0.2575         0.41915   \n",
       "4             0.4000                0.1625         0.23640   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216         0.20600   \n",
       "565           0.3215                0.1628         0.25720   \n",
       "566           0.3403                0.1418         0.22180   \n",
       "567           0.7855                0.2650         0.40870   \n",
       "568           0.0000                0.0000         0.28710   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.12301  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12301  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indep_X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1201594e-7e36-4e0e-a12c-a674c7b3488b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Logistic'][idex]=acclog[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:9: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMl'][idex]=accsvml[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['SVMnl'][idex]=accsvmnl[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['KNN'][idex]=accknn[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Navie'][idex]=accnav[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Decision'][idex]=accdes[number]\n",
      "C:\\Users\\MANIKA\\AppData\\Local\\Temp\\ipykernel_11520\\1109509503.py:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  rfedataframe['Random'][idex]=accrf[number]\n"
     ]
    }
   ],
   "source": [
    "rfelist=rfeFeature(indep_X,dep_Y,5)       \n",
    "\n",
    "acclog=[]\n",
    "accsvml=[]\n",
    "accsvmnl=[]\n",
    "accknn=[]\n",
    "accnav=[]\n",
    "accdes=[]\n",
    "accrf=[]\n",
    "\n",
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_Y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    acclog.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_linear(X_train,y_train,X_test)  \n",
    "    accsvml.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=svm_NL(X_train,y_train,X_test)  \n",
    "    accsvmnl.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=knn(X_train,y_train,X_test)  \n",
    "    accknn.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Navie(X_train,y_train,X_test)  \n",
    "    accnav.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)  \n",
    "    accdes.append(Accuracy)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)  \n",
    "    accrf.append(Accuracy)\n",
    "    \n",
    "result=rfe_classification(acclog,accsvml,accsvmnl,accknn,accnav,accdes,accrf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d080a-92b3-49dc-bcd4-777a5f2eea54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef143cda-dac8-43b4-ab26-d9007da0c456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.874126</td>\n",
       "      <td>0.853147</td>\n",
       "      <td>0.881119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.888112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision  \\\n",
       "Logistic      0.881119  0.853147  0.867133   0.86014  0.874126  0.853147   \n",
       "SVC           0.902098  0.902098  0.916084  0.902098  0.881119  0.881119   \n",
       "Random        0.951049  0.951049  0.944056  0.958042  0.951049  0.923077   \n",
       "DecisionTree  0.937063  0.951049   0.93007   0.93007  0.937063  0.937063   \n",
       "\n",
       "                Random  \n",
       "Logistic      0.881119  \n",
       "SVC           0.888112  \n",
       "Random        0.937063  \n",
       "DecisionTree  0.937063  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #value n=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9678d8a0-ac46-4209-bd30-054adfbca066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.951049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.867133</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.965035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.944056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision  \\\n",
       "Logistic      0.944056  0.937063   0.93007  0.923077  0.909091  0.923077   \n",
       "SVC           0.902098  0.909091  0.916084  0.909091  0.867133  0.902098   \n",
       "Random        0.951049  0.951049  0.965035  0.944056  0.951049  0.944056   \n",
       "DecisionTree  0.944056  0.937063  0.923077  0.916084  0.937063  0.916084   \n",
       "\n",
       "                Random  \n",
       "Logistic      0.951049  \n",
       "SVC           0.916084  \n",
       "Random        0.965035  \n",
       "DecisionTree  0.944056  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #value n=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1ebf28c-0044-42b3-8914-47082992249b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.944056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.951049</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.965035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.895105</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision  \\\n",
       "Logistic      0.937063  0.951049  0.923077  0.923077  0.902098   0.93007   \n",
       "SVC           0.902098  0.909091   0.93007  0.895105   0.86014   0.86014   \n",
       "Random        0.951049  0.958042  0.965035  0.937063  0.944056  0.937063   \n",
       "DecisionTree  0.923077   0.93007  0.909091  0.895105  0.923077  0.923077   \n",
       "\n",
       "                Random  \n",
       "Logistic      0.944056  \n",
       "SVC           0.958042  \n",
       "Random        0.965035  \n",
       "DecisionTree  0.944056  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #value n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5d51ca7-f515-4903-8b96-16d8b897c112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>SVMl</th>\n",
       "      <th>SVMnl</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Navie</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.86014</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random</th>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.965035</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.951049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.937063</td>\n",
       "      <td>0.944056</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.916084</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.937063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Logistic      SVMl     SVMnl       KNN     Navie  Decision  \\\n",
       "Logistic      0.944056  0.958042  0.937063  0.923077  0.902098  0.937063   \n",
       "SVC           0.909091  0.902098  0.916084  0.909091   0.86014  0.916084   \n",
       "Random        0.944056  0.937063  0.965035   0.93007   0.93007  0.902098   \n",
       "DecisionTree  0.937063  0.944056  0.916084  0.916084   0.93007  0.923077   \n",
       "\n",
       "                Random  \n",
       "Logistic      0.958042  \n",
       "SVC           0.937063  \n",
       "Random        0.951049  \n",
       "DecisionTree  0.937063  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result #value n=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79346553-579f-4ca5-9a38-3be5681f54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\MANIKA\\Anaconda3\\envs\\iml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', random_state=0)\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "Selected features for Classifier 1:\n",
      "1. [17.99     0.28241 25.38     0.62695  0.7119 ]\n",
      "2. [20.57    0.0869 24.99    0.1866  0.2416]\n",
      "3. [19.69    0.1974 23.57    0.4245  0.4504]\n",
      "4. [11.42     0.2414  14.91     0.62695  0.6869 ]\n",
      "5. [20.29   0.198 22.54   0.205  0.4  ]\n",
      "6. [12.45    0.1578 15.47    0.5249  0.5355]\n",
      "7. [18.25    0.1127 22.88    0.2576  0.3784]\n",
      "8. [13.71     0.09366 17.06     0.3682   0.2678 ]\n",
      "9. [13.      0.1859 15.49    0.5401  0.539 ]\n",
      "10. [12.46     0.2273  15.09     0.62695  0.7855 ]\n",
      "11. [16.02     0.03299 19.19     0.1551   0.1459 ]\n",
      "12. [15.78     0.09954 20.42     0.5609   0.3965 ]\n",
      "13. [19.17    0.2065 20.96    0.3903  0.3639]\n",
      "14. [15.85     0.09938 16.84     0.1924   0.2322 ]\n",
      "15. [13.73     0.2128  15.03     0.62695  0.6943 ]\n",
      "16. [14.54     0.1639  17.46     0.62695  0.7026 ]\n",
      "17. [14.68     0.07395 19.07     0.1871   0.2914 ]\n",
      "18. [16.13    0.1722 20.96    0.4233  0.4784]\n",
      "19. [19.81    0.1479 27.32    0.315   0.5372]\n",
      "20. [13.54     0.06664 15.11     0.1773   0.239  ]\n",
      "21. [13.08     0.04568 14.5      0.2776   0.189  ]\n",
      "22. [ 9.504    0.02956 10.23     0.1148   0.08867]\n",
      "23. [15.34    0.2077 18.07    0.5954  0.6305]\n",
      "24. [21.16    0.1097 27.46    0.26    0.3155]\n",
      "25. [16.65    0.1525 26.46    0.3578  0.4695]\n",
      "26. [17.14    0.2229 22.25    0.3949  0.3853]\n",
      "27. [14.58     0.1425  17.62     0.62695  0.5539 ]\n",
      "28. [18.61    0.149  21.31    0.2117  0.3446]\n",
      "29. [15.3     0.1683 20.27    0.611   0.6335]\n",
      "30. [17.57     0.09875 20.01     0.2812   0.2489 ]\n",
      "31. [18.63    0.2319 23.15    0.4257  0.6133]\n",
      "32. [11.84    0.1218 16.82    0.5775  0.6956]\n",
      "33. [17.02    0.2417 20.88    0.3559  0.5588]\n",
      "34. [19.27     0.1657  24.15     0.62695  0.6091 ]\n",
      "35. [16.13    0.1354 20.21    0.5804  0.5274]\n",
      "36. [16.74    0.1348 20.01    0.3835  0.5409]\n",
      "37. [14.25    0.1319 15.89    0.4238  0.5186]\n",
      "38. [13.03     0.02562 13.3      0.04619  0.04833]\n",
      "39. [14.99     0.02398 14.99     0.05131  0.02398]\n",
      "40. [13.48    0.1063 15.53    0.4225  0.503 ]\n",
      "41. [13.44    0.0311 15.93    0.2043  0.2085]\n",
      "42. [10.95    0.1044 12.84    0.2698  0.4023]\n",
      "43. [19.07     0.2107  24.09     0.62695  0.7242 ]\n",
      "44. [13.28     0.09847 17.38     0.3724   0.3664 ]\n",
      "45. [13.17     0.08259 16.23     0.3904   0.3728 ]\n",
      "46. [18.65    0.1974 22.82    0.509   0.7345]\n",
      "47. [8.196   0.01588 8.964   0.1357  0.0688 ]\n",
      "48. [13.17    0.1226 15.67    0.4166  0.5006]\n",
      "49. [12.05     0.06592 13.76     0.2156   0.305  ]\n",
      "50. [13.49     0.04751 15.15     0.1711   0.2282 ]\n",
      "51. [11.76     0.01657 12.98     0.08615  0.05523]\n",
      "52. [13.64     0.01857 14.67     0.1582   0.105  ]\n",
      "53. [11.94     0.01972 13.1      0.08906  0.09203]\n",
      "54. [18.22    0.1772 20.6     0.2297  0.2623]\n",
      "55. [15.1      0.05253 18.1      0.2057   0.2712 ]\n",
      "56. [11.52     0.03036 12.84     0.0872   0.09076]\n",
      "57. [19.21    0.1323 26.14    0.3511  0.3879]\n",
      "58. [14.71    0.1293 17.87    0.429   0.3587]\n",
      "59. [1.305e+01 6.920e-04 1.423e+01 6.191e-02 1.845e-03]\n",
      "60. [8.618   0.02061 9.507   0.1239  0.1168 ]\n",
      "61. [1.017e+01 1.084e-02 1.102e+01 9.866e-02 2.168e-02]\n",
      "62. [8.598   0.03    9.565   0.1698  0.09001]\n",
      "63. [14.25    0.2135 17.67    0.6247  0.6922]\n",
      "64. [ 9.173    0.05988 10.01     0.1678   0.1397 ]\n",
      "65. [12.68    0.1128 17.09    0.4061  0.4024]\n",
      "66. [14.78    0.1267 17.31    0.3416  0.3024]\n",
      "67. [ 9.465    0.02172 10.41     0.1664   0.09412]\n",
      "68. [11.31     0.03709 12.33     0.09148  0.1444 ]\n",
      "69. [ 9.029    0.28241 10.31     0.4365   0.7855 ]\n",
      "70. [12.78     0.03653 13.46     0.07061  0.1039 ]\n",
      "71. [18.94    0.108  24.86    0.2336  0.2687]\n",
      "72. [8.888   0.08606 9.733   0.2436  0.1434 ]\n",
      "73. [17.2      0.1692  23.32     0.62695  0.6566 ]\n",
      "74. [13.8      0.07789 16.57     0.3542   0.2779 ]\n",
      "75. [12.31     0.03372 14.11     0.1843   0.1703 ]\n",
      "76. [16.07     0.09769 19.77     0.2045   0.2829 ]\n",
      "77. [13.53     0.06877 14.08     0.1379   0.08539]\n",
      "78. [18.05    0.1684 22.39    0.5634  0.3786]\n",
      "79. [20.18     0.28241 23.37     0.6164   0.7681 ]\n",
      "80. [12.86     0.03889 14.24     0.2141   0.1731 ]\n",
      "81. [11.45     0.04591 13.11     0.1676   0.1755 ]\n",
      "82. [13.34    0.1169 15.53    0.4791  0.4858]\n",
      "83. [21.9      0.28241 27.46     0.6076   0.6476 ]\n",
      "84. [19.1     0.1937 20.33    0.2817  0.2432]\n",
      "85. [12.       0.04151 13.67     0.2003   0.2267 ]\n",
      "86. [18.46    0.1335 22.93    0.2089  0.3157]\n",
      "87. [14.48    0.1204 16.21    0.1976  0.3349]\n",
      "88. [19.02    0.1468 24.56    0.3206  0.5755]\n",
      "89. [12.36     0.06015 13.83     0.2463   0.2434 ]\n",
      "90. [14.64     0.09966 16.34     0.3089   0.2604 ]\n",
      "91. [14.62     0.03102 16.11     0.1766   0.09189]\n",
      "92. [15.37    0.1122 16.43    0.1997  0.2846]\n",
      "93. [13.27     0.03261 16.36     0.1238   0.135  ]\n",
      "94. [13.45     0.03974 15.1      0.1751   0.1381 ]\n",
      "95. [15.06    0.17   18.23    0.4203  0.5203]\n",
      "96. [20.26    0.1465 24.22    0.3539  0.4098]\n",
      "97. [12.18     0.0249  12.83     0.09358  0.0498 ]\n",
      "98. [9.787e+00 6.829e-03 1.092e+01 9.473e-02 2.049e-02]\n",
      "99. [11.6      0.04196 13.06     0.1851   0.1922 ]\n",
      "100. [14.42     0.09388 16.33     0.3026   0.3194 ]\n",
      "101. [13.61     0.08625 16.99     0.1943   0.3169 ]\n",
      "102. [6.981  0.     7.93   0.1202 0.    ]\n",
      "103. [12.18     0.02383 13.34     0.08862  0.1145 ]\n",
      "104. [ 9.876    0.06154 10.76     0.2302   0.2644 ]\n",
      "105. [10.49     0.02995 11.54     0.1486   0.07987]\n",
      "106. [13.11    0.2071 16.31    0.4099  0.6376]\n",
      "107. [11.64    0.0707 13.14    0.266   0.2873]\n",
      "108. [12.36     0.02643 13.29     0.1963   0.1937 ]\n",
      "109. [21.9      0.28241 27.46     0.62695  0.7855 ]\n",
      "110. [11.34     0.05133 13.01     0.2196   0.312  ]\n",
      "111. [ 9.777    0.04334 11.05     0.1765   0.13   ]\n",
      "112. [12.63    0.1065 13.33    0.225   0.2216]\n",
      "113. [14.26     0.28241 15.3      0.4193   0.6783 ]\n",
      "114. [10.51     0.06476 11.16     0.2049   0.1295 ]\n",
      "115. [8.726   0.04132 9.628   0.2364  0.2456 ]\n",
      "116. [11.93     0.03328 13.67     0.2399   0.1503 ]\n",
      "117. [8.95    0.09263 9.414   0.1879  0.1544 ]\n",
      "118. [14.87    0.169  18.81    0.448   0.4704]\n",
      "119. [15.78    0.2133 20.19    0.4925  0.7356]\n",
      "120. [17.95     0.07293 20.58     0.1202   0.2249 ]\n",
      "121. [11.41     0.03512 12.82     0.239    0.2102 ]\n",
      "122. [18.66    0.1457 22.25    0.2291  0.3272]\n",
      "123. [21.9      0.28241 26.02     0.4244   0.5803 ]\n",
      "124. [14.5      0.08842 15.7      0.1788   0.256  ]\n",
      "125. [13.37     0.08092 14.26     0.2531   0.3308 ]\n",
      "126. [1.385e+01 1.420e-02 1.549e+01 1.350e-01 8.115e-02]\n",
      "127. [13.61     0.05285 16.89     0.2884   0.3796 ]\n",
      "128. [19.       0.09271 22.32     0.2264   0.3207 ]\n",
      "129. [15.1     0.1138 16.11    0.2883  0.196 ]\n",
      "130. [19.79    0.2545 22.63    0.3861  0.5673]\n",
      "131. [12.19     0.02855 13.34     0.2585   0.09915]\n",
      "132. [15.46    0.1466 19.26    0.2394  0.3791]\n",
      "133. [16.16    0.1043 19.47    0.3055  0.2992]\n",
      "134. [15.71     0.07135 17.5      0.1949   0.1709 ]\n",
      "135. [18.45    0.1153 22.52    0.2275  0.3965]\n",
      "136. [12.77     0.04711 14.49     0.1523   0.2177 ]\n",
      "137. [11.71     0.03592 13.33     0.1028   0.1046 ]\n",
      "138. [11.43     0.03503 12.32     0.1648   0.1399 ]\n",
      "139. [14.95    0.1539 18.55    0.2164  0.3355]\n",
      "140. [11.28     0.04635 11.92     0.1822   0.08669]\n",
      "141. [ 9.738    0.      10.62     0.07204  0.     ]\n",
      "142. [16.11     0.09447 19.92     0.2236   0.2802 ]\n",
      "143. [11.43     0.02031 12.78     0.1792   0.07708]\n",
      "144. [12.9      0.04894 14.48     0.2548   0.209  ]\n",
      "145. [10.75     0.02251 11.95     0.1223   0.09755]\n",
      "146. [11.9     0.0371 13.15    0.2517  0.0942]\n",
      "147. [11.8     0.1659 13.74    0.4092  0.4504]\n",
      "148. [14.95    0.0905 16.25    0.2521  0.25  ]\n",
      "149. [14.44     0.08487 15.85     0.2735   0.3103 ]\n",
      "150. [13.74     0.02881 15.34     0.1824   0.1564 ]\n",
      "151. [13.       0.03136 14.16     0.1105   0.08112]\n",
      "152. [8.219  0.1321 9.092  0.431  0.5381]\n",
      "153. [ 9.731    0.28241 11.02     0.2772   0.7855 ]\n",
      "154. [11.15     0.01982 11.99     0.08971  0.07116]\n",
      "155. [13.15     0.09293 14.77     0.2256   0.3009 ]\n",
      "156. [12.25     0.03885 13.59     0.1788   0.1943 ]\n",
      "157. [17.68    0.1855 20.47    0.3498  0.3583]\n",
      "158. [16.84    0.0515 18.22    0.171   0.1882]\n",
      "159. [12.06     0.01972 13.14     0.1232   0.08636]\n",
      "160. [1.090e+01 3.090e-03 1.236e+01 8.294e-02 1.854e-02]\n",
      "161. [11.75     0.06843 13.32     0.1892   0.1956 ]\n",
      "162. [19.19    0.1193 22.03    0.2016  0.2264]\n",
      "163. [19.59    0.2508 26.73    0.3846  0.681 ]\n",
      "164. [12.34    0.0537 13.58    0.2338  0.1688]\n",
      "165. [21.9     0.1324 27.46    0.3583  0.3948]\n",
      "166. [14.97     0.01947 15.98     0.09995  0.0775 ]\n",
      "167. [10.8      0.02531 11.6      0.1257   0.1047 ]\n",
      "168. [16.78     0.08422 20.05     0.2119   0.2318 ]\n",
      "169. [17.47    0.2159 23.14    0.383   0.489 ]\n",
      "170. [14.97     0.02602 16.11     0.1637   0.06648]\n",
      "171. [12.32     0.03987 13.5      0.1266   0.1242 ]\n",
      "172. [13.43     0.05858 17.98     0.1546   0.2644 ]\n",
      "173. [15.46    0.2032 18.79    0.3583  0.583 ]\n",
      "174. [11.08     0.02363 11.35     0.0824   0.03938]\n",
      "175. [10.66     0.      11.54     0.06791  0.     ]\n",
      "176. [8.671   0.      9.262   0.07057 0.     ]\n",
      "177. [ 9.904   0.1307 11.26    0.295   0.3486]\n",
      "178. [16.46    0.1793 17.79    0.4667  0.5862]\n",
      "179. [1.301e+01 1.595e-03 1.400e+01 3.432e-02 7.977e-03]\n",
      "180. [1.281e+01 9.193e-03 1.363e+01 5.445e-02 2.758e-02]\n",
      "181. [21.9      0.28241 27.46     0.4034   0.534  ]\n",
      "182. [21.09     0.2487  26.68     0.62695  0.678  ]\n",
      "183. [15.7      0.06593 20.11     0.3547   0.2902 ]\n",
      "184. [11.41     0.06181 12.37     0.161    0.1648 ]\n",
      "185. [15.28     0.05375 17.8      0.3299   0.363  ]\n",
      "186. [1.008e+01 1.597e-03 1.187e+01 1.019e-01 6.920e-03]\n",
      "187. [18.31     0.08169 21.31     0.2445   0.3538 ]\n",
      "188. [11.71     0.03809 13.01     0.104    0.1521 ]\n",
      "189. [11.81     0.02353 12.57     0.1      0.08803]\n",
      "190. [12.3      0.03844 13.35     0.165    0.1423 ]\n",
      "191. [14.22     0.1981  15.74     0.62695  0.7855 ]\n",
      "192. [12.77     0.03112 13.75     0.08978  0.05186]\n",
      "193. [9.72    0.      9.968   0.02729 0.     ]\n",
      "194. [12.34    0.1085 15.65    0.4706  0.4425]\n",
      "195. [14.86    0.1697 16.08    0.4648  0.4589]\n",
      "196. [12.91     0.03873 13.88     0.1506   0.1764 ]\n",
      "197. [13.77    0.1385 16.39    0.3122  0.3809]\n",
      "198. [18.08    0.1103 19.76    0.1963  0.2535]\n",
      "199. [19.18    0.1114 23.36    0.5601  0.3865]\n",
      "200. [14.45    0.118  18.33    0.4056  0.4967]\n",
      "201. [12.23     0.04187 14.44     0.2042   0.1377 ]\n",
      "202. [17.54    0.1036 20.42    0.342   0.3508]\n",
      "203. [21.9      0.28241 25.12     0.4167   0.7855 ]\n",
      "204. [13.81    0.1558 19.2     0.5209  0.4646]\n",
      "205. [12.47     0.08005 14.97     0.2378   0.2671 ]\n",
      "206. [15.12    0.0755 17.77    0.3331  0.3327]\n",
      "207. [ 9.876    0.01756 10.42     0.1247   0.06213]\n",
      "208. [17.01    0.0695 19.8     0.1486  0.1932]\n",
      "209. [13.11     0.08705 14.55     0.4402   0.3162 ]\n",
      "210. [15.27     0.05892 17.38     0.2186   0.2962 ]\n",
      "211. [20.58    0.164  23.24    0.292   0.3861]\n",
      "212. [11.84     0.02669 13.3      0.188    0.1471 ]\n",
      "213. [21.9      0.28241 27.46     0.1516   0.3201 ]\n",
      "214. [17.42    0.1682 18.07    0.1793  0.2803]\n",
      "215. [14.19    0.1115 16.86    0.4059  0.3744]\n",
      "216. [13.86     0.09901 15.75     0.437    0.4636 ]\n",
      "217. [11.89     0.06636 13.25     0.3046   0.2806 ]\n",
      "218. [10.2      0.05774 11.48     0.1397   0.1925 ]\n",
      "219. [19.8     0.1272 25.73    0.3235  0.3617]\n",
      "220. [19.53    0.1145 27.46    0.4097  0.3995]\n",
      "221. [13.65     0.03888 15.34     0.2474   0.1759 ]\n",
      "222. [13.56    0.0786 14.98    0.2698  0.2577]\n",
      "223. [10.18     0.01768 11.17     0.144    0.06572]\n",
      "224. [15.75    0.1147 19.56    0.448   0.3976]\n",
      "225. [13.27     0.03554 15.14     0.1311   0.1786 ]\n",
      "226. [14.34     0.05724 16.77     0.1525   0.1632 ]\n",
      "227. [1.044e+01 6.643e-03 1.152e+01 1.153e-01 2.639e-02]\n",
      "228. [15.       0.06505 16.41     0.3627   0.3402 ]\n",
      "229. [12.62     0.05438 14.2      0.3454   0.3911 ]\n",
      "230. [12.83    0.1695 15.2     0.5343  0.6282]\n",
      "231. [17.05    0.191  19.59    0.3934  0.5018]\n",
      "232. [11.32     0.01633 12.08     0.1432   0.1089 ]\n",
      "233. [1.122e+01 4.967e-03 1.236e+01 6.885e-02 2.318e-02]\n",
      "234. [20.51    0.1554 24.47    0.2761  0.4146]\n",
      "235. [ 9.567    0.01652 10.51     0.09515  0.07161]\n",
      "236. [1.403e+01 1.462e-02 1.533e+01 1.513e-01 6.231e-02]\n",
      "237. [21.9     0.195  27.46    0.4126  0.582 ]\n",
      "238. [20.48     0.09042 24.22     0.2311   0.3158 ]\n",
      "239. [14.22    0.1103 15.75    0.2426  0.3064]\n",
      "240. [17.46    0.1417 22.51    0.3735  0.3241]\n",
      "241. [13.64     0.04705 14.85     0.1291   0.1533 ]\n",
      "242. [1.242e+01 1.053e-02 1.320e+01 7.776e-02 6.243e-02]\n",
      "243. [11.3     0.1548 12.58    0.4848  0.7436]\n",
      "244. [13.75     0.04697 15.01     0.1442   0.1359 ]\n",
      "245. [19.4     0.2049 21.65    0.2968  0.3458]\n",
      "246. [10.48     0.04831 11.48     0.1026   0.1181 ]\n",
      "247. [13.2      0.04336 13.94     0.1508   0.2298 ]\n",
      "248. [12.89    0.1374 14.39    0.5849  0.7727]\n",
      "249. [10.65     0.02379 12.25     0.1398   0.1125 ]\n",
      "250. [11.52     0.04328 12.65     0.1582   0.1804 ]\n",
      "251. [20.94    0.2712 25.58    0.3172  0.6991]\n",
      "252. [11.5      0.02638 12.97     0.1049   0.08105]\n",
      "253. [19.73    0.2417 25.28    0.5955  0.7855]\n",
      "254. [17.3     0.1266 19.85    0.2405  0.3378]\n",
      "255. [19.45    0.1379 25.7     0.3161  0.4317]\n",
      "256. [13.96     0.09789 16.39     0.3262   0.3209 ]\n",
      "257. [19.55    0.1784 25.05    0.5329  0.4251]\n",
      "258. [15.32    0.2448 17.73    0.4503  0.4429]\n",
      "259. [15.66     0.28241 19.85     0.5172   0.6181 ]\n",
      "260. [15.53    0.1751 18.49    0.5564  0.5703]\n",
      "261. [20.31    0.1519 24.33    0.2945  0.3788]\n",
      "262. [17.35     0.02891 19.85     0.1486   0.1211 ]\n",
      "263. [17.29     0.09697 20.39     0.2867   0.2298 ]\n",
      "264. [15.61     0.04209 17.91     0.1807   0.226  ]\n",
      "265. [17.19     0.09061 21.58     0.2567   0.3889 ]\n",
      "266. [20.73    0.1367 27.46    0.2644  0.3442]\n",
      "267. [10.6      0.06387 11.88     0.2515   0.1916 ]\n",
      "268. [13.59     0.04072 14.8      0.173    0.1453 ]\n",
      "269. [12.87    0.039  13.9     0.1808  0.1992]\n",
      "270. [10.71     0.08448 11.69     0.255    0.2534 ]\n",
      "271. [1.429e+01 7.250e-03 1.491e+01 5.036e-02 3.866e-02]\n",
      "272. [11.29     0.03265 12.32     0.1507   0.1275 ]\n",
      "273. [21.75    0.2195 27.46    0.4725  0.5807]\n",
      "274. [ 9.742    0.01103 10.75     0.0937   0.04043]\n",
      "275. [17.93     0.05699 20.92     0.1806   0.208  ]\n",
      "276. [11.89     0.05929 12.4      0.08368  0.07153]\n",
      "277. [1.133e+01 1.487e-03 1.220e+01 7.348e-02 4.955e-03]\n",
      "278. [18.81    0.0802 19.96    0.116   0.221 ]\n",
      "279. [13.59     0.01997 15.5      0.07622  0.106  ]\n",
      "280. [13.85     0.04479 14.98     0.1724   0.1456 ]\n",
      "281. [19.16    0.1921 23.72    0.3841  0.5754]\n",
      "282. [11.74     0.02245 13.31     0.085    0.06735]\n",
      "283. [19.4     0.1626 23.79    0.3749  0.4316]\n",
      "284. [16.24    0.1948 18.55    0.4706  0.5026]\n",
      "285. [12.89    0.1115 13.9     0.2317  0.3344]\n",
      "286. [1.258e+01 1.860e-03 1.350e+01 6.624e-02 5.579e-03]\n",
      "287. [11.94     0.06574 13.24     0.2813   0.2365 ]\n",
      "288. [12.89    0.0226 13.62    0.1147  0.1186]\n",
      "289. [11.26     0.09274 11.86     0.1843   0.1546 ]\n",
      "290. [11.37     0.02399 12.36     0.09708  0.07529]\n",
      "291. [14.41    0.1362 15.77    0.2472  0.222 ]\n",
      "292. [14.96    0.0594 16.25    0.303   0.1804]\n",
      "293. [12.95     0.06155 13.74     0.2068   0.2241 ]\n",
      "294. [11.85     0.02688 13.06     0.1758   0.1316 ]\n",
      "295. [1.272e+01 1.288e-02 1.350e+01 1.472e-01 5.233e-02]\n",
      "296. [1.377e+01 1.063e-02 1.467e+01 1.072e-01 3.732e-02]\n",
      "297. [10.91     0.01236 11.37     0.07506  0.02884]\n",
      "298. [11.76     0.02685 13.36     0.07974  0.0612 ]\n",
      "299. [14.26     0.02475 16.22     0.2167   0.1565 ]\n",
      "300. [10.51     0.02495 10.93     0.08614  0.04158]\n",
      "301. [19.53    0.2197 25.93    0.4116  0.6121]\n",
      "302. [12.46    0.0683 13.46    0.2158  0.1904]\n",
      "303. [20.09    0.2283 23.68    0.3391  0.4932]\n",
      "304. [10.49     0.02297 11.06     0.1044   0.08423]\n",
      "305. [11.46     0.03344 12.68     0.1789   0.1226 ]\n",
      "306. [11.6      0.01974 12.44     0.1361   0.07239]\n",
      "307. [1.320e+01 1.461e-03 1.441e+01 1.346e-01 1.120e-02]\n",
      "308. [9.000e+00 3.681e-03 9.699e+00 5.232e-02 1.472e-02]\n",
      "309. [1.350e+01 2.758e-03 1.497e+01 5.836e-02 1.379e-02]\n",
      "310. [1.305e+01 4.559e-03 1.473e+01 5.847e-02 1.824e-02]\n",
      "311. [11.7      0.01583 12.61     0.1087   0.07915]\n",
      "312. [1.461e+01 1.447e-02 1.646e+01 7.087e-02 4.746e-02]\n",
      "313. [12.76     0.04052 14.19     0.2208   0.1769 ]\n",
      "314. [11.54     0.01367 12.34     0.1626   0.08324]\n",
      "315. [8.597   0.      8.952   0.07767 0.     ]\n",
      "316. [1.249e+01 4.473e-03 1.334e+01 4.953e-02 1.938e-02]\n",
      "317. [1.218e+01 1.123e-02 1.285e+01 5.332e-02 4.116e-02]\n",
      "318. [18.22    0.113  21.84    0.2763  0.3853]\n",
      "319. [ 9.042   0.1975 10.06    0.3748  0.4609]\n",
      "320. [12.43     0.01342 12.9      0.04712  0.02237]\n",
      "321. [10.25     0.06726 11.28     0.236    0.1898 ]\n",
      "322. [20.16    0.1155 23.06    0.1537  0.2606]\n",
      "323. [12.86    0.038  14.04    0.2231  0.1791]\n",
      "324. [20.34    0.2565 25.3     0.4492  0.5344]\n",
      "325. [12.2      0.01994 13.75     0.1928   0.1167 ]\n",
      "326. [12.67     0.03193 13.71     0.1212   0.102  ]\n",
      "327. [14.11     0.01765 15.53     0.1109   0.05307]\n",
      "328. [1.203e+01 1.546e-03 1.307e+01 7.390e-02 7.732e-03]\n",
      "329. [16.27    0.1478 19.28    0.2947  0.3597]\n",
      "330. [16.26    0.1799 17.73    0.2116  0.3344]\n",
      "331. [16.03    0.1204 18.76    0.4478  0.4956]\n",
      "332. [12.98     0.07107 14.42     0.3253   0.3439 ]\n",
      "333. [1.122e+01 5.006e-03 1.198e+01 9.669e-02 1.335e-02]\n",
      "334. [1.125e+01 9.737e-04 1.276e+01 9.794e-02 5.518e-03]\n",
      "335. [1.230e+01 7.756e-03 1.335e+01 9.052e-02 3.619e-02]\n",
      "336. [17.06    0.1508 20.99    0.2053  0.392 ]\n",
      "337. [12.99     0.03738 13.72     0.1975   0.145  ]\n",
      "338. [18.77    0.106  24.54    0.4827  0.4634]\n",
      "339. [10.05     0.02511 11.16     0.1402   0.1055 ]\n",
      "340. [21.9     0.2308 27.46    0.2678  0.4819]\n",
      "341. [14.42     0.08007 16.67     0.3371   0.3755 ]\n",
      "342. [ 9.606    0.08422 10.75     0.3416   0.4341 ]\n",
      "343. [11.06     0.05397 11.92     0.221    0.2299 ]\n",
      "344. [19.68    0.1863 22.75    0.3458  0.4734]\n",
      "345. [11.71     0.04006 13.06     0.1115   0.1087 ]\n",
      "346. [10.26     0.03581 10.88     0.1636   0.07162]\n",
      "347. [1.206e+01 7.510e-03 1.364e+01 1.352e-01 4.506e-02]\n",
      "348. [14.76     0.04608 17.27     0.2009   0.2151 ]\n",
      "349. [11.47     0.02587 12.51     0.112    0.09823]\n",
      "350. [1.195e+01 1.171e-02 1.281e+01 1.885e-01 3.122e-02]\n",
      "351. [1.166e+01 8.306e-03 1.328e+01 6.476e-02 3.046e-02]\n",
      "352. [15.75     0.28241 17.36     0.5046   0.6872 ]\n",
      "353. [21.9      0.28241 27.46     0.5937   0.6451 ]\n",
      "354. [15.08    0.1235 18.51    0.2356  0.4029]\n",
      "355. [11.14     0.04505 12.12     0.1256   0.1201 ]\n",
      "356. [12.56    0.103  13.37    0.2002  0.2388]\n",
      "357. [13.05     0.09603 14.19     0.2658   0.2573 ]\n",
      "358. [1.387e+01 1.502e-02 1.511e+01 1.008e-01 5.285e-02]\n",
      "359. [8.878   0.04721 9.981   0.1248  0.09441]\n",
      "360. [ 9.436   0.0271 12.02    0.1049  0.1144]\n",
      "361. [1.254e+01 1.194e-03 1.372e+01 4.327e-02 3.581e-03]\n",
      "362. [13.3      0.03344 14.2      0.1667   0.1212 ]\n",
      "363. [12.76     0.02688 13.75     0.1839   0.1255 ]\n",
      "364. [16.5      0.05862 18.13     0.1679   0.1663 ]\n",
      "365. [13.4      0.02181 14.73     0.1676   0.1364 ]\n",
      "366. [20.44     0.09799 24.31     0.2376   0.2702 ]\n",
      "367. [20.2     0.1641 24.19    0.3416  0.3703]\n",
      "368. [12.21     0.04392 14.29     0.217    0.2413 ]\n",
      "369. [21.71    0.1168 27.46    0.1628  0.2861]\n",
      "370. [21.9     0.2448 27.46    0.3885  0.4756]\n",
      "371. [16.35    0.1811 19.38    0.4665  0.7087]\n",
      "372. [15.19     0.03393 16.2      0.1737   0.1362 ]\n",
      "373. [21.37    0.1932 22.69    0.284   0.4024]\n",
      "374. [20.64    0.1527 25.37    0.3055  0.4159]\n",
      "375. [13.69     0.02556 14.84     0.2096   0.1346 ]\n",
      "376. [16.17     0.06651 16.97     0.255    0.2114 ]\n",
      "377. [10.57    0.228  10.85    0.3619  0.603 ]\n",
      "378. [1.346e+01 1.271e-02 1.469e+01 1.457e-01 7.934e-02]\n",
      "379. [13.66     0.04249 14.54     0.3104   0.2569 ]\n",
      "380. [11.08     0.1689  13.24     0.62695  0.7855 ]\n",
      "381. [11.27    0.079  12.84    0.2429  0.2247]\n",
      "382. [11.04     0.03546 12.09     0.1982   0.1553 ]\n",
      "383. [12.05     0.07943 12.57     0.3214   0.2912 ]\n",
      "384. [12.39     0.05892 14.18     0.3593   0.3206 ]\n",
      "385. [13.28     0.05077 14.24     0.2685   0.2866 ]\n",
      "386. [14.6     0.0839 15.79    0.1581  0.2675]\n",
      "387. [12.21     0.06839 13.13     0.2431   0.3076 ]\n",
      "388. [13.88     0.02045 15.51     0.1233   0.1091 ]\n",
      "389. [11.27    0.1007 12.04    0.2809  0.3021]\n",
      "390. [19.55    0.1856 20.82    0.2414  0.3829]\n",
      "391. [10.26     0.01923 11.38     0.165    0.08615]\n",
      "392. [ 8.734  0.    10.17   0.131  0.   ]\n",
      "393. [15.49    0.1891 21.2     0.3913  0.5553]\n",
      "394. [21.61    0.281  26.23    0.5717  0.7053]\n",
      "395. [12.1      0.04783 13.56     0.1773   0.1603 ]\n",
      "396. [14.06     0.02681 14.92     0.1231   0.0846 ]\n",
      "397. [13.51    0.0858 14.8     0.257   0.3438]\n",
      "398. [12.8     0.0739 13.74    0.1812  0.1901]\n",
      "399. [11.06     0.02712 12.68     0.1879   0.2079 ]\n",
      "400. [11.8      0.02853 13.45     0.1726   0.1449 ]\n",
      "401. [17.91     0.28241 20.8      0.5917   0.7855 ]\n",
      "402. [11.93     0.02606 13.8      0.1575   0.1514 ]\n",
      "403. [12.96     0.04057 14.13     0.2318   0.1604 ]\n",
      "404. [12.94     0.03296 13.86     0.1958   0.181  ]\n",
      "405. [12.34     0.02109 13.18     0.06744  0.04921]\n",
      "406. [10.94     0.04944 12.4      0.1644   0.1412 ]\n",
      "407. [16.14    0.055  17.71    0.1722  0.231 ]\n",
      "408. [12.85     0.06126 14.4      0.1936   0.1838 ]\n",
      "409. [17.99    0.1201 21.08    0.3735  0.3301]\n",
      "410. [12.27     0.03211 14.1      0.1795   0.1377 ]\n",
      "411. [11.36     0.02783 13.05     0.1622   0.1811 ]\n",
      "412. [11.04     0.03046 12.41     0.1482   0.1067 ]\n",
      "413. [9.397   0.03735 9.965   0.1887  0.1868 ]\n",
      "414. [14.99     0.06859 16.76     0.3345   0.3114 ]\n",
      "415. [15.13     0.04686 17.26     0.09866  0.1547 ]\n",
      "416. [11.89     0.02555 13.05     0.2187   0.1164 ]\n",
      "417. [ 9.405    0.02047 10.85     0.1193   0.06141]\n",
      "418. [15.5     0.1522 23.17    0.4002  0.4211]\n",
      "419. [12.7      0.0236  13.65     0.1607   0.09385]\n",
      "420. [1.116e+01 8.955e-03 1.236e+01 1.108e-01 3.582e-02]\n",
      "421. [11.57     0.05485 13.07     0.1937   0.256  ]\n",
      "422. [14.69    0.145  16.46    0.3635  0.3219]\n",
      "423. [11.61     0.07097 12.64     0.217    0.2302 ]\n",
      "424. [13.66     0.09657 15.14     0.3167   0.366  ]\n",
      "425. [9.742e+00 8.934e-03 1.121e+01 1.352e-01 2.085e-02]\n",
      "426. [1.003e+01 2.470e-03 1.111e+01 7.094e-02 1.235e-02]\n",
      "427. [10.48     0.06335 12.13     0.2996   0.2939 ]\n",
      "428. [10.8      0.03614 12.76     0.1696   0.1927 ]\n",
      "429. [11.13     0.01369 11.68     0.06219  0.0458 ]\n",
      "430. [12.72     0.01402 13.82     0.09605  0.03469]\n",
      "431. [14.9      0.2733  16.35     0.62695  0.7855 ]\n",
      "432. [12.4      0.07741 12.88     0.2629   0.2403 ]\n",
      "433. [20.18    0.2133 22.03    0.2942  0.5308]\n",
      "434. [18.82    0.1594 22.66    0.3463  0.3912]\n",
      "435. [14.86     0.03346 16.31     0.155    0.122  ]\n",
      "436. [13.98    0.1126 17.04    0.3568  0.4069]\n",
      "437. [12.87     0.01797 14.45     0.1652   0.07127]\n",
      "438. [14.04     0.03534 15.66     0.1252   0.1117 ]\n",
      "439. [1.385e+01 1.342e-02 1.563e+01 1.141e-01 4.753e-02]\n",
      "440. [14.02     0.02087 14.91     0.1017   0.0626 ]\n",
      "441. [10.97     0.09457 12.36     0.4082   0.4779 ]\n",
      "442. [17.27    0.1204 20.38    0.4122  0.5036]\n",
      "443. [1.378e+01 1.055e-02 1.527e+01 1.071e-01 3.517e-02]\n",
      "444. [10.57     0.01993 10.94     0.06542  0.03986]\n",
      "445. [18.03    0.109  20.38    0.2666  0.429 ]\n",
      "446. [11.99     0.05441 12.98     0.1822   0.1609 ]\n",
      "447. [17.75    0.1698 21.53    0.3762  0.6399]\n",
      "448. [14.8      0.04069 16.43     0.1881   0.206  ]\n",
      "449. [14.53     0.08817 16.3      0.2649   0.3779 ]\n",
      "450. [21.1     0.1572 25.68    0.3101  0.4399]\n",
      "451. [11.87     0.08777 12.79     0.3399   0.3218 ]\n",
      "452. [19.59    0.1655 21.44    0.1845  0.3977]\n",
      "453. [12.       0.04055 13.09     0.1856   0.1811 ]\n",
      "454. [14.53     0.06895 15.8      0.1478   0.1373 ]\n",
      "455. [12.62     0.02966 14.34     0.1517   0.1887 ]\n",
      "456. [13.38     0.02819 15.05     0.1421   0.07003]\n",
      "457. [11.63    0.0716 13.12    0.2031  0.2923]\n",
      "458. [13.21     0.02772 14.35     0.1063   0.139  ]\n",
      "459. [1.300e+01 1.206e-02 1.434e+01 1.093e-01 4.462e-02]\n",
      "460. [ 9.755    0.01541 10.67     0.1109   0.0719 ]\n",
      "461. [17.08    0.1007 22.96    0.2444  0.2639]\n",
      "462. [21.9      0.28241 27.46     0.4256   0.6833 ]\n",
      "463. [14.4      0.03476 15.4      0.146    0.1472 ]\n",
      "464. [11.6      0.03367 12.77     0.1808   0.186  ]\n",
      "465. [13.17     0.04859 14.9      0.1965   0.1876 ]\n",
      "466. [13.24    0.101  15.44    0.5646  0.6556]\n",
      "467. [13.14    0.1085 14.8     0.3549  0.4504]\n",
      "468. [ 9.668    0.01479 11.15     0.1255   0.06409]\n",
      "469. [17.6     0.2136 21.57    0.4785  0.5165]\n",
      "470. [11.62    0.102  13.36    0.2878  0.3186]\n",
      "471. [ 9.667    0.02948 11.14     0.1542   0.1277 ]\n",
      "472. [12.04     0.02367 13.6      0.09726  0.05524]\n",
      "473. [14.92     0.05539 17.18     0.2791   0.3151 ]\n",
      "474. [12.27     0.      13.45     0.05213  0.     ]\n",
      "475. [10.88     0.05115 11.94     0.3898   0.3365 ]\n",
      "476. [12.83     0.05835 14.09     0.261    0.3476 ]\n",
      "477. [14.2      0.05063 16.45     0.3429   0.2512 ]\n",
      "478. [13.9      0.02224 15.14     0.2006   0.1384 ]\n",
      "479. [11.49     0.05308 12.4      0.201    0.2596 ]\n",
      "480. [16.25    0.2236 17.39    0.4462  0.5897]\n",
      "481. [12.16     0.02916 13.34     0.2279   0.162  ]\n",
      "482. [13.9      0.02995 16.41     0.1415   0.1673 ]\n",
      "483. [13.47     0.05786 14.83     0.2499   0.1848 ]\n",
      "484. [13.7      0.04548 14.96     0.1346   0.1742 ]\n",
      "485. [15.73    0.1191 17.01    0.2979  0.4004]\n",
      "486. [12.45    0.1544 13.78    0.4061  0.4896]\n",
      "487. [14.64     0.05192 16.46     0.207    0.2437 ]\n",
      "488. [19.44    0.2256 23.96    0.3725  0.5936]\n",
      "489. [11.68     0.04279 13.32     0.1477   0.149  ]\n",
      "490. [16.69     0.03649 19.18     0.292    0.2477 ]\n",
      "491. [12.25     0.01714 14.17     0.1804   0.123  ]\n",
      "492. [17.85     0.04445 19.82     0.09976  0.1048 ]\n",
      "493. [18.01    0.117  21.53    0.2327  0.2544]\n",
      "494. [1.246e+01 7.173e-03 1.319e+01 6.477e-02 1.674e-02]\n",
      "495. [13.16     0.018   14.5      0.1646   0.07698]\n",
      "496. [14.87     0.06824 16.01     0.1388   0.17   ]\n",
      "497. [12.65     0.08017 14.38     0.3842   0.3582 ]\n",
      "498. [12.47     0.03609 14.06     0.2506   0.2028 ]\n",
      "499. [18.49    0.1491 22.75    0.3089  0.3533]\n",
      "500. [20.59    0.2188 23.86    0.3597  0.5179]\n",
      "501. [15.04     0.07721 16.76     0.2176   0.1856 ]\n",
      "502. [13.82    0.1357 16.01    0.3966  0.3381]\n",
      "503. [12.54     0.05928 13.57     0.1751   0.1889 ]\n",
      "504. [21.9     0.1676 27.46    0.3625  0.3794]\n",
      "505. [ 9.268   0.0973 10.28    0.3441  0.2099]\n",
      "506. [ 9.676   0.1188 10.6     0.3663  0.2913]\n",
      "507. [12.22     0.08175 13.16     0.2315   0.3535 ]\n",
      "508. [11.06     0.04063 11.69     0.2031   0.1256 ]\n",
      "509. [16.3      0.05526 17.32     0.1361   0.1947 ]\n",
      "510. [15.46    0.203  17.11    0.4967  0.5911]\n",
      "511. [11.74     0.06726 12.45     0.2793   0.269  ]\n",
      "512. [14.81     0.03416 15.61     0.1011   0.1101 ]\n",
      "513. [13.4     0.1445 16.41    0.3856  0.5106]\n",
      "514. [14.58     0.08222 16.76     0.1928   0.2492 ]\n",
      "515. [15.05     0.07486 17.58     0.2101   0.2866 ]\n",
      "516. [11.34     0.04302 12.47     0.1574   0.1624 ]\n",
      "517. [18.31    0.1569 21.86    0.2536  0.3759]\n",
      "518. [19.89    0.1411 23.73    0.3309  0.4185]\n",
      "519. [12.88     0.04825 15.05     0.2961   0.1246 ]\n",
      "520. [12.75    0.0388 14.45    0.1979  0.1423]\n",
      "521. [ 9.295    0.03332 10.57     0.2097   0.09996]\n",
      "522. [21.9     0.231  27.46    0.4188  0.4658]\n",
      "523. [1.126e+01 5.067e-03 1.193e+01 7.723e-02 2.533e-02]\n",
      "524. [13.71     0.05385 15.11     0.2566   0.1935 ]\n",
      "525. [ 9.847    0.0233  11.24     0.2243   0.08434]\n",
      "526. [8.571   0.02565 9.473   0.2235  0.1754 ]\n",
      "527. [13.46     0.04201 15.35     0.3124   0.2654 ]\n",
      "528. [12.34     0.02958 13.61     0.2074   0.1791 ]\n",
      "529. [13.94    0.101  14.62    0.1364  0.1559]\n",
      "530. [12.07     0.03781 13.45     0.1632   0.1622 ]\n",
      "531. [11.75     0.05282 13.5      0.1854   0.1366 ]\n",
      "532. [11.67    0.042  13.35    0.2964  0.2758]\n",
      "533. [13.68     0.01752 15.85     0.1564   0.1206 ]\n",
      "534. [20.47    0.1523 23.23    0.2534  0.3092]\n",
      "535. [10.96     0.05263 11.62     0.251    0.2123 ]\n",
      "536. [20.55    0.2085 24.3     0.3135  0.4433]\n",
      "537. [14.27    0.1463 15.29    0.2733  0.4234]\n",
      "538. [11.69     0.04515 12.98     0.3251   0.1395 ]\n",
      "539. [7.729  0.     9.077  0.0834 0.    ]\n",
      "540. [7.691   0.09252 8.678   0.3064  0.3393 ]\n",
      "541. [11.54     0.06737 12.26     0.2118   0.1797 ]\n",
      "542. [14.47    0.1009 16.22    0.4202  0.404 ]\n",
      "543. [14.74     0.04105 16.51     0.1376   0.1611 ]\n",
      "544. [13.21     0.02987 14.37     0.1381   0.1062 ]\n",
      "545. [13.87     0.03688 15.05     0.2037   0.1377 ]\n",
      "546. [13.62     0.02974 15.35     0.1517   0.1049 ]\n",
      "547. [1.032e+01 1.012e-02 1.125e+01 8.842e-02 4.384e-02]\n",
      "548. [10.26     0.04358 10.83     0.2246   0.1783 ]\n",
      "549. [ 9.683    0.02337 10.93     0.09546  0.0935 ]\n",
      "550. [10.82     0.01548 13.03     0.1633   0.06194]\n",
      "551. [10.86     0.      11.66     0.07348  0.     ]\n",
      "552. [11.13     0.04824 12.02     0.1782   0.1564 ]\n",
      "553. [12.77     0.01997 13.87     0.1064   0.08653]\n",
      "554. [9.333   0.03996 9.845   0.08298 0.07993]\n",
      "555. [12.88     0.06195 13.89     0.162    0.2439 ]\n",
      "556. [10.29     0.05999 10.84     0.171    0.2    ]\n",
      "557. [1.016e+01 5.025e-03 1.065e+01 1.200e-01 1.005e-02]\n",
      "558. [ 9.423    0.      10.49     0.07158  0.     ]\n",
      "559. [14.59    0.1029 15.48    0.3171  0.3662]\n",
      "560. [11.51    0.1112 12.48    0.2517  0.363 ]\n",
      "561. [14.05     0.04462 15.3      0.2264   0.1326 ]\n",
      "562. [11.2      0.      11.92     0.05494  0.     ]\n",
      "563. [15.22     0.255   17.52     0.62695  0.7855 ]\n",
      "564. [20.92     0.28241 24.29     0.4186   0.6599 ]\n",
      "565. [21.56    0.2439 25.45    0.2113  0.4107]\n",
      "566. [20.13    0.144  23.69    0.1922  0.3215]\n",
      "567. [16.6      0.09251 18.98     0.3094   0.3403 ]\n",
      "568. [20.6      0.28241 25.74     0.62695  0.7855 ]\n",
      "569. [7.76    0.      9.456   0.06444 0.     ]\n",
      "\n",
      "Selected features for Classifier 2:\n",
      "1. [0.1622  0.62695 0.7119  0.2654  0.41915]\n",
      "2. [0.1238 0.1866 0.2416 0.186  0.275 ]\n",
      "3. [0.1444 0.4245 0.4504 0.243  0.3613]\n",
      "4. [0.1901  0.62695 0.6869  0.2575  0.41915]\n",
      "5. [0.1374 0.205  0.4    0.1625 0.2364]\n",
      "6. [0.1791 0.5249 0.5355 0.1741 0.3985]\n",
      "7. [0.1442 0.2576 0.3784 0.1932 0.3063]\n",
      "8. [0.1654 0.3682 0.2678 0.1556 0.3196]\n",
      "9. [0.1703  0.5401  0.539   0.206   0.41915]\n",
      "10. [0.1853  0.62695 0.7855  0.221   0.41915]\n",
      "11. [0.1181  0.1551  0.1459  0.09975 0.2948 ]\n",
      "12. [0.1396 0.5609 0.3965 0.181  0.3792]\n",
      "13. [0.1037 0.3903 0.3639 0.1767 0.3176]\n",
      "14. [0.1131 0.1924 0.2322 0.1119 0.2809]\n",
      "15. [0.1651  0.62695 0.6943  0.2208  0.3596 ]\n",
      "16. [0.1678  0.62695 0.7026  0.1712  0.41915]\n",
      "17. [0.1464 0.1871 0.2914 0.1609 0.3029]\n",
      "18. [0.1789 0.4233 0.4784 0.2073 0.3706]\n",
      "19. [0.1512 0.315  0.5372 0.2388 0.2768]\n",
      "20. [0.144  0.1773 0.239  0.1288 0.2977]\n",
      "21. [0.1312  0.2776  0.189   0.07283 0.3184 ]\n",
      "22. [0.1324  0.1148  0.08867 0.06227 0.245  ]\n",
      "23. [0.139   0.5954  0.6305  0.2393  0.41915]\n",
      "24. [0.1401 0.26   0.3155 0.2009 0.2822]\n",
      "25. [0.1805 0.3578 0.4695 0.2095 0.3613]\n",
      "26. [0.1545 0.3949 0.3853 0.255  0.4066]\n",
      "27. [0.1525  0.62695 0.5539  0.2701  0.41915]\n",
      "28. [0.1338 0.2117 0.3446 0.149  0.2341]\n",
      "29. [0.1641 0.611  0.6335 0.2024 0.4027]\n",
      "30. [0.1255 0.2812 0.2489 0.1456 0.2756]\n",
      "31. [0.1491 0.4257 0.6133 0.1848 0.3444]\n",
      "32. [0.1637  0.5775  0.6956  0.1546  0.41915]\n",
      "33. [0.1634 0.3559 0.5588 0.1847 0.353 ]\n",
      "34. [0.1509  0.62695 0.6091  0.1785  0.3672 ]\n",
      "35. [0.1446  0.5804  0.5274  0.1864  0.41915]\n",
      "36. [0.1563  0.3835  0.5409  0.1813  0.41915]\n",
      "37. [0.1446 0.4238 0.5186 0.1447 0.3591]\n",
      "38. [0.09701 0.04619 0.04833 0.05013 0.1987 ]\n",
      "39. [0.09387 0.05131 0.02398 0.02899 0.1565 ]\n",
      "40. [0.161  0.4225 0.503  0.2258 0.2807]\n",
      "41. [0.1094 0.2043 0.2085 0.1112 0.2994]\n",
      "42. [0.1901 0.2698 0.4023 0.1424 0.2964]\n",
      "43. [0.1247  0.62695 0.7242  0.2493  0.41915]\n",
      "44. [0.153  0.3724 0.3664 0.1492 0.3739]\n",
      "45. [0.1503 0.3904 0.3728 0.1607 0.3693]\n",
      "46. [0.1679 0.509  0.7345 0.2378 0.3799]\n",
      "47. [0.1297  0.1357  0.0688  0.02564 0.3105 ]\n",
      "48. [0.1786 0.4166 0.5006 0.2088 0.39  ]\n",
      "49. [0.1494  0.2156  0.305   0.06548 0.2747 ]\n",
      "50. [0.1162 0.1711 0.2282 0.1282 0.2871]\n",
      "51. [0.1085  0.08615 0.05523 0.03715 0.2433 ]\n",
      "52. [0.1089  0.1582  0.105   0.08586 0.2346 ]\n",
      "53. [0.1144  0.08906 0.09203 0.06296 0.2785 ]\n",
      "54. [0.128  0.2297 0.2623 0.1325 0.3021]\n",
      "55. [0.1389 0.2057 0.2712 0.153  0.2675]\n",
      "56. [0.1249  0.0872  0.09076 0.06316 0.3306 ]\n",
      "57. [0.1624 0.3511 0.3879 0.2091 0.3537]\n",
      "58. [0.1368 0.429  0.3587 0.1834 0.3698]\n",
      "59. [0.1021   0.06191  0.001845 0.01111  0.2439  ]\n",
      "60. [0.1733  0.1239  0.1168  0.04419 0.322  ]\n",
      "61. [0.1275  0.09866 0.02168 0.02579 0.3557 ]\n",
      "62. [0.1639  0.1698  0.09001 0.02778 0.2972 ]\n",
      "63. [0.164  0.6247 0.6922 0.1785 0.2844]\n",
      "64. [0.09836 0.1678  0.1397  0.05087 0.3282 ]\n",
      "65. [0.1851 0.4061 0.4024 0.1716 0.3383]\n",
      "66. [0.1648 0.3416 0.3024 0.1614 0.3321]\n",
      "67. [0.1548  0.1664  0.09412 0.06517 0.2878 ]\n",
      "68. [0.129   0.09148 0.1444  0.06961 0.24   ]\n",
      "69. [0.1482  0.4365  0.7855  0.175   0.41915]\n",
      "70. [0.1296  0.07061 0.1039  0.05882 0.2383 ]\n",
      "71. [0.1193 0.2336 0.2687 0.1789 0.2551]\n",
      "72. [0.1207  0.2436  0.1434  0.04786 0.2254 ]\n",
      "73. [0.1585  0.62695 0.6566  0.1899  0.3313 ]\n",
      "74. [0.1411 0.3542 0.2779 0.1383 0.2589]\n",
      "75. [0.1176 0.1843 0.1703 0.0866 0.2618]\n",
      "76. [0.15   0.2045 0.2829 0.152  0.265 ]\n",
      "77. [0.1451  0.1379  0.08539 0.07407 0.271  ]\n",
      "78. [0.1478 0.5634 0.3786 0.2102 0.3751]\n",
      "79. [0.1639  0.6164  0.7681  0.2508  0.41915]\n",
      "80. [0.1289  0.2141  0.1731  0.07926 0.2779 ]\n",
      "81. [0.1557  0.1676  0.1755  0.06127 0.2762 ]\n",
      "82. [0.1536 0.4791 0.4858 0.1708 0.3527]\n",
      "83. [0.1573 0.6076 0.6476 0.2867 0.2355]\n",
      "84. [0.1392 0.2817 0.2432 0.1841 0.2311]\n",
      "85. [0.1377  0.2003  0.2267  0.07632 0.3379 ]\n",
      "86. [0.1398 0.2089 0.3157 0.1642 0.3695]\n",
      "87. [0.1306 0.1976 0.3349 0.1225 0.302 ]\n",
      "88. [0.1249 0.3206 0.5755 0.1956 0.3956]\n",
      "89. [0.1304 0.2463 0.2434 0.1205 0.2972]\n",
      "90. [0.1277 0.3089 0.2604 0.1397 0.3151]\n",
      "91. [0.1115  0.1766  0.09189 0.06946 0.2522 ]\n",
      "92. [0.1257 0.1997 0.2846 0.1476 0.2556]\n",
      "93. [0.1006 0.1238 0.135  0.1001 0.2027]\n",
      "94. [0.1339  0.1751  0.1381  0.07911 0.2678 ]\n",
      "95. [0.1551 0.4203 0.5203 0.2115 0.2834]\n",
      "96. [0.119  0.3539 0.4098 0.1573 0.3689]\n",
      "97. [0.114   0.09358 0.0498  0.05882 0.2227 ]\n",
      "98. [0.1316  0.09473 0.02049 0.02381 0.1934 ]\n",
      "99. [0.1431  0.1851  0.1922  0.08449 0.2772 ]\n",
      "100. [0.1431 0.3026 0.3194 0.1565 0.2718]\n",
      "101. [0.1265 0.1943 0.3169 0.1184 0.2651]\n",
      "102. [0.1584 0.1202 0.     0.     0.2932]\n",
      "103. [0.1123  0.08862 0.1145  0.07431 0.2694 ]\n",
      "104. [0.1559  0.2302  0.2644  0.09749 0.2622 ]\n",
      "105. [0.1219  0.1486  0.07987 0.03203 0.2826 ]\n",
      "106. [0.1862 0.4099 0.6376 0.1986 0.3147]\n",
      "107. [0.1688 0.266  0.2873 0.1218 0.2806]\n",
      "108. [0.1184  0.1963  0.1937  0.08442 0.2983 ]\n",
      "109. [0.1701  0.62695 0.7855  0.291   0.4055 ]\n",
      "110. [0.1699  0.2196  0.312   0.08278 0.2829 ]\n",
      "111. [0.1467  0.1765  0.13    0.05334 0.2533 ]\n",
      "112. [0.1287 0.225  0.2216 0.1105 0.2226]\n",
      "113. [0.08949 0.4193  0.6783  0.1505  0.2398 ]\n",
      "114. [0.13    0.2049  0.1295  0.06136 0.2383 ]\n",
      "115. [0.1724 0.2364 0.2456 0.105  0.2926]\n",
      "116. [0.15    0.2399  0.1503  0.07247 0.2438 ]\n",
      "117. [0.1179  0.1879  0.1544  0.03846 0.1652 ]\n",
      "118. [0.1878 0.448  0.4704 0.2027 0.3585]\n",
      "119. [0.1855 0.4925 0.7356 0.2034 0.3274]\n",
      "120. [0.1072  0.1202  0.2249  0.1185  0.41915]\n",
      "121. [0.1548  0.239   0.2102  0.08958 0.3016 ]\n",
      "122. [0.1503 0.2291 0.3272 0.1674 0.2894]\n",
      "123. [0.1696 0.4244 0.5803 0.2248 0.3222]\n",
      "124. [0.1313 0.1788 0.256  0.1221 0.2889]\n",
      "125. [0.1025  0.2531  0.3308  0.08978 0.2048 ]\n",
      "126. [0.1157  0.135   0.08115 0.05104 0.2364 ]\n",
      "127. [0.1471 0.2884 0.3796 0.1329 0.347 ]\n",
      "128. [0.1021 0.2264 0.3207 0.1218 0.2841]\n",
      "129. [0.1386 0.2883 0.196  0.1423 0.259 ]\n",
      "130. [0.1275 0.3861 0.5673 0.1732 0.3305]\n",
      "131. [0.1427  0.2585  0.09915 0.08187 0.3469 ]\n",
      "132. [0.1546 0.2394 0.3791 0.1514 0.2837]\n",
      "133. [0.1395 0.3055 0.2992 0.1312 0.348 ]\n",
      "134. [0.1223 0.1949 0.1709 0.1374 0.2723]\n",
      "135. [0.1465 0.2275 0.3965 0.1379 0.3109]\n",
      "136. [0.1419  0.1523  0.2177  0.09331 0.2829 ]\n",
      "137. [0.1271  0.1028  0.1046  0.06968 0.1712 ]\n",
      "138. [0.119   0.1648  0.1399  0.08476 0.2676 ]\n",
      "139. [0.1411 0.2164 0.3355 0.1667 0.3414]\n",
      "140. [0.1367  0.1822  0.08669 0.08611 0.2102 ]\n",
      "141. [0.1234  0.07204 0.      0.      0.3105 ]\n",
      "142. [0.1314 0.2236 0.2802 0.1216 0.2792]\n",
      "143. [0.1413  0.1792  0.07708 0.06402 0.2584 ]\n",
      "144. [0.1312 0.2548 0.209  0.1012 0.3549]\n",
      "145. [0.1076  0.1223  0.09755 0.03413 0.23   ]\n",
      "146. [0.1424  0.2517  0.0942  0.06042 0.2727 ]\n",
      "147. [0.1385  0.4092  0.4504  0.1865  0.41915]\n",
      "148. [0.0997  0.2521  0.25    0.08405 0.2852 ]\n",
      "149. [0.1316 0.2735 0.3103 0.1599 0.2691]\n",
      "150. [0.09711 0.1824  0.1564  0.06019 0.235  ]\n",
      "151. [0.1297  0.1105  0.08112 0.06296 0.3196 ]\n",
      "152. [0.163   0.431   0.5381  0.07879 0.3322 ]\n",
      "153. [0.1292 0.2772 0.7855 0.1571 0.3108]\n",
      "154. [0.1341  0.08971 0.07116 0.05506 0.2859 ]\n",
      "155. [0.1478  0.2256  0.3009  0.09722 0.3849 ]\n",
      "156. [0.1217  0.1788  0.1943  0.08211 0.3113 ]\n",
      "157. [0.1418 0.3498 0.3583 0.1515 0.2463]\n",
      "158. [0.08774 0.171   0.1882  0.08436 0.2527 ]\n",
      "159. [0.1275  0.1232  0.08636 0.07025 0.2514 ]\n",
      "160. [0.1171  0.08294 0.01854 0.03953 0.2738 ]\n",
      "161. [0.1358  0.1892  0.1956  0.07909 0.3168 ]\n",
      "162. [0.1124 0.2016 0.2264 0.1777 0.2443]\n",
      "163. [0.1438 0.3846 0.681  0.2247 0.3643]\n",
      "164. [0.1452  0.2338  0.1688  0.08194 0.2268 ]\n",
      "165. [0.1228 0.3583 0.3948 0.2346 0.3589]\n",
      "166. [0.1045  0.09995 0.0775  0.05754 0.2646 ]\n",
      "167. [0.1436  0.1257  0.1047  0.04603 0.209  ]\n",
      "168. [0.1168 0.2119 0.2318 0.1474 0.281 ]\n",
      "169. [0.1376 0.383  0.489  0.1721 0.216 ]\n",
      "170. [0.1216  0.1637  0.06648 0.08485 0.2404 ]\n",
      "171. [0.1385  0.1266  0.1242  0.09391 0.2827 ]\n",
      "172. [0.1401 0.1546 0.2644 0.116  0.2884]\n",
      "173. [0.1531 0.3583 0.583  0.1827 0.3216]\n",
      "174. [0.1216  0.0824  0.03938 0.04306 0.1902 ]\n",
      "175. [0.1076  0.06791 0.      0.      0.271  ]\n",
      "176. [0.1162  0.07057 0.      0.      0.2592 ]\n",
      "177. [0.1301 0.295  0.3486 0.0991 0.2614]\n",
      "178. [0.1415 0.4667 0.5862 0.2035 0.3054]\n",
      "179. [0.08125  0.03432  0.007977 0.009259 0.2295  ]\n",
      "180. [0.1162  0.05445 0.02758 0.0399  0.1783 ]\n",
      "181. [0.1472 0.4034 0.534  0.2688 0.2856]\n",
      "182. [0.1491  0.62695 0.678   0.2903  0.4098 ]\n",
      "183. [0.1414 0.3547 0.2902 0.1541 0.3437]\n",
      "184. [0.1121  0.161   0.1648  0.06296 0.1811 ]\n",
      "185. [0.1301 0.3299 0.363  0.1226 0.3175]\n",
      "186. [0.1521  0.1019  0.00692 0.01042 0.2933 ]\n",
      "187. [0.1234 0.2445 0.3538 0.1571 0.3206]\n",
      "188. [0.1323 0.104  0.1521 0.1099 0.2572]\n",
      "189. [0.1356  0.1     0.08803 0.04306 0.32   ]\n",
      "190. [0.1096  0.165   0.1423  0.04815 0.2482 ]\n",
      "191. [0.1533  0.62695 0.7855  0.1772  0.41915]\n",
      "192. [0.09388 0.08978 0.05186 0.04773 0.2179 ]\n",
      "193. [0.0725  0.02729 0.      0.      0.1909 ]\n",
      "194. [0.1785 0.4706 0.4425 0.1459 0.3215]\n",
      "195. [0.1316 0.4648 0.4589 0.1727 0.3   ]\n",
      "196. [0.1097  0.1506  0.1764  0.08235 0.3024 ]\n",
      "197. [0.1737 0.3122 0.3809 0.1673 0.308 ]\n",
      "198. [0.08822 0.1963  0.2535  0.09181 0.2369 ]\n",
      "199. [0.1322 0.5601 0.3865 0.1708 0.3193]\n",
      "200. [0.1552  0.4056  0.4967  0.1838  0.41915]\n",
      "201. [0.1429 0.2042 0.1377 0.108  0.2668]\n",
      "202. [0.1381 0.342  0.3508 0.1939 0.2928]\n",
      "203. [0.1536 0.4167 0.7855 0.2733 0.3198]\n",
      "204. [0.1901  0.5209  0.4646  0.2013  0.41915]\n",
      "205. [0.1426 0.2378 0.2671 0.1015 0.3014]\n",
      "206. [0.1491 0.3331 0.3327 0.1252 0.3415]\n",
      "207. [0.1415  0.1247  0.06213 0.05588 0.2989 ]\n",
      "208. [0.1111 0.1486 0.1932 0.1096 0.3275]\n",
      "209. [0.1349 0.4402 0.3162 0.1126 0.4128]\n",
      "210. [0.1222 0.2186 0.2962 0.1035 0.232 ]\n",
      "211. [0.1178 0.292  0.3861 0.192  0.2909]\n",
      "212. [0.128   0.188   0.1471  0.06913 0.2535 ]\n",
      "213. [0.1142 0.1516 0.3201 0.1595 0.1648]\n",
      "214. [0.1243 0.1793 0.2803 0.1099 0.1603]\n",
      "215. [0.1559  0.4059  0.3744  0.1772  0.41915]\n",
      "216. [0.146  0.437  0.4636 0.1654 0.363 ]\n",
      "217. [0.1405 0.3046 0.2806 0.1138 0.3397]\n",
      "218. [0.09527 0.1397  0.1925  0.03571 0.2868 ]\n",
      "219. [0.1353 0.3235 0.3617 0.182  0.307 ]\n",
      "220. [0.1408 0.4097 0.3995 0.1625 0.2713]\n",
      "221. [0.1311  0.2474  0.1759  0.08056 0.238  ]\n",
      "222. [0.1376 0.2698 0.2577 0.0909 0.3065]\n",
      "223. [0.1406  0.144   0.06572 0.05575 0.3055 ]\n",
      "224. [0.1552 0.448  0.3976 0.1479 0.3993]\n",
      "225. [0.1276  0.1311  0.1786  0.09678 0.2506 ]\n",
      "226. [0.1297 0.1525 0.1632 0.1087 0.3062]\n",
      "227. [0.1341  0.1153  0.02639 0.04464 0.2615 ]\n",
      "228. [0.1136 0.3627 0.3402 0.1379 0.2954]\n",
      "229. [0.1227 0.3454 0.3911 0.118  0.2826]\n",
      "230. [0.1777 0.5343 0.6282 0.1977 0.3407]\n",
      "231. [0.1703 0.3934 0.5018 0.2543 0.3109]\n",
      "232. [0.09203 0.1432  0.1089  0.02083 0.2849 ]\n",
      "233. [0.09994 0.06885 0.02318 0.03002 0.2911 ]\n",
      "234. [0.1223 0.2761 0.4146 0.1563 0.2437]\n",
      "235. [0.1504  0.09515 0.07161 0.07222 0.2757 ]\n",
      "236. [0.1287  0.1513  0.06231 0.07963 0.2226 ]\n",
      "237. [0.1481 0.4126 0.582  0.2593 0.3103]\n",
      "238. [0.1228 0.2311 0.3158 0.1445 0.2238]\n",
      "239. [0.1081  0.2426  0.3064  0.08219 0.189  ]\n",
      "240. [0.1365 0.3735 0.3241 0.2066 0.2853]\n",
      "241. [0.1278  0.1291  0.1533  0.09222 0.253  ]\n",
      "242. [0.1037  0.07776 0.06243 0.04052 0.2901 ]\n",
      "243. [0.1347 0.4848 0.7436 0.1218 0.3308]\n",
      "244. [0.09368 0.1442  0.1359  0.06106 0.2663 ]\n",
      "245. [0.1463 0.2968 0.3458 0.1564 0.292 ]\n",
      "246. [0.1515  0.1026  0.1181  0.06736 0.2883 ]\n",
      "247. [0.1101 0.1508 0.2298 0.0497 0.2767]\n",
      "248. [0.1254 0.5849 0.7727 0.1561 0.2639]\n",
      "249. [0.1499  0.1398  0.1125  0.06136 0.3409 ]\n",
      "250. [0.1389  0.1582  0.1804  0.09608 0.2664 ]\n",
      "251. [0.1211 0.3172 0.6991 0.2105 0.3126]\n",
      "252. [0.1183  0.1049  0.08105 0.06544 0.274  ]\n",
      "253. [0.171  0.5955 0.7855 0.2507 0.2749]\n",
      "254. [0.1416 0.2405 0.3378 0.1857 0.3138]\n",
      "255. [0.1497 0.3161 0.4317 0.1999 0.3379]\n",
      "256. [0.1512 0.3262 0.3209 0.1374 0.3068]\n",
      "257. [0.1281 0.5329 0.4251 0.1941 0.2818]\n",
      "258. [0.1765 0.4503 0.4429 0.2229 0.3258]\n",
      "259. [0.1504 0.5172 0.6181 0.2462 0.3277]\n",
      "260. [0.1883 0.5564 0.5703 0.2014 0.3512]\n",
      "261. [0.1522 0.2945 0.3788 0.1697 0.3151]\n",
      "262. [0.124   0.1486  0.1211  0.08235 0.2452 ]\n",
      "263. [0.1134 0.2867 0.2298 0.1528 0.3067]\n",
      "264. [0.1084  0.1807  0.226   0.08568 0.2683 ]\n",
      "265. [0.1558 0.2567 0.3889 0.1984 0.3216]\n",
      "266. [0.1401 0.2644 0.3442 0.1659 0.2868]\n",
      "267. [0.1213  0.2515  0.1916  0.07926 0.294  ]\n",
      "268. [0.1005  0.173   0.1453  0.06189 0.2446 ]\n",
      "269. [0.1256 0.1808 0.1992 0.0578 0.3604]\n",
      "270. [0.1335 0.255  0.2534 0.086  0.2605]\n",
      "271. [0.08567 0.05036 0.03866 0.03333 0.2458 ]\n",
      "272. [0.1358 0.1507 0.1275 0.0875 0.2733]\n",
      "273. [0.1272 0.4725 0.5807 0.1841 0.2833]\n",
      "274. [0.1467  0.0937  0.04043 0.05159 0.2841 ]\n",
      "275. [0.1315 0.1806 0.208  0.1136 0.2504]\n",
      "276. [0.1359  0.08368 0.07153 0.08946 0.222  ]\n",
      "277. [0.1259   0.07348  0.004955 0.01111  0.2758  ]\n",
      "278. [0.1243 0.116  0.221  0.1294 0.2567]\n",
      "279. [0.105   0.07622 0.106   0.05185 0.2335 ]\n",
      "280. [0.1185  0.1724  0.1456  0.09993 0.2955 ]\n",
      "281. [0.1782 0.3841 0.5754 0.1872 0.3258]\n",
      "282. [0.1036  0.085   0.06735 0.0829  0.3101 ]\n",
      "283. [0.1518 0.3749 0.4316 0.2252 0.359 ]\n",
      "284. [0.1365 0.4706 0.5026 0.1732 0.277 ]\n",
      "285. [0.09926 0.2317  0.3344  0.1017  0.1999 ]\n",
      "286. [0.1038   0.06624  0.005579 0.008772 0.2505  ]\n",
      "287. [0.1116 0.2813 0.2365 0.1155 0.2465]\n",
      "288. [0.09616 0.1147  0.1186  0.05366 0.2309 ]\n",
      "289. [0.1028  0.1843  0.1546  0.09314 0.2955 ]\n",
      "290. [0.1118  0.09708 0.07529 0.06203 0.3267 ]\n",
      "291. [0.09983 0.2472  0.222   0.1021  0.2272 ]\n",
      "292. [0.1313 0.303  0.1804 0.1489 0.2962]\n",
      "293. [0.1483 0.2068 0.2241 0.1056 0.338 ]\n",
      "294. [0.1369 0.1758 0.1316 0.0914 0.3101]\n",
      "295. [0.1298  0.1472  0.05233 0.06343 0.2369 ]\n",
      "296. [0.117   0.1072  0.03732 0.05802 0.2823 ]\n",
      "297. [0.09312 0.07506 0.02884 0.03194 0.2143 ]\n",
      "298. [0.1137  0.07974 0.0612  0.0716  0.1978 ]\n",
      "299. [0.09445 0.2167  0.1565  0.0753  0.2636 ]\n",
      "300. [0.1143  0.08614 0.04158 0.03125 0.2227 ]\n",
      "301. [0.1495 0.4116 0.6121 0.198  0.2968]\n",
      "302. [0.105   0.2158  0.1904  0.07625 0.2685 ]\n",
      "303. [0.1347 0.3391 0.4932 0.1923 0.3294]\n",
      "304. [0.1413  0.1044  0.08423 0.06528 0.2213 ]\n",
      "305. [0.1144  0.1789  0.1226  0.05509 0.2208 ]\n",
      "306. [0.09545 0.1361  0.07239 0.04815 0.3244 ]\n",
      "307. [0.1128 0.1346 0.0112 0.025  0.2651]\n",
      "308. [0.09861 0.05232 0.01472 0.01389 0.2991 ]\n",
      "309. [0.09023 0.05836 0.01379 0.0221  0.2267 ]\n",
      "310. [0.1016  0.05847 0.01824 0.03532 0.2107 ]\n",
      "311. [0.1223  0.1087  0.07915 0.05741 0.3487 ]\n",
      "312. [0.1011  0.07087 0.04746 0.05813 0.253  ]\n",
      "313. [0.1194  0.2208  0.1769  0.08411 0.2564 ]\n",
      "314. [0.1092  0.1626  0.08324 0.04715 0.339  ]\n",
      "315. [0.1347  0.07767 0.      0.      0.3142 ]\n",
      "316. [0.1104  0.04953 0.01938 0.02784 0.1917 ]\n",
      "317. [0.1001  0.05332 0.04116 0.01852 0.2293 ]\n",
      "318. [0.1434 0.2763 0.3853 0.1776 0.2812]\n",
      "319. [0.1221 0.3748 0.4609 0.1145 0.3135]\n",
      "320. [0.08409 0.04712 0.02237 0.02832 0.1901 ]\n",
      "321. [0.1402  0.236   0.1898  0.09744 0.2608 ]\n",
      "322. [0.1054 0.1537 0.2606 0.1425 0.3055]\n",
      "323. [0.1547 0.2231 0.1791 0.1155 0.2382]\n",
      "324. [0.1592  0.4492  0.5344  0.2685  0.41915]\n",
      "325. [0.1256  0.1928  0.1167  0.05556 0.2661 ]\n",
      "326. [0.1384  0.1212  0.102   0.05602 0.2688 ]\n",
      "327. [0.1281  0.1109  0.05307 0.0589  0.21   ]\n",
      "328. [0.1013   0.0739   0.007732 0.02796  0.2171  ]\n",
      "329. [0.159  0.2947 0.3597 0.1583 0.3103]\n",
      "330. [0.1426 0.2116 0.3344 0.1047 0.2736]\n",
      "331. [0.1435 0.4478 0.4956 0.1981 0.3019]\n",
      "332. [0.1288  0.3253  0.3439  0.09858 0.3596 ]\n",
      "333. [0.1424  0.09669 0.01335 0.02022 0.3292 ]\n",
      "334. [0.1166   0.09794  0.005518 0.01667  0.2815  ]\n",
      "335. [0.1222  0.09052 0.03619 0.03983 0.2554 ]\n",
      "336. [0.1449 0.2053 0.392  0.1827 0.2623]\n",
      "337. [0.1142 0.1975 0.145  0.0585 0.2432]\n",
      "338. [0.1498 0.4827 0.4634 0.2048 0.3679]\n",
      "339. [0.1402  0.1402  0.1055  0.06499 0.2894 ]\n",
      "340. [0.1515 0.2678 0.4819 0.2089 0.2593]\n",
      "341. [0.1294 0.3371 0.3755 0.1414 0.3053]\n",
      "342. [0.1233 0.3416 0.4341 0.0812 0.2982]\n",
      "343. [0.1418 0.221  0.2299 0.1075 0.3301]\n",
      "344. [0.1218 0.3458 0.4734 0.2255 0.4045]\n",
      "345. [0.146   0.1115  0.1087  0.07864 0.2765 ]\n",
      "346. [0.136   0.1636  0.07162 0.04074 0.2434 ]\n",
      "347. [0.1289  0.1352  0.04506 0.05093 0.288  ]\n",
      "348. [0.122  0.2009 0.2151 0.1251 0.3109]\n",
      "349. [0.1531  0.112   0.09823 0.06548 0.2851 ]\n",
      "350. [0.1293  0.1885  0.03122 0.04766 0.3124 ]\n",
      "351. [0.09958 0.06476 0.03046 0.04262 0.2731 ]\n",
      "352. [0.155   0.5046  0.6872  0.2135  0.41915]\n",
      "353. [0.153  0.5937 0.6451 0.2756 0.369 ]\n",
      "354. [0.166  0.2356 0.4029 0.1526 0.2654]\n",
      "355. [0.08864 0.1256  0.1201  0.03922 0.2576 ]\n",
      "356. [0.1096  0.2002  0.2388  0.09265 0.2121 ]\n",
      "357. [0.1343 0.2658 0.2573 0.1258 0.3113]\n",
      "358. [0.1153  0.1008  0.05285 0.05556 0.2362 ]\n",
      "359. [0.1015  0.1248  0.09441 0.04762 0.2434 ]\n",
      "360. [0.1333  0.1049  0.1144  0.05052 0.2454 ]\n",
      "361. [0.09293  0.04327  0.003581 0.01635  0.2233  ]\n",
      "362. [0.114   0.1667  0.1212  0.05614 0.2637 ]\n",
      "363. [0.1298  0.1839  0.1255  0.08312 0.2744 ]\n",
      "364. [0.1338  0.1679  0.1663  0.09123 0.2394 ]\n",
      "365. [0.1213  0.1676  0.1364  0.06987 0.2741 ]\n",
      "366. [0.1327 0.2376 0.2702 0.1765 0.2609]\n",
      "367. [0.1278 0.3416 0.3703 0.2152 0.3271]\n",
      "368. [0.1368  0.217   0.2413  0.08829 0.3218 ]\n",
      "369. [0.1363 0.1628 0.2861 0.182  0.251 ]\n",
      "370. [0.1294 0.3885 0.4756 0.2432 0.2741]\n",
      "371. [0.1415  0.4665  0.7087  0.2248  0.41915]\n",
      "372. [0.1126  0.1737  0.1362  0.08178 0.2487 ]\n",
      "373. [0.1192 0.284  0.4024 0.1966 0.273 ]\n",
      "374. [0.1562 0.3055 0.4159 0.2112 0.2689]\n",
      "375. [0.1105  0.2096  0.1346  0.06987 0.3323 ]\n",
      "376. [0.1235 0.255  0.2114 0.1251 0.3153]\n",
      "377. [0.1143 0.3619 0.603  0.1465 0.2597]\n",
      "378. [0.1108  0.1457  0.07934 0.05781 0.2694 ]\n",
      "379. [0.1275 0.3104 0.2569 0.1054 0.3387]\n",
      "380. [0.1901  0.62695 0.7855  0.2524  0.4154 ]\n",
      "381. [0.161  0.2429 0.2247 0.1318 0.3343]\n",
      "382. [0.1095  0.1982  0.1553  0.06754 0.3202 ]\n",
      "383. [0.08799 0.3214  0.2912  0.1092  0.2191 ]\n",
      "384. [0.1427  0.3593  0.3206  0.09804 0.2819 ]\n",
      "385. [0.1166  0.2685  0.2866  0.09173 0.2736 ]\n",
      "386. [0.1312 0.1581 0.2675 0.1359 0.2477]\n",
      "387. [0.1026 0.2431 0.3076 0.0914 0.2677]\n",
      "388. [0.08484 0.1233  0.1091  0.04537 0.2542 ]\n",
      "389. [0.1102  0.2809  0.3021  0.08272 0.2157 ]\n",
      "390. [0.1251 0.2414 0.3829 0.1825 0.2576]\n",
      "391. [0.1343  0.165   0.08615 0.06696 0.2937 ]\n",
      "392. [0.146  0.131  0.     0.     0.2445]\n",
      "393. [0.1681 0.3913 0.5553 0.2121 0.3187]\n",
      "394. [0.1502 0.5717 0.7053 0.2422 0.3828]\n",
      "395. [0.1432  0.1773  0.1603  0.06266 0.3049 ]\n",
      "396. [0.1066  0.1231  0.0846  0.07911 0.2523 ]\n",
      "397. [0.1428 0.257  0.3438 0.1453 0.2666]\n",
      "398. [0.09534 0.1812  0.1901  0.08296 0.1988 ]\n",
      "399. [0.112   0.1879  0.2079  0.05556 0.259  ]\n",
      "400. [0.1244  0.1726  0.1449  0.05356 0.2779 ]\n",
      "401. [0.1873 0.5917 0.7855 0.1964 0.3245]\n",
      "402. [0.1374  0.1575  0.1514  0.06876 0.246  ]\n",
      "403. [0.09329 0.2318  0.1604  0.06608 0.3207 ]\n",
      "404. [0.1172  0.1958  0.181   0.08388 0.3297 ]\n",
      "405. [0.1048  0.06744 0.04921 0.04793 0.2298 ]\n",
      "406. [0.1363  0.1644  0.1412  0.07887 0.2251 ]\n",
      "407. [0.1206 0.1722 0.231  0.1129 0.2778]\n",
      "408. [0.09402 0.1936  0.1838  0.05601 0.2488 ]\n",
      "409. [0.1482 0.3735 0.3301 0.1974 0.306 ]\n",
      "410. [0.124   0.1795  0.1377  0.09532 0.3455 ]\n",
      "411. [0.1453  0.1622  0.1811  0.08698 0.2973 ]\n",
      "412. [0.1369  0.1482  0.1067  0.07431 0.2998 ]\n",
      "413. [0.1086  0.1887  0.1868  0.02564 0.2376 ]\n",
      "414. [0.1077 0.3345 0.3114 0.1308 0.3163]\n",
      "415. [0.1148  0.09866 0.1547  0.06575 0.3233 ]\n",
      "416. [0.1426  0.2187  0.1164  0.08263 0.3075 ]\n",
      "417. [0.1526  0.1193  0.06141 0.0377  0.2872 ]\n",
      "418. [0.1517 0.4002 0.4211 0.2134 0.3003]\n",
      "419. [0.1314  0.1607  0.09385 0.08224 0.2775 ]\n",
      "420. [0.1282  0.1108  0.03582 0.04306 0.2976 ]\n",
      "421. [0.1249  0.1937  0.256   0.06664 0.3035 ]\n",
      "422. [0.1312 0.3635 0.3219 0.1108 0.2827]\n",
      "423. [0.1415 0.217  0.2302 0.1105 0.2787]\n",
      "424. [0.1147 0.3167 0.366  0.1407 0.2744]\n",
      "425. [0.1398  0.1352  0.02085 0.04589 0.3196 ]\n",
      "426. [0.1126  0.07094 0.01235 0.02579 0.2349 ]\n",
      "427. [0.1327 0.2996 0.2939 0.0931 0.302 ]\n",
      "428. [0.1303  0.1696  0.1927  0.07485 0.2965 ]\n",
      "429. [0.103   0.06219 0.0458  0.04044 0.2383 ]\n",
      "430. [0.1068  0.09605 0.03469 0.03612 0.2165 ]\n",
      "431. [0.1419  0.62695 0.7855  0.2475  0.2866 ]\n",
      "432. [0.145  0.2629 0.2403 0.0737 0.2556]\n",
      "433. [0.1665 0.2942 0.5308 0.2173 0.3032]\n",
      "434. [0.139  0.3463 0.3912 0.1708 0.3007]\n",
      "435. [0.1218  0.155   0.122   0.07971 0.2525 ]\n",
      "436. [0.1613 0.3568 0.4069 0.1827 0.3179]\n",
      "437. [0.1214  0.1652  0.07127 0.06384 0.3313 ]\n",
      "438. [0.1195  0.1252  0.1117  0.07453 0.2725 ]\n",
      "439. [0.1118  0.1141  0.04753 0.0589  0.2513 ]\n",
      "440. [0.1034  0.1017  0.0626  0.08216 0.2136 ]\n",
      "441. [0.1391 0.4082 0.4779 0.1555 0.254 ]\n",
      "442. [0.1436 0.4122 0.5036 0.1739 0.25  ]\n",
      "443. [0.1072  0.1071  0.03517 0.03312 0.1859 ]\n",
      "444. [0.09794 0.06542 0.03986 0.02222 0.2699 ]\n",
      "445. [0.1263 0.2666 0.429  0.1535 0.2842]\n",
      "446. [0.1311 0.1822 0.1609 0.1202 0.2599]\n",
      "447. [0.1401 0.3762 0.6399 0.197  0.2972]\n",
      "448. [0.1226  0.1881  0.206   0.08308 0.36   ]\n",
      "449. [0.1089  0.2649  0.3779  0.09594 0.2471 ]\n",
      "450. [0.1368 0.3101 0.4399 0.228  0.2268]\n",
      "451. [0.09457 0.3399  0.3218  0.0875  0.2305 ]\n",
      "452. [0.1528 0.1845 0.3977 0.1466 0.2293]\n",
      "453. [0.1208  0.1856  0.1811  0.07116 0.2447 ]\n",
      "454. [0.1347 0.1478 0.1373 0.1069 0.2606]\n",
      "455. [0.1225  0.1517  0.1887  0.09851 0.327  ]\n",
      "456. [0.1172  0.1421  0.07003 0.07763 0.2196 ]\n",
      "457. [0.1406  0.2031  0.2923  0.06835 0.2884 ]\n",
      "458. [0.1289  0.1063  0.139   0.06005 0.2444 ]\n",
      "459. [0.1218  0.1093  0.04462 0.05921 0.2306 ]\n",
      "460. [0.111   0.1109  0.0719  0.04866 0.2321 ]\n",
      "461. [0.16   0.2444 0.2639 0.1555 0.301 ]\n",
      "462. [0.1357 0.4256 0.6833 0.2625 0.2641]\n",
      "463. [0.1017  0.146   0.1472  0.05563 0.2345 ]\n",
      "464. [0.1342  0.1808  0.186   0.08288 0.321  ]\n",
      "465. [0.1282 0.1965 0.1876 0.1045 0.2235]\n",
      "466. [0.1201 0.5646 0.6556 0.1357 0.2845]\n",
      "467. [0.1351 0.3549 0.4504 0.1181 0.2563]\n",
      "468. [0.1388  0.1255  0.06409 0.025   0.3057 ]\n",
      "469. [0.1207 0.4785 0.5165 0.1996 0.2301]\n",
      "470. [0.178  0.2878 0.3186 0.1416 0.266 ]\n",
      "471. [0.1234 0.1542 0.1277 0.0656 0.3174]\n",
      "472. [0.1041  0.09726 0.05524 0.05547 0.2404 ]\n",
      "473. [0.1065 0.2791 0.3151 0.1147 0.2688]\n",
      "474. [0.09422 0.05213 0.      0.      0.2409 ]\n",
      "475. [0.1332  0.3898  0.3365  0.07966 0.2581 ]\n",
      "476. [0.1326  0.261   0.3476  0.09783 0.3006 ]\n",
      "477. [0.1153 0.3429 0.2512 0.1339 0.2534]\n",
      "478. [0.09384 0.2006  0.1384  0.06222 0.2679 ]\n",
      "479. [0.1352  0.201   0.2596  0.07431 0.2941 ]\n",
      "480. [0.1377 0.4462 0.5897 0.1775 0.3318]\n",
      "481. [0.1208 0.2279 0.162  0.0569 0.2406]\n",
      "482. [0.1064 0.1415 0.1673 0.0815 0.2356]\n",
      "483. [0.1393 0.2499 0.1848 0.1335 0.3227]\n",
      "484. [0.1199  0.1346  0.1742  0.09077 0.2518 ]\n",
      "485. [0.1541 0.2979 0.4004 0.1452 0.2557]\n",
      "486. [0.1175 0.4061 0.4896 0.1342 0.3231]\n",
      "487. [0.1142  0.207   0.2437  0.07828 0.2455 ]\n",
      "488. [0.1514 0.3725 0.5936 0.206  0.3266]\n",
      "489. [0.1526  0.1477  0.149   0.09815 0.2804 ]\n",
      "490. [0.1009  0.292   0.2477  0.08737 0.41915]\n",
      "491. [0.1256  0.1804  0.123   0.06335 0.31   ]\n",
      "492. [0.09862 0.09976 0.1048  0.08341 0.1783 ]\n",
      "493. [0.1309 0.2327 0.2544 0.1489 0.3251]\n",
      "494. [0.09439 0.06477 0.01674 0.0268  0.228  ]\n",
      "495. [0.1118  0.1646  0.07698 0.04195 0.2687 ]\n",
      "496. [0.1216 0.1388 0.17   0.1017 0.2369]\n",
      "497. [0.1533 0.3842 0.3582 0.1407 0.323 ]\n",
      "498. [0.1276 0.2506 0.2028 0.1053 0.3035]\n",
      "499. [0.1412 0.3089 0.3533 0.1663 0.251 ]\n",
      "500. [0.1464 0.3597 0.5179 0.2113 0.248 ]\n",
      "501. [0.1135 0.2176 0.1856 0.1018 0.2177]\n",
      "502. [0.1794 0.3966 0.3381 0.1521 0.3651]\n",
      "503. [0.158   0.1751  0.1889  0.08411 0.3155 ]\n",
      "504. [0.1199 0.3625 0.3794 0.2264 0.2908]\n",
      "505. [0.1901 0.3441 0.2099 0.1025 0.3038]\n",
      "506. [0.1901 0.3663 0.2913 0.1075 0.2848]\n",
      "507. [0.1402  0.2315  0.3535  0.08088 0.2709 ]\n",
      "508. [0.1662  0.2031  0.1256  0.09514 0.278  ]\n",
      "509. [0.1354 0.1361 0.1947 0.1357 0.23  ]\n",
      "510. [0.1732 0.4967 0.5911 0.2163 0.3013]\n",
      "511. [0.1073 0.2793 0.269  0.1056 0.2604]\n",
      "512. [0.1139  0.1011  0.1101  0.07955 0.2334 ]\n",
      "513. [0.1574 0.3856 0.5106 0.2051 0.3585]\n",
      "514. [0.1223  0.1928  0.2492  0.09186 0.2626 ]\n",
      "515. [0.1246 0.2101 0.2866 0.112  0.2282]\n",
      "516. [0.1483  0.1574  0.1624  0.08542 0.306  ]\n",
      "517. [0.1492 0.2536 0.3759 0.151  0.3074]\n",
      "518. [0.1417 0.3309 0.4185 0.1613 0.2549]\n",
      "519. [0.1456 0.2961 0.1246 0.1096 0.2582]\n",
      "520. [0.1475  0.1979  0.1423  0.08045 0.3071 ]\n",
      "521. [0.185   0.2097  0.09996 0.07262 0.3681 ]\n",
      "522. [0.1342 0.4188 0.4658 0.2475 0.3157]\n",
      "523. [0.1108  0.07723 0.02533 0.02832 0.2557 ]\n",
      "524. [0.1425 0.2566 0.1935 0.1284 0.2849]\n",
      "525. [0.1419  0.2243  0.08434 0.06528 0.2502 ]\n",
      "526. [0.1641  0.2235  0.1754  0.08512 0.2983 ]\n",
      "527. [0.1624 0.3124 0.2654 0.1427 0.3518]\n",
      "528. [0.1292 0.2074 0.1791 0.107  0.311 ]\n",
      "529. [0.1394 0.1364 0.1559 0.1015 0.216 ]\n",
      "530. [0.1521  0.1632  0.1622  0.07393 0.2781 ]\n",
      "531. [0.1349 0.1854 0.1366 0.101  0.2478]\n",
      "532. [0.155  0.2964 0.2758 0.0812 0.3206]\n",
      "533. [0.1264  0.1564  0.1206  0.08704 0.2806 ]\n",
      "534. [0.1097 0.2534 0.3092 0.1613 0.322 ]\n",
      "535. [0.1428  0.251   0.2123  0.09861 0.2289 ]\n",
      "536. [0.1268 0.3135 0.4433 0.2148 0.3077]\n",
      "537. [0.138  0.2733 0.4234 0.1362 0.2698]\n",
      "538. [0.1768 0.3251 0.1395 0.1308 0.2803]\n",
      "539. [0.1256 0.0834 0.     0.     0.3058]\n",
      "540. [0.1596 0.3064 0.3393 0.05   0.279 ]\n",
      "541. [0.1345  0.2118  0.1797  0.06918 0.2329 ]\n",
      "542. [0.134  0.4202 0.404  0.1205 0.3187]\n",
      "543. [0.106  0.1376 0.1611 0.1095 0.2722]\n",
      "544. [0.1072  0.1381  0.1062  0.07958 0.2473 ]\n",
      "545. [0.1264  0.2037  0.1377  0.06845 0.2249 ]\n",
      "546. [0.1216  0.1517  0.1049  0.07174 0.2642 ]\n",
      "547. [0.1285  0.08842 0.04384 0.02381 0.2681 ]\n",
      "548. [0.1461  0.2246  0.1783  0.08333 0.2691 ]\n",
      "549. [0.1199  0.09546 0.0935  0.03846 0.2552 ]\n",
      "550. [0.1204  0.1633  0.06194 0.03264 0.3059 ]\n",
      "551. [0.1001  0.07348 0.      0.      0.2458 ]\n",
      "552. [0.1087  0.1782  0.1564  0.06413 0.3169 ]\n",
      "553. [0.1234  0.1064  0.08653 0.06498 0.2407 ]\n",
      "554. [0.1103  0.08298 0.07993 0.02564 0.2435 ]\n",
      "555. [0.1227  0.162   0.2439  0.06493 0.2372 ]\n",
      "556. [0.1384  0.171   0.2     0.09127 0.2226 ]\n",
      "557. [0.1265  0.12    0.01005 0.02232 0.2262 ]\n",
      "558. [0.1073  0.07158 0.      0.      0.2475 ]\n",
      "559. [0.1026 0.3171 0.3662 0.1105 0.2258]\n",
      "560. [0.1298  0.2517  0.363   0.09653 0.2112 ]\n",
      "561. [0.1241 0.2264 0.1326 0.1048 0.225 ]\n",
      "562. [0.09267 0.05494 0.      0.      0.1566 ]\n",
      "563. [0.1417  0.62695 0.7855  0.2356  0.4089 ]\n",
      "564. [0.1407 0.4186 0.6599 0.2542 0.2929]\n",
      "565. [0.141  0.2113 0.4107 0.2216 0.206 ]\n",
      "566. [0.1166 0.1922 0.3215 0.1628 0.2572]\n",
      "567. [0.1139 0.3094 0.3403 0.1418 0.2218]\n",
      "568. [0.165   0.62695 0.7855  0.265   0.4087 ]\n",
      "569. [0.08996 0.06444 0.      0.      0.2871 ]\n",
      "\n",
      "Selected features for Classifier 3:\n",
      "1. [1.47100e-01 2.53800e+01 1.84600e+02 1.93705e+03 2.65400e-01]\n",
      "2. [7.01700e-02 2.49900e+01 1.58800e+02 1.93705e+03 1.86000e-01]\n",
      "3. [1.279e-01 2.357e+01 1.525e+02 1.709e+03 2.430e-01]\n",
      "4. [1.052e-01 1.491e+01 9.887e+01 5.677e+02 2.575e-01]\n",
      "5. [1.043e-01 2.254e+01 1.522e+02 1.575e+03 1.625e-01]\n",
      "6. [8.089e-02 1.547e+01 1.034e+02 7.416e+02 1.741e-01]\n",
      "7. [7.400e-02 2.288e+01 1.532e+02 1.606e+03 1.932e-01]\n",
      "8. [5.985e-02 1.706e+01 1.106e+02 8.970e+02 1.556e-01]\n",
      "9. [9.353e-02 1.549e+01 1.062e+02 7.393e+02 2.060e-01]\n",
      "10. [8.543e-02 1.509e+01 9.765e+01 7.114e+02 2.210e-01]\n",
      "11. [3.323e-02 1.919e+01 1.238e+02 1.150e+03 9.975e-02]\n",
      "12. [6.606e-02 2.042e+01 1.365e+02 1.299e+03 1.810e-01]\n",
      "13. [1.118e-01 2.096e+01 1.517e+02 1.332e+03 1.767e-01]\n",
      "14. [5.364e-02 1.684e+01 1.120e+02 8.765e+02 1.119e-01]\n",
      "15. [8.025e-02 1.503e+01 1.088e+02 6.977e+02 2.208e-01]\n",
      "16. [7.364e-02 1.746e+01 1.241e+02 9.432e+02 1.712e-01]\n",
      "17. [5.259e-02 1.907e+01 1.234e+02 1.138e+03 1.609e-01]\n",
      "18. [1.028e-01 2.096e+01 1.368e+02 1.315e+03 2.073e-01]\n",
      "19. [9.49800e-02 2.73200e+01 1.86800e+02 1.93705e+03 2.38800e-01]\n",
      "20. [4.781e-02 1.511e+01 9.970e+01 7.112e+02 1.288e-01]\n",
      "21. [3.110e-02 1.450e+01 9.609e+01 6.305e+02 7.283e-02]\n",
      "22. [2.076e-02 1.023e+01 6.513e+01 3.149e+02 6.227e-02]\n",
      "23. [9.756e-02 1.807e+01 1.251e+02 9.809e+02 2.393e-01]\n",
      "24. [8.63200e-02 2.74600e+01 1.87335e+02 1.93705e+03 2.00900e-01]\n",
      "25. [9.17000e-02 2.64600e+01 1.77000e+02 1.93705e+03 2.09500e-01]\n",
      "26. [1.401e-01 2.225e+01 1.524e+02 1.461e+03 2.550e-01]\n",
      "27. [8.783e-02 1.762e+01 1.224e+02 8.969e+02 2.701e-01]\n",
      "28. [7.731e-02 2.131e+01 1.399e+02 1.403e+03 1.490e-01]\n",
      "29. [8.751e-02 2.027e+01 1.493e+02 1.269e+03 2.024e-01]\n",
      "30. [7.953e-02 2.001e+01 1.349e+02 1.227e+03 1.456e-01]\n",
      "31. [1.244e-01 2.315e+01 1.605e+02 1.670e+03 1.848e-01]\n",
      "32. [5.182e-02 1.682e+01 1.194e+02 8.887e+02 1.546e-01]\n",
      "33. [1.203e-01 2.088e+01 1.361e+02 1.344e+03 1.847e-01]\n",
      "34. [7.593e-02 2.415e+01 1.614e+02 1.813e+03 1.785e-01]\n",
      "35. [7.752e-02 2.021e+01 1.327e+02 1.261e+03 1.864e-01]\n",
      "36. [6.018e-02 2.001e+01 1.335e+02 1.229e+03 1.813e-01]\n",
      "37. [5.598e-02 1.589e+01 1.162e+02 7.996e+02 1.447e-01]\n",
      "38. [2.923e-02 1.330e+01 8.446e+01 5.459e+02 5.013e-02]\n",
      "39. [2.899e-02 1.499e+01 9.554e+01 6.988e+02 2.899e-02]\n",
      "40. [5.439e-02 1.553e+01 1.073e+02 7.404e+02 2.258e-01]\n",
      "41. [2.031e-02 1.593e+01 1.025e+02 7.879e+02 1.112e-01]\n",
      "42. [5.669e-02 1.284e+01 8.722e+01 5.140e+02 1.424e-01]\n",
      "43. [9.961e-02 2.409e+01 1.774e+02 1.651e+03 2.493e-01]\n",
      "44. [6.158e-02 1.738e+01 1.131e+02 9.072e+02 1.492e-01]\n",
      "45. [5.252e-02 1.623e+01 1.055e+02 7.407e+02 1.607e-01]\n",
      "46. [1.009e-01 2.282e+01 1.506e+02 1.567e+03 2.378e-01]\n",
      "47. [5.917e-03 8.964e+00 5.726e+01 2.422e+02 2.564e-02]\n",
      "48. [7.340e-02 1.567e+01 1.028e+02 7.594e+02 2.088e-01]\n",
      "49. [2.749e-02 1.376e+01 8.988e+01 5.826e+02 6.548e-02]\n",
      "50. [3.384e-02 1.515e+01 9.900e+01 6.988e+02 1.282e-01]\n",
      "51. [1.115e-02 1.298e+01 8.298e+01 5.165e+02 3.715e-02]\n",
      "52. [1.723e-02 1.467e+01 9.608e+01 6.567e+02 8.586e-02]\n",
      "53. [1.349e-02 1.310e+01 8.367e+01 5.272e+02 6.296e-02]\n",
      "54. [1.060e-01 2.060e+01 1.351e+02 1.321e+03 1.325e-01]\n",
      "55. [3.334e-02 1.810e+01 1.177e+02 1.030e+03 1.530e-01]\n",
      "56. [2.278e-02 1.284e+01 8.181e+01 5.062e+02 6.316e-02]\n",
      "57. [8.99400e-02 2.61400e+01 1.70100e+02 1.93705e+03 2.09100e-01]\n",
      "58. [8.123e-02 1.787e+01 1.157e+02 9.855e+02 1.834e-01]\n",
      "59. [4.167e-03 1.423e+01 9.024e+01 6.241e+02 1.111e-02]\n",
      "60. [7.799e-03 9.507e+00 5.990e+01 2.749e+02 4.419e-02]\n",
      "61. [1.290e-02 1.102e+01 6.986e+01 3.686e+02 2.579e-02]\n",
      "62. [9.259e-03 9.565e+00 6.206e+01 2.739e+02 2.778e-02]\n",
      "63. [8.653e-02 1.767e+01 1.191e+02 9.595e+02 1.785e-01]\n",
      "64. [2.180e-02 1.001e+01 6.559e+01 3.101e+02 5.087e-02]\n",
      "65. [6.873e-02 1.709e+01 1.118e+02 8.883e+02 1.716e-01]\n",
      "66. [9.029e-02 1.731e+01 1.146e+02 9.251e+02 1.614e-01]\n",
      "67. [1.504e-02 1.041e+01 6.703e+01 3.307e+02 6.517e-02]\n",
      "68. [2.230e-02 1.233e+01 7.800e+01 4.667e+02 6.961e-02]\n",
      "69. [4.375e-02 1.031e+01 6.550e+01 3.247e+02 1.750e-01]\n",
      "70. [2.864e-02 1.346e+01 8.567e+01 5.549e+02 5.882e-02]\n",
      "71. [7.951e-02 2.486e+01 1.659e+02 1.866e+03 1.789e-01]\n",
      "72. [2.872e-02 9.733e+00 6.256e+01 2.844e+02 4.786e-02]\n",
      "73. [7.944e-02 2.332e+01 1.516e+02 1.681e+03 1.899e-01]\n",
      "74. [5.069e-02 1.657e+01 1.103e+02 8.124e+02 1.383e-01]\n",
      "75. [2.272e-02 1.411e+01 8.971e+01 6.111e+02 8.660e-02]\n",
      "76. [6.638e-02 1.977e+01 1.288e+02 1.223e+03 1.520e-01]\n",
      "77. [6.556e-02 1.408e+01 9.136e+01 6.055e+02 7.407e-02]\n",
      "78. [1.080e-01 2.239e+01 1.501e+02 1.610e+03 2.102e-01]\n",
      "79. [1.54535e-01 2.33700e+01 1.70300e+02 1.62300e+03 2.50800e-01]\n",
      "80. [2.315e-02 1.424e+01 9.188e+01 6.221e+02 7.926e-02]\n",
      "81. [2.233e-02 1.311e+01 8.453e+01 5.251e+02 6.127e-02]\n",
      "82. [6.987e-02 1.553e+01 9.666e+01 6.149e+02 1.708e-01]\n",
      "83. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.86700e-01]\n",
      "84. [1.469e-01 2.033e+01 1.413e+02 1.298e+03 1.841e-01]\n",
      "85. [1.863e-02 1.367e+01 8.778e+01 5.679e+02 7.632e-02]\n",
      "86. [8.795e-02 2.293e+01 1.522e+02 1.603e+03 1.642e-01]\n",
      "87. [4.938e-02 1.621e+01 1.084e+02 8.089e+02 1.225e-01]\n",
      "88. [8.271e-02 2.456e+01 1.529e+02 1.623e+03 1.956e-01]\n",
      "89. [3.745e-02 1.383e+01 9.146e+01 5.747e+02 1.205e-01]\n",
      "90. [7.064e-02 1.634e+01 1.094e+02 8.036e+02 1.397e-01]\n",
      "91. [2.957e-02 1.611e+01 1.029e+02 8.037e+02 6.946e-02]\n",
      "92. [7.483e-02 1.643e+01 1.075e+02 8.309e+02 1.476e-01]\n",
      "93. [2.648e-02 1.636e+01 1.045e+02 8.306e+02 1.001e-01]\n",
      "94. [2.780e-02 1.510e+01 9.759e+01 6.994e+02 7.911e-02]\n",
      "95. [8.815e-02 1.823e+01 1.235e+02 1.025e+03 2.115e-01]\n",
      "96. [8.683e-02 2.422e+01 1.561e+02 1.750e+03 1.573e-01]\n",
      "97. [2.941e-02 1.283e+01 8.214e+01 4.952e+02 5.882e-02]\n",
      "98. [7.937e-03 1.092e+01 6.881e+01 3.661e+02 2.381e-02]\n",
      "99. [3.350e-02 1.306e+01 8.296e+01 5.125e+02 8.449e-02]\n",
      "100. [5.839e-02 1.633e+01 1.095e+02 8.264e+02 1.565e-01]\n",
      "101. [4.489e-02 1.699e+01 1.086e+02 9.065e+02 1.184e-01]\n",
      "102. [  0.     7.93  50.41 185.2    0.  ]\n",
      "103. [1.770e-02 1.334e+01 8.458e+01 5.478e+02 7.431e-02]\n",
      "104. [3.029e-02 1.076e+01 7.222e+01 3.612e+02 9.749e-02]\n",
      "105. [1.201e-02 1.154e+01 7.422e+01 4.028e+02 3.203e-02]\n",
      "106. [9.601e-02 1.631e+01 1.064e+02 8.272e+02 1.986e-01]\n",
      "107. [3.485e-02 1.314e+01 8.551e+01 5.217e+02 1.218e-01]\n",
      "108. [1.921e-02 1.329e+01 8.556e+01 5.441e+02 8.442e-02]\n",
      "109. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.91000e-01]\n",
      "110. [1.899e-02 1.301e+01 8.399e+01 5.181e+02 8.278e-02]\n",
      "111. [1.778e-02 1.105e+01 7.168e+01 3.670e+02 5.334e-02]\n",
      "112. [6.021e-02 1.333e+01 8.900e+01 5.274e+02 1.105e-01]\n",
      "113. [7.798e-02 1.530e+01 1.070e+02 7.090e+02 1.505e-01]\n",
      "114. [3.068e-02 1.116e+01 7.262e+01 3.744e+02 6.136e-02]\n",
      "115. [1.924e-02 9.628e+00 6.448e+01 2.844e+02 1.050e-01]\n",
      "116. [2.008e-02 1.367e+01 8.754e+01 5.830e+02 7.247e-02]\n",
      "117. [2.308e-02 9.414e+00 6.334e+01 2.700e+02 3.846e-02]\n",
      "118. [8.923e-02 1.881e+01 1.271e+02 1.095e+03 2.027e-01]\n",
      "119. [9.479e-02 2.019e+01 1.303e+02 1.272e+03 2.034e-01]\n",
      "120. [5.596e-02 2.058e+01 1.292e+02 1.261e+03 1.185e-01]\n",
      "121. [2.623e-02 1.282e+01 8.374e+01 5.105e+02 8.958e-02]\n",
      "122. [8.665e-02 2.225e+01 1.454e+02 1.549e+03 1.674e-01]\n",
      "123. [1.54535e-01 2.60200e+01 1.80900e+02 1.93705e+03 2.24800e-01]\n",
      "124. [5.778e-02 1.570e+01 1.028e+02 7.455e+02 1.221e-01]\n",
      "125. [2.800e-02 1.426e+01 9.199e+01 6.321e+02 8.978e-02]\n",
      "126. [1.141e-02 1.549e+01 1.003e+02 7.259e+02 5.104e-02]\n",
      "127. [3.085e-02 1.689e+01 1.132e+02 8.487e+02 1.329e-01]\n",
      "128. [5.627e-02 2.232e+01 1.482e+02 1.538e+03 1.218e-01]\n",
      "129. [8.534e-02 1.611e+01 1.059e+02 7.626e+02 1.423e-01]\n",
      "130. [1.149e-01 2.263e+01 1.487e+02 1.589e+03 1.732e-01]\n",
      "131. [2.882e-02 1.334e+01 9.138e+01 5.452e+02 8.187e-02]\n",
      "132. [8.087e-02 1.926e+01 1.249e+02 1.156e+03 1.514e-01]\n",
      "133. [5.613e-02 1.947e+01 1.297e+02 1.175e+03 1.312e-01]\n",
      "134. [5.933e-02 1.750e+01 1.143e+02 9.228e+02 1.374e-01]\n",
      "135. [6.847e-02 2.252e+01 1.456e+02 1.590e+03 1.379e-01]\n",
      "136. [2.704e-02 1.449e+01 9.204e+01 6.536e+02 9.331e-02]\n",
      "137. [2.600e-02 1.333e+01 8.616e+01 5.467e+02 6.968e-02]\n",
      "138. [2.875e-02 1.232e+01 7.993e+01 4.620e+02 8.476e-02]\n",
      "139. [8.624e-02 1.855e+01 1.214e+02 9.714e+02 1.667e-01]\n",
      "140. [4.796e-02 1.192e+01 7.653e+01 4.340e+02 8.611e-02]\n",
      "141. [  0.    10.62  66.53 342.9    0.  ]\n",
      "142. [5.943e-02 1.992e+01 1.290e+02 1.233e+03 1.216e-01]\n",
      "143. [1.861e-02 1.278e+01 8.266e+01 5.030e+02 6.402e-02]\n",
      "144. [3.088e-02 1.448e+01 9.717e+01 6.438e+02 1.012e-01]\n",
      "145. [7.875e-03 1.195e+01 7.779e+01 4.412e+02 3.413e-02]\n",
      "146. [3.003e-02 1.315e+01 8.626e+01 5.096e+02 6.042e-02]\n",
      "147. [7.415e-02 1.374e+01 9.193e+01 5.917e+02 1.865e-01]\n",
      "148. [3.562e-02 1.625e+01 1.071e+02 8.097e+02 8.405e-02]\n",
      "149. [5.532e-02 1.585e+01 1.086e+02 7.669e+02 1.599e-01]\n",
      "150. [1.329e-02 1.534e+01 9.719e+01 7.259e+02 6.019e-02]\n",
      "151. [2.645e-02 1.416e+01 9.082e+01 6.167e+02 6.296e-02]\n",
      "152. [2.168e-02 9.092e+00 5.808e+01 2.498e+02 7.879e-02]\n",
      "153. [7.857e-02 1.102e+01 7.104e+01 3.805e+02 1.571e-01]\n",
      "154. [1.786e-02 1.199e+01 7.625e+01 4.408e+02 5.506e-02]\n",
      "155. [3.483e-02 1.477e+01 9.767e+01 6.773e+02 9.722e-02]\n",
      "156. [2.331e-02 1.359e+01 8.660e+01 5.642e+02 8.211e-02]\n",
      "157. [1.054e-01 2.047e+01 1.329e+02 1.302e+03 1.515e-01]\n",
      "158. [2.771e-02 1.822e+01 1.203e+02 1.032e+03 8.436e-02]\n",
      "159. [1.963e-02 1.314e+01 8.408e+01 5.328e+02 7.025e-02]\n",
      "160. [6.588e-03 1.236e+01 7.807e+01 4.700e+02 3.953e-02]\n",
      "161. [3.738e-02 1.332e+01 8.891e+01 5.439e+02 7.909e-02]\n",
      "162. [9.667e-02 2.203e+01 1.466e+02 1.495e+03 1.777e-01]\n",
      "163. [1.28600e-01 2.67300e+01 1.74900e+02 1.93705e+03 2.24700e-01]\n",
      "164. [2.822e-02 1.358e+01 8.736e+01 5.530e+02 8.194e-02]\n",
      "165. [9.70200e-02 2.74600e+01 1.84200e+02 1.93705e+03 2.34600e-01]\n",
      "166. [1.939e-02 1.598e+01 1.023e+02 7.821e+02 5.754e-02]\n",
      "167. [1.698e-02 1.160e+01 7.366e+01 4.140e+02 4.603e-02]\n",
      "168. [6.576e-02 2.005e+01 1.307e+02 1.260e+03 1.474e-01]\n",
      "169. [1.043e-01 2.314e+01 1.553e+02 1.660e+03 1.721e-01]\n",
      "170. [3.781e-02 1.611e+01 1.046e+02 7.937e+02 8.485e-02]\n",
      "171. [3.700e-02 1.350e+01 8.697e+01 5.491e+02 9.391e-02]\n",
      "172. [3.438e-02 1.798e+01 1.166e+02 9.936e+02 1.160e-01]\n",
      "173. [1.097e-01 1.879e+01 1.250e+02 1.102e+03 1.827e-01]\n",
      "174. [2.583e-02 1.135e+01 7.201e+01 3.965e+02 4.306e-02]\n",
      "175. [  0.    11.54  73.2  408.3    0.  ]\n",
      "176. [  0.      9.262  58.36  259.2     0.   ]\n",
      "177. [3.716e-02 1.126e+01 7.307e+01 3.902e+02 9.910e-02]\n",
      "178. [8.866e-02 1.779e+01 1.235e+02 9.812e+02 2.035e-01]\n",
      "179. [1.852e-03 1.400e+01 8.818e+01 6.088e+02 9.259e-03]\n",
      "180. [1.330e-02 1.363e+01 8.670e+01 5.707e+02 3.990e-02]\n",
      "181. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.68800e-01]\n",
      "182. [1.49600e-01 2.66800e+01 1.76500e+02 1.93705e+03 2.90300e-01]\n",
      "183. [5.189e-02 2.011e+01 1.293e+02 1.269e+03 1.541e-01]\n",
      "184. [2.361e-02 1.237e+01 7.912e+01 4.672e+02 6.296e-02]\n",
      "185. [3.263e-02 1.780e+01 1.138e+02 9.731e+02 1.226e-01]\n",
      "186. [2.404e-03 1.187e+01 7.539e+01 4.370e+02 1.042e-02]\n",
      "187. [5.814e-02 2.131e+01 1.392e+02 1.410e+03 1.571e-01]\n",
      "188. [3.239e-02 1.301e+01 8.442e+01 5.215e+02 1.099e-01]\n",
      "189. [1.553e-02 1.257e+01 7.957e+01 4.895e+02 4.306e-02]\n",
      "190. [1.654e-02 1.335e+01 8.665e+01 5.467e+02 4.815e-02]\n",
      "191. [6.618e-02 1.574e+01 1.064e+02 7.624e+02 1.772e-01]\n",
      "192. [2.864e-02 1.375e+01 8.904e+01 5.795e+02 4.773e-02]\n",
      "193. [  0.      9.968  62.25  303.8     0.   ]\n",
      "194. [4.562e-02 1.565e+01 1.017e+02 7.689e+02 1.459e-01]\n",
      "195. [8.878e-02 1.608e+01 1.186e+02 7.847e+02 1.727e-01]\n",
      "196. [2.377e-02 1.388e+01 9.081e+01 6.006e+02 8.235e-02]\n",
      "197. [6.526e-02 1.639e+01 1.116e+02 8.069e+02 1.673e-01]\n",
      "198. [5.778e-02 1.976e+01 1.291e+02 1.228e+03 9.181e-02]\n",
      "199. [6.772e-02 2.336e+01 1.664e+02 1.688e+03 1.708e-01]\n",
      "200. [5.980e-02 1.833e+01 1.179e+02 1.044e+03 1.838e-01]\n",
      "201. [4.107e-02 1.444e+01 9.215e+01 6.384e+02 1.080e-01]\n",
      "202. [7.488e-02 2.042e+01 1.395e+02 1.239e+03 1.939e-01]\n",
      "203. [1.54535e-01 2.51200e+01 1.77000e+02 1.93705e+03 2.73300e-01]\n",
      "204. [9.176e-02 1.920e+01 1.285e+02 1.153e+03 2.013e-01]\n",
      "205. [3.821e-02 1.497e+01 9.605e+01 6.779e+02 1.015e-01]\n",
      "206. [4.079e-02 1.777e+01 1.177e+02 9.895e+02 1.252e-01]\n",
      "207. [1.952e-02 1.042e+01 6.708e+01 3.316e+02 5.588e-02]\n",
      "208. [5.390e-02 1.980e+01 1.300e+02 1.210e+03 1.096e-01]\n",
      "209. [5.102e-02 1.455e+01 9.948e+01 6.393e+02 1.126e-01]\n",
      "210. [3.157e-02 1.738e+01 1.137e+02 9.327e+02 1.035e-01]\n",
      "211. [9.561e-02 2.324e+01 1.583e+02 1.656e+03 1.920e-01]\n",
      "212. [1.393e-02 1.330e+01 8.522e+01 5.463e+02 6.913e-02]\n",
      "213. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 1.59500e-01]\n",
      "214. [6.597e-02 1.807e+01 1.204e+02 1.021e+03 1.099e-01]\n",
      "215. [6.462e-02 1.686e+01 1.150e+02 8.113e+02 1.772e-01]\n",
      "216. [5.602e-02 1.575e+01 1.044e+02 7.501e+02 1.654e-01]\n",
      "217. [3.142e-02 1.325e+01 8.620e+01 5.312e+02 1.138e-01]\n",
      "218. [1.071e-02 1.148e+01 7.540e+01 4.037e+02 3.571e-02]\n",
      "219. [8.69100e-02 2.57300e+01 1.70300e+02 1.93705e+03 1.82000e-01]\n",
      "220. [6.63700e-02 2.74600e+01 1.80200e+02 1.93705e+03 1.62500e-01]\n",
      "221. [2.563e-02 1.534e+01 9.971e+01 7.062e+02 8.056e-02]\n",
      "222. [4.451e-02 1.498e+01 1.011e+02 6.866e+02 9.090e-02]\n",
      "223. [1.915e-02 1.117e+01 7.194e+01 3.756e+02 5.575e-02]\n",
      "224. [6.462e-02 1.956e+01 1.259e+02 1.088e+03 1.479e-01]\n",
      "225. [2.456e-02 1.514e+01 9.884e+01 7.088e+02 9.678e-02]\n",
      "226. [4.603e-02 1.677e+01 1.104e+02 8.732e+02 1.087e-01]\n",
      "227. [1.216e-02 1.152e+01 7.347e+01 3.954e+02 4.464e-02]\n",
      "228. [3.780e-02 1.641e+01 1.142e+02 8.082e+02 1.379e-01]\n",
      "229. [2.036e-02 1.420e+01 9.067e+01 6.240e+02 1.180e-01]\n",
      "230. [6.861e-02 1.520e+01 1.053e+02 7.060e+02 1.977e-01]\n",
      "231. [1.090e-01 1.959e+01 1.335e+02 1.189e+03 2.543e-01]\n",
      "232. [3.125e-03 1.208e+01 7.982e+01 4.523e+02 2.083e-02]\n",
      "233. [6.434e-03 1.236e+01 7.844e+01 4.709e+02 3.002e-02]\n",
      "234. [8.340e-02 2.447e+01 1.627e+02 1.872e+03 1.563e-01]\n",
      "235. [1.667e-02 1.051e+01 6.574e+01 3.359e+02 7.222e-02]\n",
      "236. [1.896e-02 1.533e+01 9.827e+01 7.155e+02 7.963e-02]\n",
      "237. [1.23700e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.59300e-01]\n",
      "238. [6.022e-02 2.422e+01 1.617e+02 1.750e+03 1.445e-01]\n",
      "239. [4.408e-02 1.575e+01 1.025e+02 7.640e+02 8.219e-02]\n",
      "240. [8.811e-02 2.251e+01 1.412e+02 1.408e+03 2.066e-01]\n",
      "241. [3.731e-02 1.485e+01 9.411e+01 6.834e+02 9.222e-02]\n",
      "242. [1.108e-02 1.320e+01 8.385e+01 5.434e+02 4.052e-02]\n",
      "243. [2.854e-02 1.258e+01 8.716e+01 4.729e+02 1.218e-01]\n",
      "244. [2.344e-02 1.501e+01 9.800e+01 7.060e+02 6.106e-02]\n",
      "245. [8.886e-02 2.165e+01 1.449e+02 1.417e+03 1.564e-01]\n",
      "246. [3.070e-02 1.148e+01 7.368e+01 4.028e+02 6.736e-02]\n",
      "247. [1.105e-02 1.394e+01 8.828e+01 6.020e+02 4.970e-02]\n",
      "248. [3.980e-02 1.439e+01 1.050e+02 6.391e+02 1.561e-01]\n",
      "249. [1.615e-02 1.225e+01 7.798e+01 4.557e+02 6.136e-02]\n",
      "250. [2.929e-02 1.265e+01 8.088e+01 4.918e+02 9.608e-02]\n",
      "251. [1.31000e-01 2.55800e+01 1.65300e+02 1.93705e+03 2.10500e-01]\n",
      "252. [2.069e-02 1.297e+01 8.312e+01 5.089e+02 6.544e-02]\n",
      "253. [9.740e-02 2.528e+01 1.598e+02 1.933e+03 2.507e-01]\n",
      "254. [8.353e-02 1.985e+01 1.309e+02 1.222e+03 1.857e-01]\n",
      "255. [8.59100e-02 2.57000e+01 1.63100e+02 1.93705e+03 1.99900e-01]\n",
      "256. [5.246e-02 1.639e+01 1.081e+02 8.260e+02 1.374e-01]\n",
      "257. [1.144e-01 2.505e+01 1.786e+02 1.926e+03 1.941e-01]\n",
      "258. [1.242e-01 1.773e+01 1.198e+02 9.288e+02 2.229e-01]\n",
      "259. [1.377e-01 1.985e+01 1.437e+02 1.226e+03 2.462e-01]\n",
      "260. [8.399e-02 1.849e+01 1.263e+02 1.035e+03 2.014e-01]\n",
      "261. [9.333e-02 2.433e+01 1.623e+02 1.844e+03 1.697e-01]\n",
      "262. [2.837e-02 1.985e+01 1.282e+02 1.218e+03 8.235e-02]\n",
      "263. [7.507e-02 2.039e+01 1.379e+02 1.295e+03 1.528e-01]\n",
      "264. [2.847e-02 1.791e+01 1.159e+02 9.886e+02 8.568e-02]\n",
      "265. [6.527e-02 2.158e+01 1.405e+02 1.436e+03 1.984e-01]\n",
      "266. [8.64600e-02 2.74600e+01 1.87335e+02 1.93705e+03 1.65900e-01]\n",
      "267. [2.642e-02 1.188e+01 7.828e+01 4.248e+02 7.926e-02]\n",
      "268. [2.142e-02 1.480e+01 9.766e+01 6.615e+02 6.189e-02]\n",
      "269. [1.615e-02 1.390e+01 8.927e+01 5.975e+02 5.780e-02]\n",
      "270. [2.867e-02 1.169e+01 7.651e+01 4.104e+02 8.600e-02]\n",
      "271. [6.250e-03 1.491e+01 9.444e+01 6.846e+02 3.333e-02]\n",
      "272. [2.755e-02 1.232e+01 7.827e+01 4.575e+02 8.750e-02]\n",
      "273. [1.08800e-01 2.74600e+01 1.87335e+02 1.93705e+03 1.84100e-01]\n",
      "274. [1.407e-02 1.075e+01 6.809e+01 3.552e+02 5.159e-02]\n",
      "275. [4.744e-02 2.092e+01 1.351e+02 1.320e+03 1.136e-01]\n",
      "276. [7.404e-02 1.240e+01 7.946e+01 4.724e+02 8.946e-02]\n",
      "277. [3.333e-03 1.220e+01 7.737e+01 4.580e+02 1.111e-02]\n",
      "278. [5.843e-02 1.996e+01 1.290e+02 1.236e+03 1.294e-01]\n",
      "279. [1.238e-02 1.550e+01 9.891e+01 7.391e+02 5.185e-02]\n",
      "280. [3.711e-02 1.498e+01 9.837e+01 6.700e+02 9.993e-02]\n",
      "281. [9.664e-02 2.372e+01 1.598e+02 1.724e+03 1.872e-01]\n",
      "282. [2.763e-02 1.331e+01 8.470e+01 5.337e+02 8.290e-02]\n",
      "283. [9.464e-02 2.379e+01 1.524e+02 1.628e+03 2.252e-01]\n",
      "284. [9.052e-02 1.855e+01 1.269e+02 1.031e+03 1.732e-01]\n",
      "285. [3.390e-02 1.390e+01 9.212e+01 5.956e+02 1.017e-01]\n",
      "286. [2.924e-03 1.350e+01 8.556e+01 5.641e+02 8.772e-03]\n",
      "287. [3.791e-02 1.324e+01 9.220e+01 5.461e+02 1.155e-01]\n",
      "288. [1.171e-02 1.362e+01 8.740e+01 5.770e+02 5.366e-02]\n",
      "289. [5.588e-02 1.186e+01 7.827e+01 4.376e+02 9.314e-02]\n",
      "290. [2.173e-02 1.236e+01 7.929e+01 4.593e+02 6.203e-02]\n",
      "291. [6.602e-02 1.577e+01 1.017e+02 7.673e+02 1.021e-01]\n",
      "292. [4.819e-02 1.625e+01 1.091e+02 8.098e+02 1.489e-01]\n",
      "293. [3.370e-02 1.374e+01 8.881e+01 5.854e+02 1.056e-01]\n",
      "294. [2.280e-02 1.306e+01 8.435e+01 5.178e+02 9.140e-02]\n",
      "295. [1.924e-02 1.350e+01 8.854e+01 5.537e+02 6.343e-02]\n",
      "296. [1.917e-02 1.467e+01 9.417e+01 6.611e+02 5.802e-02]\n",
      "297. [1.369e-02 1.137e+01 7.242e+01 3.922e+02 3.194e-02]\n",
      "298. [3.515e-02 1.336e+01 8.510e+01 5.536e+02 7.160e-02]\n",
      "299. [1.374e-02 1.622e+01 1.058e+02 8.197e+02 7.530e-02]\n",
      "300. [1.875e-02 1.093e+01 7.010e+01 3.627e+02 3.125e-02]\n",
      "301. [1.06200e-01 2.59300e+01 1.71100e+02 1.93705e+03 1.98000e-01]\n",
      "302. [3.099e-02 1.346e+01 8.813e+01 5.513e+02 7.625e-02]\n",
      "303. [1.280e-01 2.368e+01 1.588e+02 1.696e+03 1.923e-01]\n",
      "304. [1.780e-02 1.106e+01 7.076e+01 3.754e+02 6.528e-02]\n",
      "305. [1.502e-02 1.268e+01 8.269e+01 4.898e+02 5.509e-02]\n",
      "306. [1.313e-02 1.244e+01 8.139e+01 4.765e+02 4.815e-02]\n",
      "307. [3.261e-03 1.441e+01 9.200e+01 6.369e+02 2.500e-02]\n",
      "308. [3.472e-03 9.699e+00 6.090e+01 2.855e+02 1.389e-02]\n",
      "309. [4.419e-03 1.497e+01 9.548e+01 6.987e+02 2.210e-02]\n",
      "310. [8.829e-03 1.473e+01 9.396e+01 6.724e+02 3.532e-02]\n",
      "311. [1.148e-02 1.261e+01 8.092e+01 4.831e+02 5.741e-02]\n",
      "312. [1.877e-02 1.646e+01 1.037e+02 8.408e+02 5.813e-02]\n",
      "313. [2.548e-02 1.419e+01 9.204e+01 6.188e+02 8.411e-02]\n",
      "314. [8.907e-03 1.234e+01 8.123e+01 4.678e+02 4.715e-02]\n",
      "315. [  0.      8.952  56.65  240.1     0.   ]\n",
      "316. [6.423e-03 1.334e+01 8.448e+01 5.442e+02 2.784e-02]\n",
      "317. [5.051e-03 1.285e+01 8.160e+01 5.131e+02 1.852e-02]\n",
      "318. [7.950e-02 2.184e+01 1.409e+02 1.485e+03 1.776e-01]\n",
      "319. [4.908e-02 1.006e+01 6.862e+01 2.971e+02 1.145e-01]\n",
      "320. [1.699e-02 1.290e+01 8.176e+01 5.159e+02 2.832e-02]\n",
      "321. [3.965e-02 1.128e+01 7.153e+01 3.904e+02 9.744e-02]\n",
      "322. [7.726e-02 2.306e+01 1.502e+02 1.657e+03 1.425e-01]\n",
      "323. [3.400e-02 1.404e+01 9.280e+01 5.995e+02 1.155e-01]\n",
      "324. [1.50400e-01 2.53000e+01 1.71100e+02 1.93705e+03 2.68500e-01]\n",
      "325. [1.692e-02 1.375e+01 9.111e+01 5.831e+02 5.556e-02]\n",
      "326. [2.107e-02 1.371e+01 8.870e+01 5.744e+02 5.602e-02]\n",
      "327. [2.733e-02 1.553e+01 9.840e+01 7.499e+02 5.890e-02]\n",
      "328. [5.592e-03 1.307e+01 8.274e+01 5.234e+02 2.796e-02]\n",
      "329. [8.488e-02 1.928e+01 1.298e+02 1.121e+03 1.583e-01]\n",
      "330. [7.981e-02 1.773e+01 1.137e+02 9.752e+02 1.047e-01]\n",
      "331. [7.041e-02 1.876e+01 1.243e+02 1.070e+03 1.981e-01]\n",
      "332. [2.950e-02 1.442e+01 9.921e+01 6.343e+02 9.858e-02]\n",
      "333. [7.583e-03 1.198e+01 7.691e+01 4.361e+02 2.022e-02]\n",
      "334. [2.941e-03 1.276e+01 8.208e+01 4.927e+02 1.667e-02]\n",
      "335. [8.535e-03 1.335e+01 8.453e+01 5.443e+02 3.983e-02]\n",
      "336. [9.934e-02 2.099e+01 1.432e+02 1.362e+03 1.827e-01]\n",
      "337. [2.098e-02 1.372e+01 8.738e+01 5.760e+02 5.850e-02]\n",
      "338. [6.090e-02 2.454e+01 1.611e+02 1.873e+03 2.048e-01]\n",
      "339. [1.775e-02 1.116e+01 7.198e+01 3.840e+02 6.499e-02]\n",
      "340. [1.41000e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.08900e-01]\n",
      "341. [4.223e-02 1.667e+01 1.114e+02 8.621e+02 1.414e-01]\n",
      "342. [2.292e-02 1.075e+01 7.125e+01 3.536e+02 8.120e-02]\n",
      "343. [3.341e-02 1.192e+01 7.976e+01 4.400e+02 1.075e-01]\n",
      "344. [1.103e-01 2.275e+01 1.576e+02 1.540e+03 2.255e-01]\n",
      "345. [3.250e-02 1.306e+01 8.416e+01 5.164e+02 7.864e-02]\n",
      "346. [2.037e-02 1.088e+01 7.089e+01 3.571e+02 4.074e-02]\n",
      "347. [8.488e-03 1.364e+01 8.654e+01 5.626e+02 5.093e-02]\n",
      "348. [3.528e-02 1.727e+01 1.142e+02 8.808e+02 1.251e-01]\n",
      "349. [2.322e-02 1.251e+01 7.967e+01 4.758e+02 6.548e-02]\n",
      "350. [1.787e-02 1.281e+01 8.309e+01 4.962e+02 4.766e-02]\n",
      "351. [1.162e-02 1.328e+01 8.361e+01 5.425e+02 4.262e-02]\n",
      "352. [1.242e-01 1.736e+01 1.194e+02 9.153e+02 2.135e-01]\n",
      "353. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.75600e-01]\n",
      "354. [6.553e-02 1.851e+01 1.212e+02 1.050e+03 1.526e-01]\n",
      "355. [1.471e-02 1.212e+01 7.962e+01 4.535e+02 3.922e-02]\n",
      "356. [4.391e-02 1.337e+01 8.902e+01 5.474e+02 9.265e-02]\n",
      "357. [5.603e-02 1.419e+01 9.422e+01 5.912e+02 1.258e-01]\n",
      "358. [2.088e-02 1.511e+01 9.674e+01 6.944e+02 5.556e-02]\n",
      "359. [2.381e-02 9.981e+00 6.527e+01 3.020e+02 4.762e-02]\n",
      "360. [1.406e-02 1.202e+01 7.579e+01 4.396e+02 5.052e-02]\n",
      "361. [5.449e-03 1.372e+01 8.682e+01 5.857e+02 1.635e-02]\n",
      "362. [2.424e-02 1.420e+01 9.294e+01 6.212e+02 5.614e-02]\n",
      "363. [1.781e-02 1.375e+01 8.782e+01 5.797e+02 8.312e-02]\n",
      "364. [4.835e-02 1.813e+01 1.172e+02 1.009e+03 9.123e-02]\n",
      "365. [1.473e-02 1.473e+01 9.376e+01 6.635e+02 6.987e-02]\n",
      "366. [7.785e-02 2.431e+01 1.612e+02 1.780e+03 1.765e-01]\n",
      "367. [1.265e-01 2.419e+01 1.600e+02 1.671e+03 2.152e-01]\n",
      "368. [2.027e-02 1.429e+01 9.385e+01 6.246e+02 8.829e-02]\n",
      "369. [8.46500e-02 2.74600e+01 1.87335e+02 1.93705e+03 1.82000e-01]\n",
      "370. [1.50100e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.43200e-01]\n",
      "371. [8.773e-02 1.938e+01 1.293e+02 1.165e+03 2.248e-01]\n",
      "372. [2.657e-02 1.620e+01 1.045e+02 8.191e+02 8.178e-02]\n",
      "373. [1.255e-01 2.269e+01 1.521e+02 1.535e+03 1.966e-01]\n",
      "374. [8.94100e-02 2.53700e+01 1.66800e+02 1.93705e+03 2.11200e-01]\n",
      "375. [2.031e-02 1.484e+01 9.916e+01 6.706e+02 6.987e-02]\n",
      "376. [5.397e-02 1.697e+01 1.131e+02 8.615e+02 1.251e-01]\n",
      "377. [5.941e-02 1.085e+01 7.651e+01 3.519e+02 1.465e-01]\n",
      "378. [1.117e-02 1.469e+01 9.711e+01 6.806e+02 5.781e-02]\n",
      "379. [2.471e-02 1.454e+01 9.796e+01 6.570e+02 1.054e-01]\n",
      "380. [6.367e-02 1.324e+01 9.176e+01 5.081e+02 2.524e-01]\n",
      "381. [5.550e-02 1.284e+01 8.493e+01 4.761e+02 1.318e-01]\n",
      "382. [2.074e-02 1.209e+01 7.973e+01 4.471e+02 6.754e-02]\n",
      "383. [2.978e-02 1.257e+01 8.736e+01 4.884e+02 1.092e-01]\n",
      "384. [2.880e-02 1.418e+01 9.523e+01 6.005e+02 9.804e-02]\n",
      "385. [2.864e-02 1.424e+01 9.659e+01 6.237e+02 9.173e-02]\n",
      "386. [5.271e-02 1.579e+01 1.022e+02 7.582e+02 1.359e-01]\n",
      "387. [2.534e-02 1.313e+01 8.765e+01 5.299e+02 9.140e-02]\n",
      "388. [8.507e-03 1.551e+01 9.966e+01 7.453e+02 4.537e-02]\n",
      "389. [2.757e-02 1.204e+01 7.973e+01 4.500e+02 8.272e-02]\n",
      "390. [1.021e-01 2.082e+01 1.420e+02 1.313e+03 1.825e-01]\n",
      "391. [1.968e-02 1.138e+01 7.323e+01 3.945e+02 6.696e-02]\n",
      "392. [  0.    10.17  64.01 317.     0.  ]\n",
      "393. [9.113e-02 2.120e+01 1.421e+02 1.359e+03 2.121e-01]\n",
      "394. [1.54535e-01 2.62300e+01 1.72000e+02 1.93705e+03 2.42200e-01]\n",
      "395. [3.326e-02 1.356e+01 8.833e+01 5.595e+02 6.266e-02]\n",
      "396. [3.251e-02 1.492e+01 9.642e+01 6.845e+02 7.911e-02]\n",
      "397. [5.381e-02 1.480e+01 9.733e+01 6.752e+02 1.453e-01]\n",
      "398. [4.083e-02 1.374e+01 9.072e+01 5.910e+02 8.296e-02]\n",
      "399. [7.246e-03 1.268e+01 8.079e+01 4.967e+02 5.556e-02]\n",
      "400. [1.638e-02 1.345e+01 8.600e+01 5.620e+02 5.356e-02]\n",
      "401. [1.198e-01 2.080e+01 1.496e+02 1.304e+03 1.964e-01]\n",
      "402. [1.796e-02 1.380e+01 8.764e+01 5.895e+02 6.876e-02]\n",
      "403. [1.883e-02 1.413e+01 9.631e+01 6.219e+02 6.608e-02]\n",
      "404. [2.390e-02 1.386e+01 8.969e+01 5.809e+02 8.388e-02]\n",
      "405. [2.054e-02 1.318e+01 8.411e+01 5.331e+02 4.793e-02]\n",
      "406. [2.932e-02 1.240e+01 8.276e+01 4.724e+02 7.887e-02]\n",
      "407. [4.528e-02 1.771e+01 1.159e+02 9.479e+02 1.129e-01]\n",
      "408. [1.867e-02 1.440e+01 9.163e+01 6.458e+02 5.601e-02]\n",
      "409. [8.824e-02 2.108e+01 1.381e+02 1.349e+03 1.974e-01]\n",
      "410. [2.653e-02 1.410e+01 8.900e+01 6.102e+02 9.532e-02]\n",
      "411. [2.100e-02 1.305e+01 8.507e+01 5.213e+02 8.698e-02]\n",
      "412. [2.480e-02 1.241e+01 7.993e+01 4.714e+02 7.431e-02]\n",
      "413. [5.128e-03 9.965e+00 6.661e+01 3.010e+02 2.564e-02]\n",
      "414. [3.876e-02 1.676e+01 1.102e+02 8.671e+02 1.308e-01]\n",
      "415. [2.739e-02 1.726e+01 1.101e+02 9.314e+02 6.575e-02]\n",
      "416. [2.179e-02 1.305e+01 8.509e+01 5.229e+02 8.263e-02]\n",
      "417. [1.257e-02 1.085e+01 6.873e+01 3.594e+02 3.770e-02]\n",
      "418. [8.481e-02 2.317e+01 1.571e+02 1.748e+03 2.134e-01]\n",
      "419. [2.402e-02 1.365e+01 8.812e+01 5.669e+02 8.224e-02]\n",
      "420. [1.076e-02 1.236e+01 7.926e+01 4.580e+02 4.306e-02]\n",
      "421. [1.428e-02 1.307e+01 8.643e+01 5.205e+02 6.664e-02]\n",
      "422. [6.300e-02 1.646e+01 1.141e+02 8.092e+02 1.108e-01]\n",
      "423. [4.497e-02 1.264e+01 8.193e+01 4.757e+02 1.105e-01]\n",
      "424. [4.812e-02 1.514e+01 1.014e+02 7.088e+02 1.407e-01]\n",
      "425. [1.967e-02 1.121e+01 7.179e+01 3.809e+02 4.589e-02]\n",
      "426. [5.159e-03 1.111e+01 6.992e+01 3.763e+02 2.579e-02]\n",
      "427. [2.218e-02 1.213e+01 8.141e+01 4.404e+02 9.310e-02]\n",
      "428. [1.404e-02 1.276e+01 8.369e+01 4.895e+02 7.485e-02]\n",
      "429. [1.370e-02 1.168e+01 7.435e+01 4.211e+02 4.044e-02]\n",
      "430. [1.835e-02 1.382e+01 8.887e+01 5.868e+02 3.612e-02]\n",
      "431. [9.711e-02 1.635e+01 1.254e+02 8.327e+02 2.475e-01]\n",
      "432. [2.799e-02 1.288e+01 8.961e+01 5.158e+02 7.370e-02]\n",
      "433. [1.259e-01 2.203e+01 1.460e+02 1.479e+03 2.173e-01]\n",
      "434. [8.744e-02 2.266e+01 1.453e+02 1.603e+03 1.708e-01]\n",
      "435. [2.877e-02 1.631e+01 1.023e+02 7.775e+02 7.971e-02]\n",
      "436. [6.463e-02 1.704e+01 1.139e+02 8.693e+02 1.827e-01]\n",
      "437. [2.090e-02 1.445e+01 9.514e+01 6.269e+02 6.384e-02]\n",
      "438. [2.944e-02 1.566e+01 1.012e+02 7.500e+02 7.453e-02]\n",
      "439. [2.293e-02 1.563e+01 1.009e+02 7.491e+02 5.890e-02]\n",
      "440. [2.652e-02 1.491e+01 9.653e+01 6.889e+02 8.216e-02]\n",
      "441. [3.613e-02 1.236e+01 9.014e+01 4.764e+02 1.555e-01]\n",
      "442. [5.736e-02 2.038e+01 1.328e+02 1.284e+03 1.739e-01]\n",
      "443. [9.937e-03 1.527e+01 9.790e+01 7.066e+02 3.312e-02]\n",
      "444. [1.111e-02 1.094e+01 6.935e+01 3.663e+02 2.222e-02]\n",
      "445. [6.254e-02 2.038e+01 1.333e+02 1.292e+03 1.535e-01]\n",
      "446. [4.274e-02 1.298e+01 8.448e+01 5.139e+02 1.202e-01]\n",
      "447. [8.293e-02 2.153e+01 1.454e+02 1.437e+03 1.970e-01]\n",
      "448. [2.260e-02 1.643e+01 1.059e+02 8.295e+02 8.308e-02]\n",
      "449. [2.925e-02 1.630e+01 1.081e+02 8.305e+02 9.594e-02]\n",
      "450. [1.15500e-01 2.56800e+01 1.68200e+02 1.93705e+03 2.28000e-01]\n",
      "451. [2.386e-02 1.279e+01 8.351e+01 5.072e+02 8.750e-02]\n",
      "452. [9.063e-02 2.144e+01 1.398e+02 1.421e+03 1.466e-01]\n",
      "453. [1.945e-02 1.309e+01 8.507e+01 5.237e+02 7.116e-02]\n",
      "454. [6.495e-02 1.580e+01 1.031e+02 7.499e+02 1.069e-01]\n",
      "455. [2.272e-02 1.434e+01 9.162e+01 6.335e+02 9.851e-02]\n",
      "456. [3.264e-02 1.505e+01 9.669e+01 7.056e+02 7.763e-02]\n",
      "457. [2.017e-02 1.312e+01 8.604e+01 5.278e+02 6.835e-02]\n",
      "458. [2.068e-02 1.435e+01 9.129e+01 6.329e+02 6.005e-02]\n",
      "459. [1.762e-02 1.434e+01 9.106e+01 6.285e+02 5.921e-02]\n",
      "460. [1.043e-02 1.067e+01 6.803e+01 3.499e+02 4.866e-02]\n",
      "461. [6.431e-02 2.296e+01 1.521e+02 1.648e+03 1.555e-01]\n",
      "462. [1.54535e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.62500e-01]\n",
      "463. [1.737e-02 1.540e+01 1.004e+02 7.346e+02 5.563e-02]\n",
      "464. [1.777e-02 1.277e+01 8.268e+01 4.951e+02 8.288e-02]\n",
      "465. [2.870e-02 1.490e+01 9.510e+01 6.876e+02 1.045e-01]\n",
      "466. [2.833e-02 1.544e+01 1.150e+02 7.335e+02 1.357e-01]\n",
      "467. [3.510e-02 1.480e+01 1.009e+02 6.891e+02 1.181e-01]\n",
      "468. [5.769e-03 1.115e+01 7.111e+01 3.802e+02 2.500e-02]\n",
      "469. [1.002e-01 2.157e+01 1.436e+02 1.437e+03 1.996e-01]\n",
      "470. [5.564e-02 1.336e+01 8.814e+01 5.281e+02 1.416e-01]\n",
      "471. [1.514e-02 1.114e+01 7.088e+01 3.852e+02 6.560e-02]\n",
      "472. [2.377e-02 1.360e+01 8.724e+01 5.676e+02 5.547e-02]\n",
      "473. [3.221e-02 1.718e+01 1.120e+02 9.066e+02 1.147e-01]\n",
      "474. [  0.    13.45  85.08 558.9    0.  ]\n",
      "475. [1.571e-02 1.194e+01 8.078e+01 4.331e+02 7.966e-02]\n",
      "476. [3.078e-02 1.409e+01 9.322e+01 6.058e+02 9.783e-02]\n",
      "477. [3.058e-02 1.645e+01 1.121e+02 8.285e+02 1.339e-01]\n",
      "478. [1.339e-02 1.514e+01 1.012e+02 7.189e+02 6.222e-02]\n",
      "479. [1.969e-02 1.240e+01 8.204e+01 4.676e+02 7.431e-02]\n",
      "480. [9.194e-02 1.739e+01 1.221e+02 9.397e+02 1.775e-01]\n",
      "481. [1.527e-02 1.334e+01 8.883e+01 5.474e+02 5.690e-02]\n",
      "482. [2.070e-02 1.641e+01 1.044e+02 8.305e+02 8.150e-02]\n",
      "483. [5.266e-02 1.483e+01 9.494e+01 6.602e+02 1.335e-01]\n",
      "484. [3.160e-02 1.496e+01 9.578e+01 6.865e+02 9.077e-02]\n",
      "485. [6.211e-02 1.701e+01 1.125e+02 8.543e+02 1.452e-01]\n",
      "486. [4.846e-02 1.378e+01 9.782e+01 5.806e+02 1.342e-01]\n",
      "487. [2.791e-02 1.646e+01 1.060e+02 8.310e+02 7.828e-02]\n",
      "488. [1.194e-01 2.396e+01 1.539e+02 1.740e+03 2.060e-01]\n",
      "489. [3.132e-02 1.332e+01 8.657e+01 5.498e+02 9.815e-02]\n",
      "490. [2.307e-02 1.918e+01 1.273e+02 1.084e+03 8.737e-02]\n",
      "491. [1.261e-02 1.417e+01 9.274e+01 6.229e+02 6.335e-02]\n",
      "492. [4.178e-02 1.982e+01 1.271e+02 1.210e+03 8.341e-02]\n",
      "493. [7.762e-02 2.153e+01 1.434e+02 1.426e+03 1.489e-01]\n",
      "494. [1.149e-02 1.319e+01 8.324e+01 5.340e+02 2.680e-02]\n",
      "495. [1.256e-02 1.450e+01 9.529e+01 6.483e+02 4.195e-02]\n",
      "496. [4.951e-02 1.601e+01 1.039e+02 7.836e+02 1.017e-01]\n",
      "497. [5.074e-02 1.438e+01 9.529e+01 6.337e+02 1.407e-01]\n",
      "498. [2.369e-02 1.406e+01 9.282e+01 6.073e+02 1.053e-01]\n",
      "499. [9.183e-02 2.275e+01 1.464e+02 1.600e+03 1.663e-01]\n",
      "500. [1.121e-01 2.386e+01 1.632e+02 1.760e+03 2.113e-01]\n",
      "501. [6.142e-02 1.676e+01 1.097e+02 8.569e+02 1.018e-01]\n",
      "502. [6.759e-02 1.601e+01 1.060e+02 7.880e+02 1.521e-01]\n",
      "503. [3.279e-02 1.357e+01 8.667e+01 5.520e+02 8.411e-02]\n",
      "504. [1.00300e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.26400e-01]\n",
      "505. [5.252e-02 1.028e+01 6.905e+01 3.002e+02 1.025e-01]\n",
      "506. [7.038e-02 1.060e+01 6.947e+01 3.281e+02 1.075e-01]\n",
      "507. [2.166e-02 1.316e+01 8.513e+01 5.153e+02 8.088e-02]\n",
      "508. [4.268e-02 1.169e+01 7.608e+01 4.111e+02 9.514e-02]\n",
      "509. [4.563e-02 1.732e+01 1.098e+02 9.282e+02 1.357e-01]\n",
      "510. [8.520e-02 1.711e+01 1.177e+02 9.094e+02 2.163e-01]\n",
      "511. [2.639e-02 1.245e+01 8.125e+01 4.738e+02 1.056e-01]\n",
      "512. [2.541e-02 1.561e+01 1.017e+02 7.602e+02 7.955e-02]\n",
      "513. [8.172e-02 1.641e+01 1.133e+02 8.444e+02 2.051e-01]\n",
      "514. [4.349e-02 1.676e+01 1.085e+02 8.620e+02 9.186e-02]\n",
      "515. [4.335e-02 1.758e+01 1.138e+02 9.670e+02 1.120e-01]\n",
      "516. [2.594e-02 1.247e+01 7.915e+01 4.786e+02 8.542e-02]\n",
      "517. [9.451e-02 2.186e+01 1.422e+02 1.493e+03 1.510e-01]\n",
      "518. [9.431e-02 2.373e+01 1.605e+02 1.646e+03 1.613e-01]\n",
      "519. [5.303e-02 1.505e+01 9.931e+01 6.747e+02 1.096e-01]\n",
      "520. [2.995e-02 1.445e+01 9.363e+01 6.241e+02 8.045e-02]\n",
      "521. [2.421e-02 1.057e+01 6.784e+01 3.266e+02 7.262e-02]\n",
      "522. [1.47100e-01 2.74600e+01 1.87335e+02 1.93705e+03 2.47500e-01]\n",
      "523. [5.664e-03 1.193e+01 7.638e+01 4.359e+02 2.832e-02]\n",
      "524. [3.783e-02 1.511e+01 9.943e+01 7.019e+02 1.284e-01]\n",
      "525. [2.416e-02 1.124e+01 7.432e+01 3.765e+02 6.528e-02]\n",
      "526. [1.510e-02 9.473e+00 6.330e+01 2.756e+02 8.512e-02]\n",
      "527. [3.152e-02 1.535e+01 1.019e+02 7.198e+02 1.427e-01]\n",
      "528. [2.647e-02 1.361e+01 8.722e+01 5.649e+02 1.070e-01]\n",
      "529. [6.615e-02 1.462e+01 9.452e+01 6.533e+02 1.015e-01]\n",
      "530. [2.798e-02 1.345e+01 8.692e+01 5.499e+02 7.393e-02]\n",
      "531. [4.440e-02 1.350e+01 8.852e+01 5.523e+02 1.010e-01]\n",
      "532. [2.157e-02 1.335e+01 8.700e+01 5.506e+02 8.120e-02]\n",
      "533. [1.880e-02 1.585e+01 1.016e+02 7.734e+02 8.704e-02]\n",
      "534. [1.015e-01 2.323e+01 1.520e+02 1.645e+03 1.613e-01]\n",
      "535. [2.788e-02 1.162e+01 7.643e+01 4.075e+02 9.861e-02]\n",
      "536. [1.322e-01 2.430e+01 1.602e+02 1.809e+03 2.148e-01]\n",
      "537. [6.139e-02 1.529e+01 1.043e+02 7.283e+02 1.362e-01]\n",
      "538. [4.531e-02 1.298e+01 8.612e+01 4.877e+02 1.308e-01]\n",
      "539. [  0.      9.077  57.17  248.      0.   ]\n",
      "540. [1.364e-02 8.678e+00 5.449e+01 2.236e+02 5.000e-02]\n",
      "541. [2.594e-02 1.226e+01 7.878e+01 4.578e+02 6.918e-02]\n",
      "542. [3.890e-02 1.622e+01 1.135e+02 8.089e+02 1.205e-01]\n",
      "543. [3.027e-02 1.651e+01 1.074e+02 8.264e+02 1.095e-01]\n",
      "544. [3.275e-02 1.437e+01 9.248e+01 6.296e+02 7.958e-02]\n",
      "545. [2.369e-02 1.505e+01 9.917e+01 6.886e+02 6.845e-02]\n",
      "546. [2.443e-02 1.535e+01 9.758e+01 7.298e+02 7.174e-02]\n",
      "547. [5.495e-03 1.125e+01 7.112e+01 3.849e+02 2.381e-02]\n",
      "548. [2.438e-02 1.083e+01 7.108e+01 3.574e+02 8.333e-02]\n",
      "549. [9.615e-03 1.093e+01 6.910e+01 3.642e+02 3.846e-02]\n",
      "550. [8.160e-03 1.303e+01 8.390e+01 5.056e+02 3.264e-02]\n",
      "551. [  0.    11.66  74.08 412.3    0.  ]\n",
      "552. [2.257e-02 1.202e+01 7.780e+01 4.366e+02 6.413e-02]\n",
      "553. [1.499e-02 1.387e+01 8.810e+01 5.947e+02 6.498e-02]\n",
      "554. [1.282e-02 9.845e+00 6.286e+01 2.958e+02 2.564e-02]\n",
      "555. [2.343e-02 1.389e+01 8.884e+01 5.957e+02 6.493e-02]\n",
      "556. [2.738e-02 1.084e+01 6.957e+01 3.576e+02 9.127e-02]\n",
      "557. [1.116e-02 1.065e+01 6.788e+01 3.473e+02 2.232e-02]\n",
      "558. [  0.    10.49  66.5  330.6    0.  ]\n",
      "559. [3.736e-02 1.548e+01 1.059e+02 7.335e+02 1.105e-01]\n",
      "560. [4.105e-02 1.248e+01 8.228e+01 4.742e+02 9.653e-02]\n",
      "561. [4.304e-02 1.530e+01 1.002e+02 7.067e+02 1.048e-01]\n",
      "562. [  0.    11.92  75.19 439.6    0.  ]\n",
      "563. [9.429e-02 1.752e+01 1.287e+02 9.150e+02 2.356e-01]\n",
      "564. [1.474e-01 2.429e+01 1.791e+02 1.819e+03 2.542e-01]\n",
      "565. [1.38900e-01 2.54500e+01 1.66100e+02 1.93705e+03 2.21600e-01]\n",
      "566. [9.791e-02 2.369e+01 1.550e+02 1.731e+03 1.628e-01]\n",
      "567. [5.302e-02 1.898e+01 1.267e+02 1.124e+03 1.418e-01]\n",
      "568. [1.520e-01 2.574e+01 1.846e+02 1.821e+03 2.650e-01]\n",
      "569. [  0.      9.456  59.16  268.6     0.   ]\n",
      "\n",
      "Selected features for Classifier 4:\n",
      "1. [9.05300e-01 8.62000e+01 1.93705e+03 7.11900e-01 4.19150e-01]\n",
      "2. [7.33900e-01 7.40800e+01 1.93705e+03 2.41600e-01 2.75000e-01]\n",
      "3. [7.869e-01 8.620e+01 1.709e+03 4.504e-01 3.613e-01]\n",
      "4. [1.1560e+00 2.7230e+01 5.6770e+02 6.8690e-01 4.1915e-01]\n",
      "5. [7.813e-01 8.620e+01 1.575e+03 4.000e-01 2.364e-01]\n",
      "6. [8.902e-01 2.719e+01 7.416e+02 5.355e-01 3.985e-01]\n",
      "7. [7.732e-01 5.391e+01 1.606e+03 3.784e-01 3.063e-01]\n",
      "8. [1.377e+00 5.096e+01 8.970e+02 2.678e-01 3.196e-01]\n",
      "9. [1.0020e+00 2.4320e+01 7.3930e+02 5.3900e-01 4.1915e-01]\n",
      "10. [1.5990e+00 2.3940e+01 7.1140e+02 7.8550e-01 4.1915e-01]\n",
      "11. [1.187e+00 4.051e+01 1.150e+03 1.459e-01 2.948e-01]\n",
      "12. [9.849e-01 5.416e+01 1.299e+03 3.965e-01 3.792e-01]\n",
      "13. [2.43415e+00 8.62000e+01 1.33200e+03 3.63900e-01 3.17600e-01]\n",
      "14. [1.078e+00 3.658e+01 8.765e+02 2.322e-01 2.809e-01]\n",
      "15. [1.169e+00 1.921e+01 6.977e+02 6.943e-01 3.596e-01]\n",
      "16. [1.0330e+00 3.2550e+01 9.4320e+02 7.0260e-01 4.1915e-01]\n",
      "17. [1.240e+00 4.540e+01 1.138e+03 2.914e-01 3.029e-01]\n",
      "18. [1.073e+00 5.418e+01 1.315e+03 4.784e-01 3.706e-01]\n",
      "19. [1.01700e+00 8.62000e+01 1.93705e+03 5.37200e-01 2.76800e-01]\n",
      "20. [7.886e-01 2.356e+01 7.112e+02 2.390e-01 2.977e-01]\n",
      "21. [7.477e-01 1.467e+01 6.305e+02 1.890e-01 3.184e-01]\n",
      "22. [9.768e-01 1.570e+01 3.149e+02 8.867e-02 2.450e-01]\n",
      "23. [7.0960e-01 4.4910e+01 9.8090e+02 6.3050e-01 4.1915e-01]\n",
      "24. [1.12700e+00 8.62000e+01 1.93705e+03 3.15500e-01 2.82200e-01]\n",
      "25. [9.01700e-01 8.62000e+01 1.93705e+03 4.69500e-01 3.61300e-01]\n",
      "26. [9.760e-01 8.620e+01 1.461e+03 3.853e-01 4.066e-01]\n",
      "27. [9.8320e-01 2.1050e+01 8.9690e+02 5.5390e-01 4.1915e-01]\n",
      "28. [1.849e+00 8.620e+01 1.403e+03 3.446e-01 2.341e-01]\n",
      "29. [1.012e+00 4.350e+01 1.269e+03 6.335e-01 4.027e-01]\n",
      "30. [8.225e-01 6.110e+01 1.227e+03 2.489e-01 2.756e-01]\n",
      "31. [1.466e+00 8.620e+01 1.670e+03 6.133e-01 3.444e-01]\n",
      "32. [1.0300e+00 4.1000e+01 8.8870e+02 6.9560e-01 4.1915e-01]\n",
      "33. [1.398e+00 6.778e+01 1.344e+03 5.588e-01 3.530e-01]\n",
      "34. [6.062e-01 6.817e+01 1.813e+03 6.091e-01 3.672e-01]\n",
      "35. [6.8570e-01 3.5030e+01 1.2610e+03 5.2740e-01 4.1915e-01]\n",
      "36. [9.1970e-01 4.5190e+01 1.2290e+03 5.4090e-01 4.1915e-01]\n",
      "37. [1.019e+00 2.491e+01 7.996e+02 5.186e-01 3.591e-01]\n",
      "38. [2.342e+00 1.416e+01 5.459e+02 4.833e-02 1.987e-01]\n",
      "39. [2.188e+00 8.620e+01 6.988e+02 2.398e-02 1.565e-01]\n",
      "40. [5.914e-01 1.852e+01 7.404e+02 5.030e-01 2.807e-01]\n",
      "41. [8.265e-01 2.053e+01 7.879e+02 2.085e-01 2.994e-01]\n",
      "42. [1.428e+00 1.697e+01 5.140e+02 4.023e-01 2.964e-01]\n",
      "43. [1.6660e+00 8.6200e+01 1.6510e+03 7.2420e-01 4.1915e-01]\n",
      "44. [8.249e-01 3.133e+01 9.072e+02 3.664e-01 3.739e-01]\n",
      "45. [6.123e-01 1.449e+01 7.407e+02 3.728e-01 3.693e-01]\n",
      "46. [6.633e-01 7.156e+01 1.567e+03 7.345e-01 3.799e-01]\n",
      "47. [9.567e-01 8.205e+00 2.422e+02 6.880e-02 3.105e-01]\n",
      "48. [8.937e-01 2.425e+01 7.594e+02 5.006e-01 3.900e-01]\n",
      "49. [7.294e-01 1.987e+01 5.826e+02 3.050e-01 2.747e-01]\n",
      "50. [1.353e+00 2.020e+01 6.988e+02 2.282e-01 2.871e-01]\n",
      "51. [1.210e+00 2.847e+01 5.165e+02 5.523e-02 2.433e-01]\n",
      "52. [9.234e-01 1.455e+01 6.567e+02 1.050e-01 2.346e-01]\n",
      "53. [6.329e-01 1.747e+01 5.272e+02 9.203e-02 2.785e-01]\n",
      "54. [1.593e+00 8.620e+01 1.321e+03 2.623e-01 3.021e-01]\n",
      "55. [8.339e-01 2.991e+01 1.030e+03 2.712e-01 2.675e-01]\n",
      "56. [9.591e-01 2.347e+01 5.062e+02 9.076e-02 3.306e-01]\n",
      "57. [1.19300e+00 8.62000e+01 1.93705e+03 3.87900e-01 3.53700e-01]\n",
      "58. [1.150e+00 4.009e+01 9.855e+02 3.587e-01 3.698e-01]\n",
      "59. [1.214e+00 3.296e+01 6.241e+02 1.845e-03 2.439e-01]\n",
      "60. [5.796e-01 8.322e+00 2.749e+02 1.168e-01 3.220e-01]\n",
      "61. [1.441e+00 3.462e+01 3.686e+02 2.168e-02 3.557e-01]\n",
      "62. [2.067e+00 1.839e+01 2.739e+02 9.001e-02 2.972e-01]\n",
      "63. [1.268e+00 6.078e+01 9.595e+02 6.922e-01 2.844e-01]\n",
      "64. [2.265e+00 2.352e+01 3.101e+02 1.397e-01 3.282e-01]\n",
      "65. [1.178e+00 3.646e+01 8.883e+02 4.024e-01 3.383e-01]\n",
      "66. [1.281e+00 3.524e+01 9.251e+02 3.024e-01 3.321e-01]\n",
      "67. [2.011e+00 1.420e+01 3.307e+02 9.412e-02 2.878e-01]\n",
      "68. [9.429e-01 1.815e+01 4.667e+02 1.444e-01 2.400e-01]\n",
      "69. [  1.194    17.67    324.7       0.7855    0.41915]\n",
      "70. [8.732e-01 1.833e+01 5.549e+02 1.039e-01 2.383e-01]\n",
      "71. [7.975e-01 8.620e+01 1.866e+03 2.687e-01 2.551e-01]\n",
      "72. [8.522e-01 2.544e+01 2.844e+02 1.434e-01 2.254e-01]\n",
      "73. [1.041e+00 6.947e+01 1.681e+03 6.566e-01 3.313e-01]\n",
      "74. [6.205e-01 2.335e+01 8.124e+02 2.779e-01 2.589e-01]\n",
      "75. [1.025e+00 1.968e+01 6.111e+02 1.703e-01 2.618e-01]\n",
      "76. [1.016e+00 7.925e+01 1.223e+03 2.829e-01 2.650e-01]\n",
      "77. [1.014e+00 3.265e+01 6.055e+02 8.539e-02 2.710e-01]\n",
      "78. [5.505e-01 8.620e+01 1.610e+03 3.786e-01 3.751e-01]\n",
      "79. [1.8850e+00 8.6200e+01 1.6230e+03 7.6810e-01 4.1915e-01]\n",
      "80. [1.095e+00 2.035e+01 6.221e+02 1.731e-01 2.779e-01]\n",
      "81. [2.174e+00 2.462e+01 5.251e+02 1.755e-01 2.762e-01]\n",
      "82. [1.016e+00 1.296e+01 6.149e+02 4.858e-01 3.527e-01]\n",
      "83. [1.47400e+00 8.62000e+01 1.93705e+03 6.47600e-01 2.35500e-01]\n",
      "84. [2.43415e+00 6.71000e+01 1.29800e+03 2.43200e-01 2.31100e-01]\n",
      "85. [1.255e+00 1.616e+01 5.679e+02 2.267e-01 3.379e-01]\n",
      "86. [1.475e+00 8.060e+01 1.603e+03 3.157e-01 3.695e-01]\n",
      "87. [2.220e+00 3.887e+01 8.089e+02 3.349e-01 3.020e-01]\n",
      "88. [6.636e-01 5.765e+01 1.623e+03 5.755e-01 3.956e-01]\n",
      "89. [1.502e+00 2.095e+01 5.747e+02 2.434e-01 2.972e-01]\n",
      "90. [7.372e-01 4.276e+01 8.036e+02 2.604e-01 3.151e-01]\n",
      "91. [1.111e+00 3.376e+01 8.037e+02 9.189e-02 2.522e-01]\n",
      "92. [8.413e-01 2.944e+01 8.309e+02 2.846e-01 2.556e-01]\n",
      "93. [1.153e+00 3.635e+01 8.306e+02 1.350e-01 2.027e-01]\n",
      "94. [1.373e+00 2.522e+01 6.994e+02 1.381e-01 2.678e-01]\n",
      "95. [9.644e-01 4.714e+01 1.025e+03 5.203e-01 2.834e-01]\n",
      "96. [1.509e+00 8.620e+01 1.750e+03 4.098e-01 3.689e-01]\n",
      "97. [1.511e+00 2.444e+01 4.952e+02 4.980e-02 2.227e-01]\n",
      "98. [2.043e+00 2.005e+01 3.661e+02 2.049e-02 1.934e-01]\n",
      "99. [5.391e-01 1.575e+01 5.125e+02 1.922e-01 2.772e-01]\n",
      "100. [1.851e+00 2.685e+01 8.264e+02 3.194e-01 2.718e-01]\n",
      "101. [1.290e+00 4.314e+01 9.065e+02 3.169e-01 2.651e-01]\n",
      "102. [  1.508    9.833  185.2      0.       0.2932]\n",
      "103. [1.571e+00 1.468e+01 5.478e+02 1.145e-01 2.694e-01]\n",
      "104. [1.222e+00 1.177e+01 3.612e+02 2.644e-01 2.622e-01]\n",
      "105. [1.534e+00 2.313e+01 4.028e+02 7.987e-02 2.826e-01]\n",
      "106. [9.238e-01 3.466e+01 8.272e+02 6.376e-01 3.147e-01]\n",
      "107. [1.657e+00 2.062e+01 5.217e+02 2.873e-01 2.806e-01]\n",
      "108. [8.944e-01 9.227e+00 5.441e+02 1.937e-01 2.983e-01]\n",
      "109. [1.54500e+00 8.62000e+01 1.93705e+03 7.85500e-01 4.05500e-01]\n",
      "110. [9.861e-01 1.641e+01 5.181e+02 3.120e-01 2.829e-01]\n",
      "111. [1.424e+00 2.287e+01 3.670e+02 1.300e-01 2.533e-01]\n",
      "112. [1.803e+00 2.048e+01 5.274e+02 2.216e-01 2.226e-01]\n",
      "113. [1.490e+00 2.925e+01 7.090e+02 6.783e-01 2.398e-01]\n",
      "114. [1.860e+00 1.991e+01 3.744e+02 1.295e-01 2.383e-01]\n",
      "115. [5.864e-01 8.966e+00 2.844e+02 2.456e-01 2.926e-01]\n",
      "116. [9.227e-01 2.479e+01 5.830e+02 1.503e-01 2.438e-01]\n",
      "117. [9.789e-01 1.694e+01 2.700e+02 1.544e-01 1.652e-01]\n",
      "118. [9.489e-01 4.118e+01 1.095e+03 4.704e-01 3.585e-01]\n",
      "119. [1.072e+00 5.863e+01 1.272e+03 7.356e-01 3.274e-01]\n",
      "120. [1.2140e+00 5.4040e+01 1.2610e+03 2.2490e-01 4.1915e-01]\n",
      "121. [4.607e-01 1.050e+01 5.105e+02 2.102e-01 3.016e-01]\n",
      "122. [1.581e+00 8.620e+01 1.549e+03 3.272e-01 2.894e-01]\n",
      "123. [2.43415e+00 8.62000e+01 1.93705e+03 5.80300e-01 3.22200e-01]\n",
      "124. [8.570e-01 2.419e+01 7.455e+02 2.560e-01 2.889e-01]\n",
      "125. [1.140e+00 1.466e+01 6.321e+02 3.308e-01 2.048e-01]\n",
      "126. [8.561e-01 1.791e+01 7.259e+02 8.115e-02 2.364e-01]\n",
      "127. [1.005e+00 1.983e+01 8.487e+02 3.796e-01 3.470e-01]\n",
      "128. [1.342e+00 8.123e+01 1.538e+03 3.207e-01 2.841e-01]\n",
      "129. [1.068e+00 3.984e+01 7.626e+02 1.960e-01 2.590e-01]\n",
      "130. [1.199e+00 6.333e+01 1.589e+03 5.673e-01 3.305e-01]\n",
      "131. [8.163e-01 1.524e+01 5.452e+02 9.915e-02 3.469e-01]\n",
      "132. [7.859e-01 4.831e+01 1.156e+03 3.791e-01 2.837e-01]\n",
      "133. [1.265e+00 4.368e+01 1.175e+03 2.992e-01 3.480e-01]\n",
      "134. [8.155e-01 2.794e+01 9.228e+02 1.709e-01 2.723e-01]\n",
      "135. [1.202e+00 6.835e+01 1.590e+03 3.965e-01 3.109e-01]\n",
      "136. [1.380e+00 1.987e+01 6.536e+02 2.177e-01 2.829e-01]\n",
      "137. [2.43415e+00 3.43700e+01 5.46700e+02 1.04600e-01 1.71200e-01]\n",
      "138. [9.938e-01 1.267e+01 4.620e+02 1.399e-01 2.676e-01]\n",
      "139. [1.452e+00 8.620e+01 9.714e+02 3.355e-01 3.414e-01]\n",
      "140. [1.343e+00 2.633e+01 4.340e+02 8.669e-02 2.102e-01]\n",
      "141. [4.960e-01 1.226e+01 3.429e+02 0.000e+00 3.105e-01]\n",
      "142. [1.332e+00 7.408e+01 1.233e+03 2.802e-01 2.792e-01]\n",
      "143. [1.908e+00 2.138e+01 5.030e+02 7.708e-02 2.584e-01]\n",
      "144. [7.712e-01 1.664e+01 6.438e+02 2.090e-01 3.549e-01]\n",
      "145. [1.239e+00 1.774e+01 4.412e+02 9.755e-02 2.300e-01]\n",
      "146. [6.538e-01 2.503e+01 5.096e+02 9.420e-02 2.727e-01]\n",
      "147. [1.4260e+00 2.4720e+01 5.9170e+02 4.5040e-01 4.1915e-01]\n",
      "148. [1.909e+00 3.943e+01 8.097e+02 2.500e-01 2.852e-01]\n",
      "149. [7.394e-01 2.120e+01 7.669e+02 3.103e-01 2.691e-01]\n",
      "150. [7.574e-01 2.147e+01 7.259e+02 1.564e-01 2.350e-01]\n",
      "151. [1.322e+00 3.478e+01 6.167e+02 8.112e-02 3.196e-01]\n",
      "152. [  1.962   10.21   249.8      0.5381   0.3322]\n",
      "153. [2.43415e+00 4.98500e+01 3.80500e+02 7.85500e-01 3.10800e-01]\n",
      "154. [7.815e-01 1.548e+01 4.408e+02 7.116e-02 2.859e-01]\n",
      "155. [7.927e-01 2.279e+01 6.773e+02 3.009e-01 3.849e-01]\n",
      "156. [9.823e-01 1.651e+01 5.642e+02 1.943e-01 3.113e-01]\n",
      "157. [1.400e+00 8.620e+01 1.302e+03 3.583e-01 2.463e-01]\n",
      "158. [2.060e+00 4.661e+01 1.032e+03 1.882e-01 2.527e-01]\n",
      "159. [7.285e-01 1.325e+01 5.328e+02 8.636e-02 2.514e-01]\n",
      "160. [7.614e-01 1.854e+01 4.700e+02 1.854e-02 2.738e-01]\n",
      "161. [1.693e+00 3.834e+01 5.439e+02 1.956e-01 3.168e-01]\n",
      "162. [6.336e-01 8.620e+01 1.495e+03 2.264e-01 2.443e-01]\n",
      "163. [1.04800e+00 8.62000e+01 1.93705e+03 6.81000e-01 3.64300e-01]\n",
      "164. [1.656e+00 2.155e+01 5.530e+02 1.688e-01 2.268e-01]\n",
      "165. [8.56100e-01 8.62000e+01 1.93705e+03 3.94800e-01 3.58900e-01]\n",
      "166. [1.065e+00 1.664e+01 7.821e+02 7.750e-02 2.646e-01]\n",
      "167. [4.064e-01 1.148e+01 4.140e+02 1.047e-01 2.090e-01]\n",
      "168. [1.391e+00 6.734e+01 1.260e+03 2.318e-01 2.810e-01]\n",
      "169. [1.41e+00 8.62e+01 1.66e+03 4.89e-01 2.16e-01]\n",
      "170. [1.217e+00 2.428e+01 7.937e+02 6.648e-02 2.404e-01]\n",
      "171. [6.656e-01 1.743e+01 5.491e+02 1.242e-01 2.827e-01]\n",
      "172. [1.147e+00 4.340e+01 9.936e+02 2.644e-01 2.884e-01]\n",
      "173. [6.583e-01 4.464e+01 1.102e+03 5.830e-01 3.216e-01]\n",
      "174. [1.805e+00 1.908e+01 3.965e+02 3.938e-02 1.902e-01]\n",
      "175. [1.925e+00 2.198e+01 4.083e+02 0.000e+00 2.710e-01]\n",
      "176. [  0.7873  11.36   259.2      0.       0.2592]\n",
      "177. [2.261e+00 2.748e+01 3.902e+02 3.486e-01 2.614e-01]\n",
      "178. [1.284e+00 3.159e+01 9.812e+02 5.862e-01 3.054e-01]\n",
      "179. [1.142e+00 1.434e+01 6.088e+02 7.977e-03 2.295e-01]\n",
      "180. [9.899e-01 2.179e+01 5.707e+02 2.758e-02 1.783e-01]\n",
      "181. [1.48100e+00 8.62000e+01 1.93705e+03 5.34000e-01 2.85600e-01]\n",
      "182. [7.62900e-01 8.14600e+01 1.93705e+03 6.78000e-01 4.09800e-01]\n",
      "183. [1.150e+00 4.098e+01 1.269e+03 2.902e-01 3.437e-01]\n",
      "184. [1.108e+00 2.277e+01 4.672e+02 1.648e-01 1.811e-01]\n",
      "185. [4.956e-01 1.953e+01 9.731e+02 3.630e-01 3.175e-01]\n",
      "186. [1.268e+00 2.643e+01 4.370e+02 6.920e-03 2.933e-01]\n",
      "187. [4.757e-01 2.892e+01 1.410e+03 3.538e-01 3.206e-01]\n",
      "188. [7.655e-01 1.786e+01 5.215e+02 1.521e-01 2.572e-01]\n",
      "189. [1.926e+00 1.447e+01 4.895e+02 8.803e-02 3.200e-01]\n",
      "190. [8.355e-01 1.832e+01 5.467e+02 1.423e-01 2.482e-01]\n",
      "191. [2.1100e+00 3.1720e+01 7.6240e+02 7.8550e-01 4.1915e-01]\n",
      "192. [1.748e+00 5.365e+01 5.795e+02 5.186e-02 2.179e-01]\n",
      "193. [2.43415e+00 2.16900e+01 3.03800e+02 0.00000e+00 1.90900e-01]\n",
      "194. [1.809e+00 3.444e+01 7.689e+02 4.425e-01 3.215e-01]\n",
      "195. [9.622e-01 2.520e+01 7.847e+02 4.589e-01 3.000e-01]\n",
      "196. [9.086e-01 1.575e+01 6.006e+02 1.764e-01 3.024e-01]\n",
      "197. [2.112e+00 4.970e+01 8.069e+02 3.809e-01 3.080e-01]\n",
      "198. [1.305e+00 7.636e+01 1.228e+03 2.535e-01 2.369e-01]\n",
      "199. [1.073e+00 5.422e+01 1.688e+03 3.865e-01 3.193e-01]\n",
      "200. [6.5090e-01 1.9420e+01 1.0440e+03 4.9670e-01 4.1915e-01]\n",
      "201. [1.326e+00 2.724e+01 6.384e+02 1.377e-01 2.668e-01]\n",
      "202. [8.282e-01 4.073e+01 1.239e+03 3.508e-01 2.928e-01]\n",
      "203. [1.56000e+00 8.31600e+01 1.93705e+03 7.85500e-01 3.19800e-01]\n",
      "204. [1.9300e+00 5.2720e+01 1.1530e+03 4.6460e-01 4.1915e-01]\n",
      "205. [1.044e+00 3.029e+01 6.779e+02 2.671e-01 3.014e-01]\n",
      "206. [3.621e-01 2.644e+01 9.895e+02 3.327e-01 3.415e-01]\n",
      "207. [1.342e+00 1.233e+01 3.316e+02 6.213e-02 2.989e-01]\n",
      "208. [8.554e-01 6.846e+01 1.210e+03 1.932e-01 3.275e-01]\n",
      "209. [9.223e-01 1.509e+01 6.393e+02 3.162e-01 4.128e-01]\n",
      "210. [3.628e-01 2.000e+01 9.327e+02 2.962e-01 2.320e-01]\n",
      "211. [1.480e+00 8.620e+01 1.656e+03 3.861e-01 2.909e-01]\n",
      "212. [8.652e-01 1.712e+01 5.463e+02 1.471e-01 2.535e-01]\n",
      "213. [1.47600e+00 8.62000e+01 1.93705e+03 3.20100e-01 1.64800e-01]\n",
      "214. [1.667e+00 5.853e+01 1.021e+03 2.803e-01 1.603e-01]\n",
      "215. [1.8450e+00 3.1000e+01 8.1130e+02 3.7440e-01 4.1915e-01]\n",
      "216. [1.194e+00 2.269e+01 7.501e+02 4.636e-01 3.630e-01]\n",
      "217. [1.563e+00 2.146e+01 5.312e+02 2.806e-01 3.397e-01]\n",
      "218. [1.922e+00 2.279e+01 4.037e+02 1.925e-01 2.868e-01]\n",
      "219. [1.18600e+00 8.62000e+01 1.93705e+03 3.61700e-01 3.07000e-01]\n",
      "220. [1.32100e+00 8.62000e+01 1.93705e+03 3.99500e-01 2.71300e-01]\n",
      "221. [4.336e-01 1.740e+01 7.062e+02 1.759e-01 2.380e-01]\n",
      "222. [4.981e-01 2.103e+01 6.866e+02 2.577e-01 3.065e-01]\n",
      "223. [1.217e+00 1.505e+01 3.756e+02 6.572e-02 3.055e-01]\n",
      "224. [9.209e-01 3.219e+01 1.088e+03 3.976e-01 3.993e-01]\n",
      "225. [8.907e-01 2.468e+01 7.088e+02 1.786e-01 2.506e-01]\n",
      "226. [8.121e-01 4.829e+01 8.732e+02 1.632e-01 3.062e-01]\n",
      "227. [9.027e-01 1.186e+01 3.954e+02 2.639e-02 2.615e-01]\n",
      "228. [4.966e-01 1.988e+01 8.082e+02 3.402e-01 2.954e-01]\n",
      "229. [1.066e+00 1.851e+01 6.240e+02 3.911e-01 2.826e-01]\n",
      "230. [1.069e+00 2.513e+01 7.060e+02 6.282e-01 3.407e-01]\n",
      "231. [6.790e-01 3.198e+01 1.189e+03 5.018e-01 3.109e-01]\n",
      "232. [8.927e-01 8.605e+00 4.523e+02 1.089e-01 2.849e-01]\n",
      "233. [1.647e+00 1.546e+01 4.709e+02 2.318e-02 2.911e-01]\n",
      "234. [1.189e+00 7.001e+01 1.872e+03 4.146e-01 2.437e-01]\n",
      "235. [8.301e-01 1.264e+01 3.359e+02 7.161e-02 2.757e-01]\n",
      "236. [1.503e+00 2.207e+01 7.155e+02 6.231e-02 2.226e-01]\n",
      "237. [9.63500e-01 8.62000e+01 1.93705e+03 5.82000e-01 3.10300e-01]\n",
      "238. [1.041e+00 8.350e+01 1.750e+03 3.158e-01 2.238e-01]\n",
      "239. [2.324e+00 2.996e+01 7.640e+02 3.064e-01 1.890e-01]\n",
      "240. [8.561e-01 4.900e+01 1.408e+03 3.241e-01 2.853e-01]\n",
      "241. [6.612e-01 2.719e+01 6.834e+02 1.533e-01 2.530e-01]\n",
      "242. [6.745e-01 9.006e+00 5.434e+02 6.243e-02 2.901e-01]\n",
      "243. [1.642e+00 1.639e+01 4.729e+02 7.436e-01 3.308e-01]\n",
      "244. [1.057e+00 3.993e+01 7.060e+02 1.359e-01 2.663e-01]\n",
      "245. [1.802e+00 6.041e+01 1.417e+03 3.458e-01 2.920e-01]\n",
      "246. [2.43415e+00 2.32200e+01 4.02800e+02 1.18100e-01 2.88300e-01]\n",
      "247. [1.601e+00 1.356e+01 6.020e+02 2.298e-01 2.767e-01]\n",
      "248. [4.402e-01 1.635e+01 6.391e+02 7.727e-01 2.639e-01]\n",
      "249. [1.493e+00 1.664e+01 4.557e+02 1.125e-01 3.409e-01]\n",
      "250. [1.038e+00 1.862e+01 4.918e+02 1.804e-01 2.664e-01]\n",
      "251. [8.20800e-01 8.62000e+01 1.93705e+03 6.99100e-01 3.12600e-01]\n",
      "252. [8.429e-01 2.699e+01 5.089e+02 8.105e-02 2.740e-01]\n",
      "253. [7.800e-01 8.620e+01 1.933e+03 7.855e-01 2.749e-01]\n",
      "254. [8.568e-01 3.363e+01 1.222e+03 3.378e-01 3.138e-01]\n",
      "255. [6.34200e-01 7.10000e+01 1.93705e+03 4.31700e-01 3.37900e-01]\n",
      "256. [8.098e-01 3.574e+01 8.260e+02 3.209e-01 3.068e-01]\n",
      "257. [1.199e+00 8.620e+01 1.926e+03 4.251e-01 2.818e-01]\n",
      "258. [1.059e+00 5.946e+01 9.288e+02 4.429e-01 3.258e-01]\n",
      "259. [2.43415e+00 8.62000e+01 1.22600e+03 6.18100e-01 3.27700e-01]\n",
      "260. [1.278e+00 2.302e+01 1.035e+03 5.703e-01 3.512e-01]\n",
      "261. [1.033e+00 5.234e+01 1.844e+03 3.788e-01 3.151e-01]\n",
      "262. [1.317e+00 4.441e+01 1.218e+03 1.211e-01 2.452e-01]\n",
      "263. [1.633e+00 8.620e+01 1.295e+03 2.298e-01 3.067e-01]\n",
      "264. [9.988e-01 2.218e+01 9.886e+02 2.260e-01 2.683e-01]\n",
      "265. [7.383e-01 4.542e+01 1.436e+03 3.889e-01 3.216e-01]\n",
      "266. [1.61700e+00 8.62000e+01 1.93705e+03 3.44200e-01 2.86800e-01]\n",
      "267. [1.197e+00 2.710e+01 4.248e+02 1.916e-01 2.940e-01]\n",
      "268. [1.916e+00 2.676e+01 6.615e+02 1.453e-01 2.446e-01]\n",
      "269. [1.219e+00 1.824e+01 5.975e+02 1.992e-01 3.604e-01]\n",
      "270. [1.489e+00 2.074e+01 4.104e+02 2.534e-01 2.605e-01]\n",
      "271. [7.198e-01 1.077e+01 6.846e+02 3.866e-02 2.458e-01]\n",
      "272. [5.293e-01 1.317e+01 4.575e+02 1.275e-01 2.733e-01]\n",
      "273. [1.35200e+00 8.62000e+01 1.93705e+03 5.80700e-01 2.83300e-01]\n",
      "274. [1.409e+00 1.639e+01 3.552e+02 4.043e-02 2.841e-01]\n",
      "275. [1.433e+00 4.581e+01 1.320e+03 2.080e-01 2.504e-01]\n",
      "276. [2.293e+00 4.884e+01 4.724e+02 7.153e-02 2.220e-01]\n",
      "277. [1.280e+00 1.709e+01 4.580e+02 4.955e-03 2.758e-01]\n",
      "278. [8.280e-01 3.674e+01 1.236e+03 2.210e-01 2.567e-01]\n",
      "279. [1.166e+00 2.222e+01 7.391e+02 1.060e-01 2.335e-01]\n",
      "280. [9.195e-01 1.941e+01 6.700e+02 1.456e-01 2.955e-01]\n",
      "281. [1.001e+00 6.965e+01 1.724e+03 5.754e-01 3.258e-01]\n",
      "282. [1.268e+00 3.783e+01 5.337e+02 6.735e-02 3.101e-01]\n",
      "283. [9.951e-01 5.316e+01 1.628e+03 4.316e-01 3.590e-01]\n",
      "284. [9.173e-01 2.809e+01 1.031e+03 5.026e-01 2.770e-01]\n",
      "285. [1.389e+00 2.329e+01 5.956e+02 3.344e-01 1.999e-01]\n",
      "286. [1.350e+00 2.245e+01 5.641e+02 5.579e-03 2.505e-01]\n",
      "287. [1.390e+00 2.191e+01 5.461e+02 2.365e-01 2.465e-01]\n",
      "288. [4.690e-01 1.268e+01 5.770e+02 1.186e-01 2.309e-01]\n",
      "289. [1.905e+00 3.468e+01 4.376e+02 1.546e-01 2.955e-01]\n",
      "290. [1.974e+00 1.749e+01 4.593e+02 7.529e-02 3.267e-01]\n",
      "291. [1.770e+00 7.711e+01 7.673e+02 2.220e-01 2.272e-01]\n",
      "292. [9.480e-01 2.487e+01 8.098e+02 1.804e-01 2.962e-01]\n",
      "293. [7.636e-01 1.767e+01 5.854e+02 2.241e-01 3.380e-01]\n",
      "294. [1.238e+00 1.388e+01 5.178e+02 1.316e-01 3.101e-01]\n",
      "295. [6.931e-01 1.338e+01 5.537e+02 5.233e-02 2.369e-01]\n",
      "296. [6.946e-01 1.774e+01 6.611e+02 3.732e-02 2.823e-01]\n",
      "297. [1.027e+00 1.109e+01 3.922e+02 2.884e-02 2.143e-01]\n",
      "298. [2.105e+00 4.911e+01 5.536e+02 6.120e-02 1.978e-01]\n",
      "299. [6.690e-01 2.056e+01 8.197e+02 1.565e-01 2.636e-01]\n",
      "300. [1.143e+00 2.056e+01 3.627e+02 4.158e-02 2.227e-01]\n",
      "301. [1.16100e+00 8.62000e+01 1.93705e+03 6.12100e-01 2.96800e-01]\n",
      "302. [1.040e+00 2.832e+01 5.513e+02 1.904e-01 2.685e-01]\n",
      "303. [1.743e+00 8.620e+01 1.696e+03 4.932e-01 3.294e-01]\n",
      "304. [1.563e+00 1.008e+01 3.754e+02 8.423e-02 2.213e-01]\n",
      "305. [1.059e+00 2.293e+01 4.898e+02 1.226e-01 2.208e-01]\n",
      "306. [1.786e+00 1.821e+01 4.765e+02 7.239e-02 3.244e-01]\n",
      "307. [5.735e-01 1.550e+01 6.369e+02 1.120e-02 2.651e-01]\n",
      "308. [1.305e+00 9.789e+00 2.855e+02 1.472e-02 2.991e-01]\n",
      "309. [6.864e-01 2.039e+01 6.987e+02 1.379e-02 2.267e-01]\n",
      "310. [8.285e-01 3.301e+01 6.724e+02 1.824e-02 2.107e-01]\n",
      "311. [1.430e+00 1.128e+01 4.831e+02 7.915e-02 3.487e-01]\n",
      "312. [9.115e-01 2.890e+01 8.408e+02 4.746e-02 2.530e-01]\n",
      "313. [6.594e-01 2.518e+01 6.188e+02 1.769e-01 2.564e-01]\n",
      "314. [3.602e-01 9.438e+00 4.678e+02 8.324e-02 3.390e-01]\n",
      "315. [  2.43415  17.81    240.1       0.        0.3142 ]\n",
      "316. [7.151e-01 1.269e+01 5.442e+02 1.938e-02 1.917e-01]\n",
      "317. [5.996e-01 1.582e+01 5.131e+02 4.116e-02 2.293e-01]\n",
      "318. [5.503e-01 4.890e+01 1.485e+03 3.853e-01 2.812e-01]\n",
      "319. [  1.911   24.2    297.1      0.4609   0.3135]\n",
      "320. [2.200e+00 3.116e+01 5.159e+02 2.237e-02 1.901e-01]\n",
      "321. [1.471e+00 2.268e+01 3.904e+02 1.898e-01 2.608e-01]\n",
      "322. [6.863e-01 7.485e+01 1.657e+03 2.606e-01 3.055e-01]\n",
      "323. [1.042e+00 1.657e+01 5.995e+02 1.791e-01 2.382e-01]\n",
      "324. [1.02300e+00 6.90600e+01 1.93705e+03 5.34400e-01 4.19150e-01]\n",
      "325. [8.073e-01 1.901e+01 5.831e+02 1.167e-01 2.661e-01]\n",
      "326. [9.505e-01 1.761e+01 5.744e+02 1.020e-01 2.688e-01]\n",
      "327. [1.081e+00 2.392e+01 7.499e+02 5.307e-02 2.100e-01]\n",
      "328. [9.097e-01 1.697e+01 5.234e+02 7.732e-03 2.171e-01]\n",
      "329. [1.232e+00 4.441e+01 1.121e+03 3.597e-01 3.103e-01]\n",
      "330. [1.457e+00 5.772e+01 9.752e+02 3.344e-01 2.736e-01]\n",
      "331. [7.476e-01 3.327e+01 1.070e+03 4.956e-01 3.019e-01]\n",
      "332. [5.664e-01 2.065e+01 6.343e+02 3.439e-01 3.596e-01]\n",
      "333. [1.966e+00 1.962e+01 4.361e+02 1.335e-02 3.292e-01]\n",
      "334. [9.961e-01 1.507e+01 4.927e+02 5.518e-03 2.815e-01]\n",
      "335. [1.532e+00 1.324e+01 5.443e+02 3.619e-02 2.554e-01]\n",
      "336. [2.129e+00 8.620e+01 1.362e+03 3.920e-01 2.623e-01]\n",
      "337. [6.412e-01 1.441e+01 5.760e+02 1.450e-01 2.432e-01]\n",
      "338. [1.530e+00 8.620e+01 1.873e+03 4.634e-01 3.679e-01]\n",
      "339. [2.015e+00 1.685e+01 3.840e+02 1.055e-01 2.894e-01]\n",
      "340. [9.24500e-01 8.62000e+01 1.93705e+03 4.81900e-01 2.59300e-01]\n",
      "341. [7.706e-01 3.214e+01 8.621e+02 3.755e-01 3.053e-01]\n",
      "342. [9.429e-01 1.207e+01 3.536e+02 4.341e-01 2.982e-01]\n",
      "343. [8.225e-01 1.080e+01 4.400e+02 2.299e-01 3.301e-01]\n",
      "344. [2.284e+00 6.766e+01 1.540e+03 4.734e-01 4.045e-01]\n",
      "345. [7.395e-01 2.453e+01 5.164e+02 1.087e-01 2.765e-01]\n",
      "346. [2.43415e+00 1.93300e+01 3.57100e+02 7.16200e-02 2.43400e-01]\n",
      "347. [1.152e+00 1.802e+01 5.626e+02 4.506e-02 2.880e-01]\n",
      "348. [3.981e-01 2.906e+01 8.808e+02 2.151e-01 3.109e-01]\n",
      "349. [7.615e-01 1.225e+01 4.758e+02 9.823e-02 2.851e-01]\n",
      "350. [1.050e+00 2.665e+01 4.962e+02 3.122e-02 3.124e-01]\n",
      "351. [6.724e-01 2.603e+01 5.425e+02 3.046e-02 2.731e-01]\n",
      "352. [1.3240e+00 5.1220e+01 9.1530e+02 6.8720e-01 4.1915e-01]\n",
      "353. [8.50900e-01 8.62000e+01 1.93705e+03 6.45100e-01 3.69000e-01]\n",
      "354. [1.506e+00 6.337e+01 1.050e+03 4.029e-01 2.654e-01]\n",
      "355. [8.092e-01 2.884e+01 4.535e+02 1.201e-01 2.576e-01]\n",
      "356. [1.478e+00 2.749e+01 5.474e+02 2.388e-01 2.121e-01]\n",
      "357. [1.510e+00 2.157e+01 5.912e+02 2.573e-01 3.113e-01]\n",
      "358. [1.363e+00 2.074e+01 6.944e+02 5.285e-02 2.362e-01]\n",
      "359. [1.200e+00 3.018e+01 3.020e+02 9.441e-02 2.434e-01]\n",
      "360. [1.247e+00 3.048e+01 4.396e+02 1.144e-01 2.454e-01]\n",
      "361. [9.527e-01 2.830e+01 5.857e+02 3.581e-03 2.233e-01]\n",
      "362. [1.539e+00 2.098e+01 6.212e+02 1.212e-01 2.637e-01]\n",
      "363. [1.285e+00 1.726e+01 5.797e+02 1.255e-01 2.744e-01]\n",
      "364. [1.439e+00 3.358e+01 1.009e+03 1.663e-01 2.394e-01]\n",
      "365. [6.124e-01 1.322e+01 6.635e+02 1.364e-01 2.741e-01]\n",
      "366. [9.168e-01 7.244e+01 1.780e+03 2.702e-01 2.609e-01]\n",
      "367. [1.892e+00 8.620e+01 1.671e+03 3.703e-01 3.271e-01]\n",
      "368. [7.786e-01 1.857e+01 6.246e+02 2.413e-01 3.218e-01]\n",
      "369. [1.05100e+00 8.62000e+01 1.93705e+03 2.86100e-01 2.51000e-01]\n",
      "370. [6.99900e-01 8.62000e+01 1.93705e+03 4.75600e-01 2.74100e-01]\n",
      "371. [1.0220e+00 4.5500e+01 1.1650e+03 7.0870e-01 4.1915e-01]\n",
      "372. [4.125e-01 1.772e+01 8.191e+02 1.362e-01 2.487e-01]\n",
      "373. [1.309e+00 3.906e+01 1.535e+03 4.024e-01 2.730e-01]\n",
      "374. [6.57500e-01 7.70200e+01 1.93705e+03 4.15900e-01 2.68900e-01]\n",
      "375. [5.066e-01 1.400e+01 6.706e+02 1.346e-01 3.323e-01]\n",
      "376. [4.890e-01 1.491e+01 8.615e+02 2.114e-01 3.153e-01]\n",
      "377. [1.231e+00 7.228e+00 3.519e+02 6.030e-01 2.597e-01]\n",
      "378. [1.150e+00 1.491e+01 6.806e+02 7.934e-02 2.694e-01]\n",
      "379. [5.417e-01 1.135e+01 6.570e+02 2.569e-01 3.387e-01]\n",
      "380. [1.027e+00 1.399e+01 5.081e+02 7.855e-01 4.154e-01]\n",
      "381. [9.858e-01 1.604e+01 4.761e+02 2.247e-01 3.343e-01]\n",
      "382. [1.031e+00 1.168e+01 4.471e+02 1.553e-01 3.202e-01]\n",
      "383. [1.434e+00 9.549e+00 4.884e+02 2.912e-01 2.191e-01]\n",
      "384. [8.730e-01 1.920e+01 6.005e+02 3.206e-01 2.819e-01]\n",
      "385. [5.308e-01 1.526e+01 6.237e+02 2.866e-01 2.736e-01]\n",
      "386. [1.627e+00 3.301e+01 7.582e+02 2.675e-01 2.477e-01]\n",
      "387. [8.309e-01 1.996e+01 5.299e+02 3.076e-01 2.677e-01]\n",
      "388. [6.218e-01 2.312e+01 7.453e+02 1.091e-01 2.542e-01]\n",
      "389. [1.067e+00 2.297e+01 4.500e+02 3.021e-01 2.157e-01]\n",
      "390. [2.43415e+00 7.01000e+01 1.31300e+03 3.82900e-01 2.57600e-01]\n",
      "391. [5.477e-01 1.188e+01 3.945e+02 8.615e-02 2.937e-01]\n",
      "392. [2.079e+00 2.885e+01 3.170e+02 0.000e+00 2.445e-01]\n",
      "393. [1.331e+00 6.691e+01 1.359e+03 5.553e-01 3.187e-01]\n",
      "394. [9.20900e-01 8.09900e+01 1.93705e+03 7.05300e-01 3.82800e-01]\n",
      "395. [1.652e+00 2.222e+01 5.595e+02 1.603e-01 3.049e-01]\n",
      "396. [1.685e+00 1.267e+01 6.845e+02 8.460e-02 2.523e-01]\n",
      "397. [1.332e+00 1.929e+01 6.752e+02 3.438e-01 2.666e-01]\n",
      "398. [1.265e+00 3.057e+01 5.910e+02 1.901e-01 1.988e-01]\n",
      "399. [6.881e-01 1.298e+01 4.967e+02 2.079e-01 2.590e-01]\n",
      "400. [1.140e+00 2.506e+01 5.620e+02 1.449e-01 2.779e-01]\n",
      "401. [7.747e-01 4.151e+01 1.304e+03 7.855e-01 3.245e-01]\n",
      "402. [1.045e+00 1.895e+01 5.895e+02 1.514e-01 2.460e-01]\n",
      "403. [1.299e+00 2.021e+01 6.219e+02 1.604e-01 3.207e-01]\n",
      "404. [9.050e-01 1.136e+01 5.809e+02 1.810e-01 3.297e-01]\n",
      "405. [9.078e-01 3.015e+01 5.331e+02 4.921e-02 2.298e-01]\n",
      "406. [1.743e+00 2.578e+01 4.724e+02 1.412e-01 2.251e-01]\n",
      "407. [6.372e-01 2.183e+01 9.479e+02 2.310e-01 2.778e-01]\n",
      "408. [1.798e+00 4.124e+01 6.458e+02 1.838e-01 2.488e-01]\n",
      "409. [8.733e-01 4.981e+01 1.349e+03 3.301e-01 3.060e-01]\n",
      "410. [1.781e+00 2.579e+01 6.102e+02 1.377e-01 3.455e-01]\n",
      "411. [1.555e+00 1.366e+01 5.213e+02 1.811e-01 2.973e-01]\n",
      "412. [1.387e+00 1.354e+01 4.714e+02 1.067e-01 2.998e-01]\n",
      "413. [1.182e+00 6.802e+00 3.010e+02 1.868e-01 2.376e-01]\n",
      "414. [1.336e+00 2.851e+01 8.671e+02 3.114e-01 3.163e-01]\n",
      "415. [1.627e+00 4.538e+01 9.314e+02 1.547e-01 3.233e-01]\n",
      "416. [1.203e+00 1.953e+01 5.229e+02 1.164e-01 3.075e-01]\n",
      "417. [2.43415e+00 2.51700e+01 3.59400e+02 6.14100e-02 2.87200e-01]\n",
      "418. [1.213e+00 8.620e+01 1.748e+03 4.211e-01 3.003e-01]\n",
      "419. [6.457e-01 1.737e+01 5.669e+02 9.385e-02 2.775e-01]\n",
      "420. [1.678e+00 1.899e+01 4.580e+02 3.582e-02 2.976e-01]\n",
      "421. [1.440e+00 2.030e+01 5.205e+02 2.560e-01 3.035e-01]\n",
      "422. [1.511e+00 4.945e+01 8.092e+02 3.219e-01 2.827e-01]\n",
      "423. [7.339e-01 1.589e+01 4.757e+02 2.302e-01 2.787e-01]\n",
      "424. [8.950e-01 1.936e+01 7.088e+02 3.660e-01 2.744e-01]\n",
      "425. [1.747e+00 4.352e+01 3.809e+02 2.085e-02 3.196e-01]\n",
      "426. [1.341e+00 1.160e+01 3.763e+02 1.235e-02 2.349e-01]\n",
      "427. [1.127e+00 2.077e+01 4.404e+02 2.939e-01 3.020e-01]\n",
      "428. [1.621e+00 2.020e+01 4.895e+02 1.927e-01 2.965e-01]\n",
      "429. [9.671e-01 9.704e+00 4.211e+02 4.580e-02 2.383e-01]\n",
      "430. [8.836e-01 2.324e+01 5.868e+02 3.469e-02 2.165e-01]\n",
      "431. [8.749e-01 2.419e+01 8.327e+02 7.855e-01 2.866e-01]\n",
      "432. [1.460e+00 1.543e+01 5.158e+02 2.403e-01 2.556e-01]\n",
      "433. [1.001e+00 5.249e+01 1.479e+03 5.308e-01 3.032e-01]\n",
      "434. [1.931e+00 8.620e+01 1.603e+03 3.912e-01 3.007e-01]\n",
      "435. [6.683e-01 2.392e+01 7.775e+02 1.220e-01 2.525e-01]\n",
      "436. [9.533e-01 1.885e+01 8.693e+02 4.069e-01 3.179e-01]\n",
      "437. [7.693e-01 2.650e+01 6.269e+02 7.127e-02 3.313e-01]\n",
      "438. [1.046e+00 3.274e+01 7.500e+02 1.117e-01 2.725e-01]\n",
      "439. [1.678e+00 2.963e+01 7.491e+02 4.753e-02 2.513e-01]\n",
      "440. [6.549e-01 1.925e+01 6.889e+02 6.260e-02 2.136e-01]\n",
      "441. [1.376e+00 1.815e+01 4.764e+02 4.779e-01 2.540e-01]\n",
      "442. [1.679e+00 5.838e+01 1.284e+03 5.036e-01 2.500e-01]\n",
      "443. [4.833e-01 2.934e+01 7.066e+02 3.517e-02 1.859e-01]\n",
      "444. [2.43415e+00 1.31200e+01 3.66300e+02 3.98600e-02 2.69900e-01]\n",
      "445. [5.906e-01 3.577e+01 1.292e+03 4.290e-01 2.842e-01]\n",
      "446. [1.204e+00 1.939e+01 5.139e+02 1.609e-01 2.599e-01]\n",
      "447. [1.077e+00 4.395e+01 1.437e+03 6.399e-01 2.972e-01]\n",
      "448. [6.221e-01 1.975e+01 8.295e+02 2.060e-01 3.600e-01]\n",
      "449. [1.354e+00 2.304e+01 8.305e+02 3.779e-01 2.471e-01]\n",
      "450. [1.36100e+00 8.18900e+01 1.93705e+03 4.39900e-01 2.26800e-01]\n",
      "451. [1.554e+00 2.024e+01 5.072e+02 3.218e-01 2.305e-01]\n",
      "452. [1.375e+00 5.618e+01 1.421e+03 3.977e-01 2.293e-01]\n",
      "453. [1.705e+00 1.386e+01 5.237e+02 1.811e-01 2.447e-01]\n",
      "454. [7.213e-01 2.570e+01 7.499e+02 1.373e-01 2.606e-01]\n",
      "455. [6.674e-01 1.332e+01 6.335e+02 1.887e-01 3.270e-01]\n",
      "456. [1.924e+00 2.893e+01 7.056e+02 7.003e-02 2.196e-01]\n",
      "457. [2.426e+00 2.313e+01 5.278e+02 2.923e-01 2.884e-01]\n",
      "458. [1.350e+00 1.758e+01 6.329e+02 1.390e-01 2.444e-01]\n",
      "459. [1.232e+00 2.119e+01 6.285e+02 4.462e-02 2.306e-01]\n",
      "460. [1.687e+00 1.128e+01 3.499e+02 7.190e-02 2.321e-01]\n",
      "461. [1.152e+00 8.620e+01 1.648e+03 2.639e-01 3.010e-01]\n",
      "462. [1.30600e+00 8.62000e+01 1.93705e+03 6.83300e-01 2.64100e-01]\n",
      "463. [9.112e-01 2.052e+01 7.346e+02 1.472e-01 2.345e-01]\n",
      "464. [7.656e-01 1.289e+01 4.951e+02 1.860e-01 3.210e-01]\n",
      "465. [6.850e-01 1.689e+01 6.876e+02 1.876e-01 2.235e-01]\n",
      "466. [8.135e-01 2.381e+01 7.335e+02 6.556e-01 2.845e-01]\n",
      "467. [7.884e-01 2.740e+01 6.891e+02 4.504e-01 2.563e-01]\n",
      "468. [1.312e+00 2.098e+01 3.802e+02 6.409e-02 3.057e-01]\n",
      "469. [1.465e+00 8.620e+01 1.437e+03 5.165e-01 2.301e-01]\n",
      "470. [1.740e+00 2.785e+01 5.281e+02 3.186e-01 2.660e-01]\n",
      "471. [1.350e+00 2.273e+01 3.852e+02 1.277e-01 3.174e-01]\n",
      "472. [2.43415e+00 4.49600e+01 5.67600e+02 5.52400e-02 2.40400e-01]\n",
      "473. [4.334e-01 2.331e+01 9.066e+02 3.151e-01 2.688e-01]\n",
      "474. [2.43415e+00 3.51300e+01 5.58900e+02 0.00000e+00 2.40900e-01]\n",
      "475. [5.380e-01 9.597e+00 4.331e+02 3.365e-01 2.581e-01]\n",
      "476. [4.875e-01 1.164e+01 6.058e+02 3.476e-01 3.006e-01]\n",
      "477. [1.018e+00 3.101e+01 8.285e+02 2.512e-01 2.534e-01]\n",
      "478. [5.762e-01 1.403e+01 7.189e+02 1.384e-01 2.679e-01]\n",
      "479. [1.166e+00 1.434e+01 4.676e+02 2.596e-01 2.941e-01]\n",
      "480. [9.857e-01 3.312e+01 9.397e+02 5.897e-01 3.318e-01]\n",
      "481. [1.190e+00 1.626e+01 5.474e+02 1.620e-01 2.406e-01]\n",
      "482. [9.264e-01 2.841e+01 8.305e+02 1.673e-01 2.356e-01]\n",
      "483. [5.733e-01 1.284e+01 6.602e+02 1.848e-01 3.227e-01]\n",
      "484. [9.462e-01 2.064e+01 6.865e+02 1.742e-01 2.518e-01]\n",
      "485. [3.871e-01 1.387e+01 8.543e+02 4.004e-01 2.557e-01]\n",
      "486. [1.207e+00 3.019e+01 5.806e+02 4.896e-01 3.231e-01]\n",
      "487. [1.006e+00 1.998e+01 8.310e+02 2.437e-01 2.455e-01]\n",
      "488. [1.408e+00 6.774e+01 1.740e+03 5.936e-01 3.266e-01]\n",
      "489. [1.154e+00 2.757e+01 5.498e+02 1.490e-01 2.804e-01]\n",
      "490. [5.6790e-01 2.2950e+01 1.0840e+03 2.4770e-01 4.1915e-01]\n",
      "491. [1.139e+00 1.804e+01 6.229e+02 1.230e-01 3.100e-01]\n",
      "492. [1.046e+00 5.095e+01 1.210e+03 1.048e-01 1.783e-01]\n",
      "493. [1.288e+00 8.620e+01 1.426e+03 2.544e-01 3.251e-01]\n",
      "494. [1.486e+00 2.460e+01 5.340e+02 1.674e-02 2.280e-01]\n",
      "495. [1.473e+00 2.607e+01 6.483e+02 7.698e-02 2.687e-01]\n",
      "496. [1.636e+00 2.184e+01 7.836e+02 1.700e-01 2.369e-01]\n",
      "497. [6.332e-01 1.840e+01 6.337e+02 3.582e-01 3.230e-01]\n",
      "498. [7.810e-01 1.191e+01 6.073e+02 2.028e-01 3.035e-01]\n",
      "499. [1.045e+00 8.620e+01 1.600e+03 3.533e-01 2.510e-01]\n",
      "500. [1.216e+00 7.509e+01 1.760e+03 5.179e-01 2.480e-01]\n",
      "501. [8.423e-01 3.484e+01 8.569e+02 1.856e-01 2.177e-01]\n",
      "502. [1.528e+00 3.905e+01 7.880e+02 3.381e-01 3.651e-01]\n",
      "503. [1.095e+00 1.849e+01 5.520e+02 1.889e-01 3.155e-01]\n",
      "504. [7.45200e-01 8.62000e+01 1.93705e+03 3.79400e-01 2.90800e-01]\n",
      "505. [1.093e+00 2.004e+01 3.002e+02 2.099e-01 3.038e-01]\n",
      "506. [1.390e+00 1.767e+01 3.281e+02 2.913e-01 2.848e-01]\n",
      "507. [7.959e-01 1.258e+01 5.153e+02 3.535e-01 2.709e-01]\n",
      "508. [1.030e+00 1.230e+01 4.111e+02 1.256e-01 2.780e-01]\n",
      "509. [4.706e-01 2.067e+01 9.282e+02 1.947e-01 2.300e-01]\n",
      "510. [1.961e+00 3.252e+01 9.094e+02 5.911e-01 3.013e-01]\n",
      "511. [6.417e-01 1.304e+01 4.738e+02 2.690e-01 2.604e-01]\n",
      "512. [6.232e-01 2.072e+01 7.602e+02 1.101e-01 2.334e-01]\n",
      "513. [9.306e-01 3.367e+01 8.444e+02 5.106e-01 3.585e-01]\n",
      "514. [6.237e-01 3.711e+01 8.620e+02 2.492e-01 2.626e-01]\n",
      "515. [1.198e+00 3.849e+01 9.670e+02 2.866e-01 2.282e-01]\n",
      "516. [1.010e+00 1.819e+01 4.786e+02 1.624e-01 3.060e-01]\n",
      "517. [9.225e-01 6.736e+01 1.493e+03 3.759e-01 3.074e-01]\n",
      "518. [8.737e-01 5.970e+01 1.646e+03 4.185e-01 2.549e-01]\n",
      "519. [1.169e+00 3.437e+01 6.747e+02 1.246e-01 2.582e-01]\n",
      "520. [1.003e+00 2.862e+01 6.241e+02 1.423e-01 3.071e-01]\n",
      "521. [1.130e+00 1.963e+01 3.266e+02 9.996e-02 3.681e-01]\n",
      "522. [9.00400e-01 8.62000e+01 1.93705e+03 4.65800e-01 3.15700e-01]\n",
      "523. [1.083e+00 9.332e+00 4.359e+02 2.533e-02 2.557e-01]\n",
      "524. [1.249e+00 2.645e+01 7.019e+02 1.935e-01 2.849e-01]\n",
      "525. [1.216e+00 1.524e+01 3.765e+02 8.434e-02 2.502e-01]\n",
      "526. [6.793e-01 7.254e+00 2.756e+02 1.754e-01 2.983e-01]\n",
      "527. [6.068e-01 1.607e+01 7.198e+02 2.654e-01 3.518e-01]\n",
      "528. [4.957e-01 8.955e+00 5.649e+02 1.791e-01 3.110e-01]\n",
      "529. [2.43415e+00 4.47400e+01 6.53300e+02 1.55900e-01 2.16000e-01]\n",
      "530. [5.040e-01 1.854e+01 5.499e+02 1.622e-01 2.781e-01]\n",
      "531. [1.907e+00 3.066e+01 5.523e+02 1.366e-01 2.478e-01]\n",
      "532. [8.745e-01 1.534e+01 5.506e+02 2.758e-01 3.206e-01]\n",
      "533. [4.801e-01 1.725e+01 7.734e+02 1.206e-01 2.806e-01]\n",
      "534. [1.736e+00 8.620e+01 1.645e+03 3.092e-01 3.220e-01]\n",
      "535. [1.583e+00 1.009e+01 4.075e+02 2.123e-01 2.289e-01]\n",
      "536. [9.901e-01 8.620e+01 1.809e+03 4.433e-01 3.077e-01]\n",
      "537. [1.851e+00 1.854e+01 7.283e+02 4.234e-01 2.698e-01]\n",
      "538. [1.978e+00 2.095e+01 4.877e+02 1.395e-01 2.803e-01]\n",
      "539. [  1.462   19.14   248.       0.       0.3058]\n",
      "540. [  1.479   11.73   223.6      0.3393   0.279 ]\n",
      "541. [1.768e+00 2.086e+01 4.578e+02 1.797e-01 2.329e-01]\n",
      "542. [1.079e+00 2.311e+01 8.089e+02 4.040e-01 3.187e-01]\n",
      "543. [1.385e+00 2.741e+01 8.264e+02 1.611e-01 2.722e-01]\n",
      "544. [1.597e+00 1.785e+01 6.296e+02 1.062e-01 2.473e-01]\n",
      "545. [1.047e+00 2.312e+01 6.886e+02 1.377e-01 2.249e-01]\n",
      "546. [1.336e+00 3.124e+01 7.298e+02 1.049e-01 2.642e-01]\n",
      "547. [9.670e-01 1.297e+01 3.849e+02 4.384e-02 2.681e-01]\n",
      "548. [1.023e+00 7.326e+00 3.574e+02 1.783e-01 2.691e-01]\n",
      "549. [1.363e+00 1.824e+01 3.642e+02 9.350e-02 2.552e-01]\n",
      "550. [1.918e+00 3.300e+01 5.056e+02 6.194e-02 3.059e-01]\n",
      "551. [1.304e+00 2.067e+01 4.123e+02 0.000e+00 2.458e-01]\n",
      "552. [1.467e+00 1.785e+01 4.366e+02 1.564e-01 3.169e-01]\n",
      "553. [1.367e+00 1.876e+01 5.947e+02 8.653e-02 2.407e-01]\n",
      "554. [1.879e+00 1.786e+01 2.958e+02 7.993e-02 2.435e-01]\n",
      "555. [1.360e+00 1.683e+01 5.957e+02 2.439e-01 2.372e-01]\n",
      "556. [2.239e+00 1.446e+01 3.576e+02 2.000e-01 2.226e-01]\n",
      "557. [2.090e+00 1.680e+01 3.473e+02 1.005e-02 2.262e-01]\n",
      "558. [2.43415e+00 2.91100e+01 3.30600e+02 0.00000e+00 2.47500e-01]\n",
      "559. [1.108e+00 1.954e+01 7.335e+02 3.662e-01 2.258e-01]\n",
      "560. [2.43415e+00 1.69700e+01 4.74200e+02 3.63000e-01 2.11200e-01]\n",
      "561. [1.492e+00 2.984e+01 7.067e+02 1.326e-01 2.250e-01]\n",
      "562. [2.43415e+00 2.28100e+01 4.39600e+02 0.00000e+00 1.56600e-01]\n",
      "563. [1.205e+00 2.265e+01 9.150e+02 7.855e-01 4.089e-01]\n",
      "564. [1.026e+00 8.620e+01 1.819e+03 6.599e-01 2.929e-01]\n",
      "565. [1.25600e+00 8.62000e+01 1.93705e+03 4.10700e-01 2.06000e-01]\n",
      "566. [2.43415e+00 8.62000e+01 1.73100e+03 3.21500e-01 2.57200e-01]\n",
      "567. [1.075e+00 4.855e+01 1.124e+03 3.403e-01 2.218e-01]\n",
      "568. [1.595e+00 8.620e+01 1.821e+03 7.855e-01 4.087e-01]\n",
      "569. [  1.428   19.15   268.6      0.       0.2871]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "selected_features_list = rfeFeature(indep_X, dep_Y, 5)\n",
    "\n",
    "# Print selected features for each classifier\n",
    "for i, selected_features in enumerate(selected_features_list):\n",
    "    print(f\"Selected features for Classifier {i+1}:\")\n",
    "    for j, feature in enumerate(selected_features):\n",
    "        print(f\"{j+1}. {feature}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "197ede50-6ab8-4c8b-90f1-83377db94ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename=\"RandomForest_CLASSIFICATION_final.sav\"\n",
    "pickle.dump(classifier,open(filename,'wb'))\n",
    "loaded_model=pickle.load(open(\"RandomForest_CLASSIFICATION_final.sav\",'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496afdd7-2200-4cc7-92e9-ad751fab0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_Prediction=loaded_model.predict([[]])# change the paramter,play with it.\n",
    "print(\"Future_Prediction={}\".format(future_Prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
